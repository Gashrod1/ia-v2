Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.07091
Policy Entropy: 0.15763
Value Function Loss: 2.15015

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.14109
Policy Update Magnitude: 0.02455
Value Function Update Magnitude: 0.03862

Collected Steps per Second: 12054.54385
Overall Steps per Second: 4888.68568

Timestep Collection Time: 4.14815
Timestep Consumption Time: 6.08037
PPO Batch Consumption Time: 2.19401
Total Iteration Time: 10.22852

Cumulative Model Updates: 5972
Cumulative Timesteps: 50076620

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.94209
Policy Entropy: 0.16006
Value Function Loss: 2.41328

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14575
Policy Update Magnitude: 0.02517
Value Function Update Magnitude: 0.04647

Collected Steps per Second: 13061.94965
Overall Steps per Second: 4944.51710

Timestep Collection Time: 3.82791
Timestep Consumption Time: 6.28430
PPO Batch Consumption Time: 2.28831
Total Iteration Time: 10.11221

Cumulative Model Updates: 5974
Cumulative Timesteps: 50126620

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.35557
Policy Entropy: 0.15753
Value Function Loss: 2.44019

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.17567
Policy Update Magnitude: 0.05095
Value Function Update Magnitude: 0.09431

Collected Steps per Second: 14890.19598
Overall Steps per Second: 3503.96205

Timestep Collection Time: 3.35953
Timestep Consumption Time: 10.91688
PPO Batch Consumption Time: 2.25217
Total Iteration Time: 14.27641

Cumulative Model Updates: 5978
Cumulative Timesteps: 50176644

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395.76290
Policy Entropy: 0.15691
Value Function Loss: 2.56368

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.06010
Value Function Update Magnitude: 0.16198

Collected Steps per Second: 13441.02975
Overall Steps per Second: 2614.45358

Timestep Collection Time: 3.72263
Timestep Consumption Time: 15.41559
PPO Batch Consumption Time: 2.29272
Total Iteration Time: 19.13822

Cumulative Model Updates: 5984
Cumulative Timesteps: 50226680

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.02774
Policy Entropy: 0.15470
Value Function Loss: 2.48757

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.06374
Value Function Update Magnitude: 0.15991

Collected Steps per Second: 12723.00377
Overall Steps per Second: 2547.70296

Timestep Collection Time: 3.93728
Timestep Consumption Time: 15.72514
PPO Batch Consumption Time: 2.28101
Total Iteration Time: 19.66242

Cumulative Model Updates: 5990
Cumulative Timesteps: 50276774

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411.47612
Policy Entropy: 0.15230
Value Function Loss: 2.52873

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.06447
Value Function Update Magnitude: 0.15657

Collected Steps per Second: 13836.09864
Overall Steps per Second: 2567.71444

Timestep Collection Time: 3.61663
Timestep Consumption Time: 15.87152
PPO Batch Consumption Time: 2.31936
Total Iteration Time: 19.48815

Cumulative Model Updates: 5996
Cumulative Timesteps: 50326814

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366.14770
Policy Entropy: 0.15672
Value Function Loss: 2.55588

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.06123
Value Function Update Magnitude: 0.18538

Collected Steps per Second: 13949.95726
Overall Steps per Second: 2638.39015

Timestep Collection Time: 3.58725
Timestep Consumption Time: 15.37962
PPO Batch Consumption Time: 2.25871
Total Iteration Time: 18.96687

Cumulative Model Updates: 6002
Cumulative Timesteps: 50376856

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.14048
Policy Entropy: 0.15403
Value Function Loss: 2.54745

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.09852
Value Function Update Magnitude: 0.16167

Collected Steps per Second: 12707.28905
Overall Steps per Second: 2622.99806

Timestep Collection Time: 3.94136
Timestep Consumption Time: 15.15282
PPO Batch Consumption Time: 2.22697
Total Iteration Time: 19.09418

Cumulative Model Updates: 6008
Cumulative Timesteps: 50426940

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.13639
Policy Entropy: 0.15919
Value Function Loss: 2.52798

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10248
Policy Update Magnitude: 0.08525
Value Function Update Magnitude: 0.12780

Collected Steps per Second: 12664.91063
Overall Steps per Second: 2623.79299

Timestep Collection Time: 3.95344
Timestep Consumption Time: 15.12962
PPO Batch Consumption Time: 2.25597
Total Iteration Time: 19.08306

Cumulative Model Updates: 6014
Cumulative Timesteps: 50477010

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.45964
Policy Entropy: 0.15623
Value Function Loss: 2.51306

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12582
Policy Update Magnitude: 0.07938
Value Function Update Magnitude: 0.11105

Collected Steps per Second: 12644.94116
Overall Steps per Second: 2613.14352

Timestep Collection Time: 3.95415
Timestep Consumption Time: 15.17989
PPO Batch Consumption Time: 2.23014
Total Iteration Time: 19.13404

Cumulative Model Updates: 6020
Cumulative Timesteps: 50527010

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 50527010...
Checkpoint 50527010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.91812
Policy Entropy: 0.15694
Value Function Loss: 2.56243

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.06842
Value Function Update Magnitude: 0.11090

Collected Steps per Second: 12769.12309
Overall Steps per Second: 2563.04090

Timestep Collection Time: 3.92196
Timestep Consumption Time: 15.61733
PPO Batch Consumption Time: 2.28693
Total Iteration Time: 19.53929

Cumulative Model Updates: 6026
Cumulative Timesteps: 50577090

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.27776
Policy Entropy: 0.15354
Value Function Loss: 2.53583

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.06128
Value Function Update Magnitude: 0.11111

Collected Steps per Second: 13514.16502
Overall Steps per Second: 2575.08058

Timestep Collection Time: 3.70485
Timestep Consumption Time: 15.73842
PPO Batch Consumption Time: 2.30490
Total Iteration Time: 19.44328

Cumulative Model Updates: 6032
Cumulative Timesteps: 50627158

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.26756
Policy Entropy: 0.15308
Value Function Loss: 2.53244

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.05821
Value Function Update Magnitude: 0.12278

Collected Steps per Second: 14877.61279
Overall Steps per Second: 2607.96249

Timestep Collection Time: 3.36398
Timestep Consumption Time: 15.82648
PPO Batch Consumption Time: 2.32526
Total Iteration Time: 19.19046

Cumulative Model Updates: 6038
Cumulative Timesteps: 50677206

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.85449
Policy Entropy: 0.15186
Value Function Loss: 2.48882

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.06095
Value Function Update Magnitude: 0.10743

Collected Steps per Second: 14795.82892
Overall Steps per Second: 2658.04088

Timestep Collection Time: 3.37933
Timestep Consumption Time: 15.43152
PPO Batch Consumption Time: 2.30033
Total Iteration Time: 18.81085

Cumulative Model Updates: 6044
Cumulative Timesteps: 50727206

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.09550
Policy Entropy: 0.15129
Value Function Loss: 2.53830

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.14908

Collected Steps per Second: 15200.62671
Overall Steps per Second: 2638.31241

Timestep Collection Time: 3.29368
Timestep Consumption Time: 15.68284
PPO Batch Consumption Time: 2.27718
Total Iteration Time: 18.97652

Cumulative Model Updates: 6050
Cumulative Timesteps: 50777272

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.53956
Policy Entropy: 0.15092
Value Function Loss: 2.56938

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.05740
Value Function Update Magnitude: 0.15752

Collected Steps per Second: 12722.50141
Overall Steps per Second: 2593.78204

Timestep Collection Time: 3.93460
Timestep Consumption Time: 15.36463
PPO Batch Consumption Time: 2.26122
Total Iteration Time: 19.29923

Cumulative Model Updates: 6056
Cumulative Timesteps: 50827330

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.90862
Policy Entropy: 0.15187
Value Function Loss: 2.54471

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10066
Policy Update Magnitude: 0.06377
Value Function Update Magnitude: 0.16268

Collected Steps per Second: 13737.36226
Overall Steps per Second: 2639.18778

Timestep Collection Time: 3.64335
Timestep Consumption Time: 15.32082
PPO Batch Consumption Time: 2.26612
Total Iteration Time: 18.96417

Cumulative Model Updates: 6062
Cumulative Timesteps: 50877380

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.85698
Policy Entropy: 0.15295
Value Function Loss: 2.47127

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08904
Policy Update Magnitude: 0.06165
Value Function Update Magnitude: 0.19706

Collected Steps per Second: 15481.59956
Overall Steps per Second: 2706.61906

Timestep Collection Time: 3.23377
Timestep Consumption Time: 15.26310
PPO Batch Consumption Time: 2.22594
Total Iteration Time: 18.49688

Cumulative Model Updates: 6068
Cumulative Timesteps: 50927444

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 394.72043
Policy Entropy: 0.15448
Value Function Loss: 2.53912

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09556
Policy Update Magnitude: 0.07397
Value Function Update Magnitude: 0.18547

Collected Steps per Second: 13275.77997
Overall Steps per Second: 2546.80055

Timestep Collection Time: 3.77168
Timestep Consumption Time: 15.88907
PPO Batch Consumption Time: 2.35388
Total Iteration Time: 19.66075

Cumulative Model Updates: 6074
Cumulative Timesteps: 50977516

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375.48602
Policy Entropy: 0.15527
Value Function Loss: 2.54730

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.06427
Value Function Update Magnitude: 0.16934

Collected Steps per Second: 15687.04998
Overall Steps per Second: 2569.31248

Timestep Collection Time: 3.18747
Timestep Consumption Time: 16.27377
PPO Batch Consumption Time: 2.40073
Total Iteration Time: 19.46124

Cumulative Model Updates: 6080
Cumulative Timesteps: 51027518

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 51027518...
Checkpoint 51027518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528.00397
Policy Entropy: 0.15600
Value Function Loss: 2.51793

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.11934
Policy Update Magnitude: 0.05672
Value Function Update Magnitude: 0.16856

Collected Steps per Second: 14621.26421
Overall Steps per Second: 2568.49627

Timestep Collection Time: 3.42501
Timestep Consumption Time: 16.07200
PPO Batch Consumption Time: 2.39946
Total Iteration Time: 19.49701

Cumulative Model Updates: 6086
Cumulative Timesteps: 51077596

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 454.01871
Policy Entropy: 0.15500
Value Function Loss: 2.41457

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12092
Policy Update Magnitude: 0.05967
Value Function Update Magnitude: 0.19201

Collected Steps per Second: 13284.55984
Overall Steps per Second: 2560.63083

Timestep Collection Time: 3.77039
Timestep Consumption Time: 15.79041
PPO Batch Consumption Time: 2.30625
Total Iteration Time: 19.56080

Cumulative Model Updates: 6092
Cumulative Timesteps: 51127684

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409.81984
Policy Entropy: 0.15190
Value Function Loss: 2.50015

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.06516
Value Function Update Magnitude: 0.20243

Collected Steps per Second: 13840.02974
Overall Steps per Second: 2617.00789

Timestep Collection Time: 3.61372
Timestep Consumption Time: 15.49742
PPO Batch Consumption Time: 2.29566
Total Iteration Time: 19.11114

Cumulative Model Updates: 6098
Cumulative Timesteps: 51177698

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689.64040
Policy Entropy: 0.15217
Value Function Loss: 2.56570

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.07361
Value Function Update Magnitude: 0.20914

Collected Steps per Second: 13243.13294
Overall Steps per Second: 2613.11593

Timestep Collection Time: 3.77811
Timestep Consumption Time: 15.36915
PPO Batch Consumption Time: 2.27746
Total Iteration Time: 19.14726

Cumulative Model Updates: 6104
Cumulative Timesteps: 51227732

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 417.39385
Policy Entropy: 0.15173
Value Function Loss: 2.58379

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.10211
Policy Update Magnitude: 0.08157
Value Function Update Magnitude: 0.18453

Collected Steps per Second: 12679.56694
Overall Steps per Second: 2536.37591

Timestep Collection Time: 3.95155
Timestep Consumption Time: 15.80262
PPO Batch Consumption Time: 2.36208
Total Iteration Time: 19.75417

Cumulative Model Updates: 6110
Cumulative Timesteps: 51277836

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.25037
Policy Entropy: 0.15045
Value Function Loss: 2.54945

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08529
Policy Update Magnitude: 0.07854
Value Function Update Magnitude: 0.14204

Collected Steps per Second: 12684.68110
Overall Steps per Second: 2486.88513

Timestep Collection Time: 3.94208
Timestep Consumption Time: 16.16500
PPO Batch Consumption Time: 2.37024
Total Iteration Time: 20.10708

Cumulative Model Updates: 6116
Cumulative Timesteps: 51327840

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.95796
Policy Entropy: 0.14989
Value Function Loss: 2.51549

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.08050
Value Function Update Magnitude: 0.14179

Collected Steps per Second: 12569.63918
Overall Steps per Second: 836.13068

Timestep Collection Time: 3.97991
Timestep Consumption Time: 55.85045
PPO Batch Consumption Time: 2.30820
Total Iteration Time: 59.83036

Cumulative Model Updates: 6122
Cumulative Timesteps: 51377866

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.70398
Policy Entropy: 0.14977
Value Function Loss: 2.47753

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09939
Policy Update Magnitude: 0.07836
Value Function Update Magnitude: 0.14434

Collected Steps per Second: 15181.56071
Overall Steps per Second: 2654.79579

Timestep Collection Time: 3.29465
Timestep Consumption Time: 15.54597
PPO Batch Consumption Time: 2.26295
Total Iteration Time: 18.84062

Cumulative Model Updates: 6128
Cumulative Timesteps: 51427884

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.70583
Policy Entropy: 0.14787
Value Function Loss: 2.45793

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11497
Policy Update Magnitude: 0.06848
Value Function Update Magnitude: 0.15724

Collected Steps per Second: 13246.69760
Overall Steps per Second: 2473.93878

Timestep Collection Time: 3.77483
Timestep Consumption Time: 16.43748
PPO Batch Consumption Time: 2.42954
Total Iteration Time: 20.21230

Cumulative Model Updates: 6134
Cumulative Timesteps: 51477888

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705.93500
Policy Entropy: 0.14830
Value Function Loss: 2.47239

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11701
Policy Update Magnitude: 0.06672
Value Function Update Magnitude: 0.15057

Collected Steps per Second: 13985.98842
Overall Steps per Second: 2517.09059

Timestep Collection Time: 3.57529
Timestep Consumption Time: 16.29050
PPO Batch Consumption Time: 2.37892
Total Iteration Time: 19.86579

Cumulative Model Updates: 6140
Cumulative Timesteps: 51527892

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 51527892...
Checkpoint 51527892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.26345
Policy Entropy: 0.14561
Value Function Loss: 2.47331

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.15400
Policy Update Magnitude: 0.07327
Value Function Update Magnitude: 0.14122

Collected Steps per Second: 13436.59772
Overall Steps per Second: 2502.92140

Timestep Collection Time: 3.72475
Timestep Consumption Time: 16.27108
PPO Batch Consumption Time: 2.38908
Total Iteration Time: 19.99583

Cumulative Model Updates: 6146
Cumulative Timesteps: 51577940

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.92121
Policy Entropy: 0.14697
Value Function Loss: 2.51615

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11839
Policy Update Magnitude: 0.06220
Value Function Update Magnitude: 0.15500

Collected Steps per Second: 13324.55462
Overall Steps per Second: 2615.02264

Timestep Collection Time: 3.75382
Timestep Consumption Time: 15.37336
PPO Batch Consumption Time: 2.30086
Total Iteration Time: 19.12718

Cumulative Model Updates: 6152
Cumulative Timesteps: 51627958

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.09390
Policy Entropy: 0.14724
Value Function Loss: 2.53938

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.06348
Value Function Update Magnitude: 0.19045

Collected Steps per Second: 12867.62919
Overall Steps per Second: 2605.09219

Timestep Collection Time: 3.89178
Timestep Consumption Time: 15.33134
PPO Batch Consumption Time: 2.24810
Total Iteration Time: 19.22312

Cumulative Model Updates: 6158
Cumulative Timesteps: 51678036

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.13334
Policy Entropy: 0.14570
Value Function Loss: 2.56160

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.11049
Policy Update Magnitude: 0.06224
Value Function Update Magnitude: 0.19645

Collected Steps per Second: 12675.73883
Overall Steps per Second: 2582.49797

Timestep Collection Time: 3.94565
Timestep Consumption Time: 15.42087
PPO Batch Consumption Time: 2.29809
Total Iteration Time: 19.36652

Cumulative Model Updates: 6164
Cumulative Timesteps: 51728050

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.81179
Policy Entropy: 0.14357
Value Function Loss: 2.51075

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.11145
Policy Update Magnitude: 0.05985
Value Function Update Magnitude: 0.16285

Collected Steps per Second: 12833.40291
Overall Steps per Second: 2609.92591

Timestep Collection Time: 3.90060
Timestep Consumption Time: 15.27925
PPO Batch Consumption Time: 2.24436
Total Iteration Time: 19.17985

Cumulative Model Updates: 6170
Cumulative Timesteps: 51778108

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.84651
Policy Entropy: 0.14385
Value Function Loss: 2.48184

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10346
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.14989

Collected Steps per Second: 16262.51940
Overall Steps per Second: 2620.28344

Timestep Collection Time: 3.07665
Timestep Consumption Time: 16.01824
PPO Batch Consumption Time: 2.38279
Total Iteration Time: 19.09488

Cumulative Model Updates: 6176
Cumulative Timesteps: 51828142

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.50667
Policy Entropy: 0.14294
Value Function Loss: 2.43214

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.06487
Value Function Update Magnitude: 0.13680

Collected Steps per Second: 13408.31753
Overall Steps per Second: 2526.29892

Timestep Collection Time: 3.73037
Timestep Consumption Time: 16.06855
PPO Batch Consumption Time: 2.36009
Total Iteration Time: 19.79892

Cumulative Model Updates: 6182
Cumulative Timesteps: 51878160

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.18782
Policy Entropy: 0.14216
Value Function Loss: 2.43268

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10531
Policy Update Magnitude: 0.07378
Value Function Update Magnitude: 0.13987

Collected Steps per Second: 13921.34205
Overall Steps per Second: 2557.73877

Timestep Collection Time: 3.59290
Timestep Consumption Time: 15.96265
PPO Batch Consumption Time: 2.37050
Total Iteration Time: 19.55555

Cumulative Model Updates: 6188
Cumulative Timesteps: 51928178

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361.05388
Policy Entropy: 0.13999
Value Function Loss: 2.37467

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.08347
Value Function Update Magnitude: 0.15336

Collected Steps per Second: 14139.71825
Overall Steps per Second: 2529.33947

Timestep Collection Time: 3.53996
Timestep Consumption Time: 16.24940
PPO Batch Consumption Time: 2.36589
Total Iteration Time: 19.78936

Cumulative Model Updates: 6194
Cumulative Timesteps: 51978232

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 771.43137
Policy Entropy: 0.13750
Value Function Loss: 2.42175

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08295
Policy Update Magnitude: 0.08376
Value Function Update Magnitude: 0.16208

Collected Steps per Second: 13049.16720
Overall Steps per Second: 2584.97755

Timestep Collection Time: 3.83442
Timestep Consumption Time: 15.52203
PPO Batch Consumption Time: 2.26220
Total Iteration Time: 19.35645

Cumulative Model Updates: 6200
Cumulative Timesteps: 52028268

Timesteps Collected: 50036
--------END ITERATION REPORT--------


Saving checkpoint 52028268...
Checkpoint 52028268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.31658
Policy Entropy: 0.13763
Value Function Loss: 2.41651

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12311
Policy Update Magnitude: 0.09370
Value Function Update Magnitude: 0.15416

Collected Steps per Second: 12567.01812
Overall Steps per Second: 2586.34406

Timestep Collection Time: 3.97867
Timestep Consumption Time: 15.35364
PPO Batch Consumption Time: 2.29136
Total Iteration Time: 19.33231

Cumulative Model Updates: 6206
Cumulative Timesteps: 52078268

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.01484
Policy Entropy: 0.13705
Value Function Loss: 2.49233

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11404
Policy Update Magnitude: 0.07676
Value Function Update Magnitude: 0.14018

Collected Steps per Second: 12706.80431
Overall Steps per Second: 2594.69436

Timestep Collection Time: 3.93836
Timestep Consumption Time: 15.34869
PPO Batch Consumption Time: 2.25389
Total Iteration Time: 19.28705

Cumulative Model Updates: 6212
Cumulative Timesteps: 52128312

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 497.21763
Policy Entropy: 0.13661
Value Function Loss: 2.47513

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.07444
Value Function Update Magnitude: 0.13620

Collected Steps per Second: 12430.66927
Overall Steps per Second: 2578.24968

Timestep Collection Time: 4.02698
Timestep Consumption Time: 15.38852
PPO Batch Consumption Time: 2.24835
Total Iteration Time: 19.41550

Cumulative Model Updates: 6218
Cumulative Timesteps: 52178370

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.99215
Policy Entropy: 0.13433
Value Function Loss: 2.48299

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.08483
Value Function Update Magnitude: 0.16499

Collected Steps per Second: 15326.87269
Overall Steps per Second: 2582.01085

Timestep Collection Time: 3.26251
Timestep Consumption Time: 16.10380
PPO Batch Consumption Time: 2.34832
Total Iteration Time: 19.36630

Cumulative Model Updates: 6224
Cumulative Timesteps: 52228374

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614.33626
Policy Entropy: 0.13519
Value Function Loss: 2.41355

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13770
Policy Update Magnitude: 0.08116
Value Function Update Magnitude: 0.20939

Collected Steps per Second: 12983.36908
Overall Steps per Second: 2512.04410

Timestep Collection Time: 3.85663
Timestep Consumption Time: 16.07615
PPO Batch Consumption Time: 2.38082
Total Iteration Time: 19.93277

Cumulative Model Updates: 6230
Cumulative Timesteps: 52278446

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 399.65491
Policy Entropy: 0.13362
Value Function Loss: 2.41349

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10757
Policy Update Magnitude: 0.07745
Value Function Update Magnitude: 0.21378

Collected Steps per Second: 13437.55937
Overall Steps per Second: 2527.87441

Timestep Collection Time: 3.72791
Timestep Consumption Time: 16.08874
PPO Batch Consumption Time: 2.39517
Total Iteration Time: 19.81665

Cumulative Model Updates: 6236
Cumulative Timesteps: 52328540

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.87372
Policy Entropy: 0.13321
Value Function Loss: 2.36022

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11920
Policy Update Magnitude: 0.07123
Value Function Update Magnitude: 0.19969

Collected Steps per Second: 15439.28975
Overall Steps per Second: 2571.82693

Timestep Collection Time: 3.24367
Timestep Consumption Time: 16.22887
PPO Batch Consumption Time: 2.37214
Total Iteration Time: 19.47254

Cumulative Model Updates: 6242
Cumulative Timesteps: 52378620

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453.02112
Policy Entropy: 0.13011
Value Function Loss: 2.46629

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.07111
Value Function Update Magnitude: 0.21225

Collected Steps per Second: 15262.35181
Overall Steps per Second: 2616.11527

Timestep Collection Time: 3.28101
Timestep Consumption Time: 15.86034
PPO Batch Consumption Time: 2.35303
Total Iteration Time: 19.14136

Cumulative Model Updates: 6248
Cumulative Timesteps: 52428696

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505.55322
Policy Entropy: 0.12976
Value Function Loss: 2.47271

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.07240
Value Function Update Magnitude: 0.21565

Collected Steps per Second: 13473.58495
Overall Steps per Second: 2545.27381

Timestep Collection Time: 3.71319
Timestep Consumption Time: 15.94285
PPO Batch Consumption Time: 2.33663
Total Iteration Time: 19.65604

Cumulative Model Updates: 6254
Cumulative Timesteps: 52478726

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342.03346
Policy Entropy: 0.12745
Value Function Loss: 2.49363

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.16890
Policy Update Magnitude: 0.07025
Value Function Update Magnitude: 0.20622

Collected Steps per Second: 12857.92454
Overall Steps per Second: 2644.15317

Timestep Collection Time: 3.89130
Timestep Consumption Time: 15.03121
PPO Batch Consumption Time: 2.24878
Total Iteration Time: 18.92250

Cumulative Model Updates: 6260
Cumulative Timesteps: 52528760

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 52528760...
Checkpoint 52528760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.80616
Policy Entropy: 0.12597
Value Function Loss: 2.47501

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.27447
Policy Update Magnitude: 0.06544
Value Function Update Magnitude: 0.15440

Collected Steps per Second: 12704.92291
Overall Steps per Second: 2526.22259

Timestep Collection Time: 3.93580
Timestep Consumption Time: 15.85818
PPO Batch Consumption Time: 2.32481
Total Iteration Time: 19.79398

Cumulative Model Updates: 6266
Cumulative Timesteps: 52578764

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.06355
Policy Entropy: 0.12500
Value Function Loss: 2.45303

Mean KL Divergence: 0.02029
SB3 Clip Fraction: 0.23696
Policy Update Magnitude: 0.04621
Value Function Update Magnitude: 0.13793

Collected Steps per Second: 13030.70338
Overall Steps per Second: 2564.99198

Timestep Collection Time: 3.83878
Timestep Consumption Time: 15.66304
PPO Batch Consumption Time: 2.30454
Total Iteration Time: 19.50182

Cumulative Model Updates: 6272
Cumulative Timesteps: 52628786

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.42920
Policy Entropy: 0.12383
Value Function Loss: 2.49740

Mean KL Divergence: 0.02130
SB3 Clip Fraction: 0.24550
Policy Update Magnitude: 0.03812
Value Function Update Magnitude: 0.14120

Collected Steps per Second: 13575.85894
Overall Steps per Second: 2514.89838

Timestep Collection Time: 3.68448
Timestep Consumption Time: 16.20499
PPO Batch Consumption Time: 2.38098
Total Iteration Time: 19.88947

Cumulative Model Updates: 6278
Cumulative Timesteps: 52678806

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 383.20852
Policy Entropy: 0.12100
Value Function Loss: 2.46438

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.05759
Value Function Update Magnitude: 0.18636

Collected Steps per Second: 14402.80001
Overall Steps per Second: 2533.84272

Timestep Collection Time: 3.47530
Timestep Consumption Time: 16.27889
PPO Batch Consumption Time: 2.38447
Total Iteration Time: 19.75419

Cumulative Model Updates: 6284
Cumulative Timesteps: 52728860

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.85755
Policy Entropy: 0.11991
Value Function Loss: 2.42311

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.06531
Value Function Update Magnitude: 0.19062

Collected Steps per Second: 14375.33514
Overall Steps per Second: 2589.42601

Timestep Collection Time: 3.47818
Timestep Consumption Time: 15.83112
PPO Batch Consumption Time: 2.36617
Total Iteration Time: 19.30930

Cumulative Model Updates: 6290
Cumulative Timesteps: 52778860

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 374.02979
Policy Entropy: 0.12050
Value Function Loss: 2.42536

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.06205
Value Function Update Magnitude: 0.19086

Collected Steps per Second: 13782.89732
Overall Steps per Second: 2556.71805

Timestep Collection Time: 3.63349
Timestep Consumption Time: 15.95412
PPO Batch Consumption Time: 2.33769
Total Iteration Time: 19.58761

Cumulative Model Updates: 6296
Cumulative Timesteps: 52828940

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 519.90931
Policy Entropy: 0.12184
Value Function Loss: 2.42957

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11341
Policy Update Magnitude: 0.06127
Value Function Update Magnitude: 0.17815

Collected Steps per Second: 13051.55984
Overall Steps per Second: 2522.07684

Timestep Collection Time: 3.83157
Timestep Consumption Time: 15.99653
PPO Batch Consumption Time: 2.38059
Total Iteration Time: 19.82810

Cumulative Model Updates: 6302
Cumulative Timesteps: 52878948

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.01767
Policy Entropy: 0.12040
Value Function Loss: 2.51297

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.05717
Value Function Update Magnitude: 0.14457

Collected Steps per Second: 17763.20121
Overall Steps per Second: 2628.16367

Timestep Collection Time: 2.81548
Timestep Consumption Time: 16.21377
PPO Batch Consumption Time: 2.38094
Total Iteration Time: 19.02926

Cumulative Model Updates: 6308
Cumulative Timesteps: 52928960

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.17267
Policy Entropy: 0.11982
Value Function Loss: 2.45780

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.04891
Value Function Update Magnitude: 0.10033

Collected Steps per Second: 13339.59427
Overall Steps per Second: 2488.74472

Timestep Collection Time: 3.75604
Timestep Consumption Time: 16.37620
PPO Batch Consumption Time: 2.41330
Total Iteration Time: 20.13224

Cumulative Model Updates: 6314
Cumulative Timesteps: 52979064

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.39951
Policy Entropy: 0.11831
Value Function Loss: 2.50403

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.08536

Collected Steps per Second: 15342.96315
Overall Steps per Second: 2504.63830

Timestep Collection Time: 3.26247
Timestep Consumption Time: 16.72285
PPO Batch Consumption Time: 2.49059
Total Iteration Time: 19.98532

Cumulative Model Updates: 6320
Cumulative Timesteps: 53029120

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 53029120...
Checkpoint 53029120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661.75951
Policy Entropy: 0.11750
Value Function Loss: 2.58200

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.05088
Value Function Update Magnitude: 0.07639

Collected Steps per Second: 14702.70451
Overall Steps per Second: 2570.90826

Timestep Collection Time: 3.40400
Timestep Consumption Time: 16.06305
PPO Batch Consumption Time: 2.35297
Total Iteration Time: 19.46705

Cumulative Model Updates: 6326
Cumulative Timesteps: 53079168

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329.86600
Policy Entropy: 0.11707
Value Function Loss: 2.60237

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.07742

Collected Steps per Second: 12658.48552
Overall Steps per Second: 2556.43429

Timestep Collection Time: 3.95466
Timestep Consumption Time: 15.62730
PPO Batch Consumption Time: 2.32734
Total Iteration Time: 19.58196

Cumulative Model Updates: 6332
Cumulative Timesteps: 53129228

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.60516
Policy Entropy: 0.11783
Value Function Loss: 2.53840

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.05592
Value Function Update Magnitude: 0.07919

Collected Steps per Second: 13070.84022
Overall Steps per Second: 2576.17606

Timestep Collection Time: 3.82577
Timestep Consumption Time: 15.58517
PPO Batch Consumption Time: 2.28764
Total Iteration Time: 19.41094

Cumulative Model Updates: 6338
Cumulative Timesteps: 53179234

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.13741
Policy Entropy: 0.11668
Value Function Loss: 2.49702

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11862
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.07840

Collected Steps per Second: 12744.98702
Overall Steps per Second: 2597.07269

Timestep Collection Time: 3.92452
Timestep Consumption Time: 15.33485
PPO Batch Consumption Time: 2.24714
Total Iteration Time: 19.25938

Cumulative Model Updates: 6344
Cumulative Timesteps: 53229252

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691.81710
Policy Entropy: 0.11682
Value Function Loss: 2.51343

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.05597
Value Function Update Magnitude: 0.08211

Collected Steps per Second: 13477.06244
Overall Steps per Second: 2525.44661

Timestep Collection Time: 3.71268
Timestep Consumption Time: 16.10005
PPO Batch Consumption Time: 2.36794
Total Iteration Time: 19.81273

Cumulative Model Updates: 6350
Cumulative Timesteps: 53279288

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.28997
Policy Entropy: 0.11275
Value Function Loss: 2.55108

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.07280
Value Function Update Magnitude: 0.08246

Collected Steps per Second: 13604.80930
Overall Steps per Second: 2532.31565

Timestep Collection Time: 3.67723
Timestep Consumption Time: 16.07860
PPO Batch Consumption Time: 2.35901
Total Iteration Time: 19.75583

Cumulative Model Updates: 6356
Cumulative Timesteps: 53329316

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367.68604
Policy Entropy: 0.11243
Value Function Loss: 2.54424

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.06240
Value Function Update Magnitude: 0.08358

Collected Steps per Second: 14496.12893
Overall Steps per Second: 2573.76804

Timestep Collection Time: 3.45499
Timestep Consumption Time: 16.00442
PPO Batch Consumption Time: 2.39078
Total Iteration Time: 19.45941

Cumulative Model Updates: 6362
Cumulative Timesteps: 53379400

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 814.88436
Policy Entropy: 0.10878
Value Function Loss: 2.58792

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.05796
Value Function Update Magnitude: 0.08600

Collected Steps per Second: 13418.01300
Overall Steps per Second: 2537.59698

Timestep Collection Time: 3.73289
Timestep Consumption Time: 16.00547
PPO Batch Consumption Time: 2.34746
Total Iteration Time: 19.73836

Cumulative Model Updates: 6368
Cumulative Timesteps: 53429488

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404.33674
Policy Entropy: 0.10473
Value Function Loss: 2.49276

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.11559
Policy Update Magnitude: 0.05157
Value Function Update Magnitude: 0.10393

Collected Steps per Second: 15721.58554
Overall Steps per Second: 2658.57661

Timestep Collection Time: 3.18568
Timestep Consumption Time: 15.65297
PPO Batch Consumption Time: 2.29848
Total Iteration Time: 18.83865

Cumulative Model Updates: 6374
Cumulative Timesteps: 53479572

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634.54953
Policy Entropy: 0.10339
Value Function Loss: 2.40497

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.15514
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.10226

Collected Steps per Second: 13254.29870
Overall Steps per Second: 2541.99869

Timestep Collection Time: 3.77628
Timestep Consumption Time: 15.91373
PPO Batch Consumption Time: 2.35994
Total Iteration Time: 19.69002

Cumulative Model Updates: 6380
Cumulative Timesteps: 53529624

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 53529624...
Checkpoint 53529624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 868.10033
Policy Entropy: 0.10071
Value Function Loss: 2.29292

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.16061
Policy Update Magnitude: 0.05771
Value Function Update Magnitude: 0.09622

Collected Steps per Second: 15995.47629
Overall Steps per Second: 2576.68669

Timestep Collection Time: 3.12838
Timestep Consumption Time: 16.29190
PPO Batch Consumption Time: 2.38724
Total Iteration Time: 19.42029

Cumulative Model Updates: 6386
Cumulative Timesteps: 53579664

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459.51947
Policy Entropy: 0.09989
Value Function Loss: 2.35872

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.18611
Policy Update Magnitude: 0.04710
Value Function Update Magnitude: 0.08267

Collected Steps per Second: 14610.23580
Overall Steps per Second: 2556.97533

Timestep Collection Time: 3.42828
Timestep Consumption Time: 16.16049
PPO Batch Consumption Time: 2.40373
Total Iteration Time: 19.58877

Cumulative Model Updates: 6392
Cumulative Timesteps: 53629752

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481.73418
Policy Entropy: 0.09804
Value Function Loss: 2.41654

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.04941
Value Function Update Magnitude: 0.11397

Collected Steps per Second: 15025.86245
Overall Steps per Second: 2559.85165

Timestep Collection Time: 3.33225
Timestep Consumption Time: 16.22747
PPO Batch Consumption Time: 2.37657
Total Iteration Time: 19.55973

Cumulative Model Updates: 6398
Cumulative Timesteps: 53679822

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.71883
Policy Entropy: 0.09468
Value Function Loss: 2.46827

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09346
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.16782

Collected Steps per Second: 15208.09270
Overall Steps per Second: 2616.60597

Timestep Collection Time: 3.29298
Timestep Consumption Time: 15.84631
PPO Batch Consumption Time: 2.35835
Total Iteration Time: 19.13930

Cumulative Model Updates: 6404
Cumulative Timesteps: 53729902

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.43906
Policy Entropy: 0.09003
Value Function Loss: 2.41574

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14689
Policy Update Magnitude: 0.05921
Value Function Update Magnitude: 0.15294

Collected Steps per Second: 13167.03579
Overall Steps per Second: 2569.80706

Timestep Collection Time: 3.80420
Timestep Consumption Time: 15.68754
PPO Batch Consumption Time: 2.29615
Total Iteration Time: 19.49174

Cumulative Model Updates: 6410
Cumulative Timesteps: 53779992

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.32682
Policy Entropy: 0.09093
Value Function Loss: 2.42783

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11888
Policy Update Magnitude: 0.05846
Value Function Update Magnitude: 0.19362

Collected Steps per Second: 13138.98077
Overall Steps per Second: 2606.78972

Timestep Collection Time: 3.80821
Timestep Consumption Time: 15.38628
PPO Batch Consumption Time: 2.27407
Total Iteration Time: 19.19449

Cumulative Model Updates: 6416
Cumulative Timesteps: 53830028

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.34711
Policy Entropy: 0.09101
Value Function Loss: 2.40010

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12403
Policy Update Magnitude: 0.05392
Value Function Update Magnitude: 0.19868

Collected Steps per Second: 13465.88545
Overall Steps per Second: 2573.32348

Timestep Collection Time: 3.71621
Timestep Consumption Time: 15.73024
PPO Batch Consumption Time: 2.30697
Total Iteration Time: 19.44645

Cumulative Model Updates: 6422
Cumulative Timesteps: 53880070

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.73658
Policy Entropy: 0.09095
Value Function Loss: 2.49880

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11716
Policy Update Magnitude: 0.05538
Value Function Update Magnitude: 0.16757

Collected Steps per Second: 12387.04914
Overall Steps per Second: 2495.90921

Timestep Collection Time: 4.03664
Timestep Consumption Time: 15.99695
PPO Batch Consumption Time: 2.35960
Total Iteration Time: 20.03358

Cumulative Model Updates: 6428
Cumulative Timesteps: 53930072

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.35054
Policy Entropy: 0.09141
Value Function Loss: 2.54955

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.11021
Policy Update Magnitude: 0.05596
Value Function Update Magnitude: 0.15212

Collected Steps per Second: 14475.80164
Overall Steps per Second: 2610.92277

Timestep Collection Time: 3.45667
Timestep Consumption Time: 15.70821
PPO Batch Consumption Time: 2.34393
Total Iteration Time: 19.16487

Cumulative Model Updates: 6434
Cumulative Timesteps: 53980110

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.05045
Policy Entropy: 0.08950
Value Function Loss: 2.56478

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10496
Policy Update Magnitude: 0.06295
Value Function Update Magnitude: 0.16932

Collected Steps per Second: 15366.45393
Overall Steps per Second: 2567.56396

Timestep Collection Time: 3.25866
Timestep Consumption Time: 16.24388
PPO Batch Consumption Time: 2.37781
Total Iteration Time: 19.50253

Cumulative Model Updates: 6440
Cumulative Timesteps: 54030184

Timesteps Collected: 50074
--------END ITERATION REPORT--------


Saving checkpoint 54030184...
Checkpoint 54030184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.55248
Policy Entropy: 0.08983
Value Function Loss: 2.49666

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.11059
Policy Update Magnitude: 0.06173
Value Function Update Magnitude: 0.17106

Collected Steps per Second: 15055.35963
Overall Steps per Second: 2577.77413

Timestep Collection Time: 3.32333
Timestep Consumption Time: 16.08643
PPO Batch Consumption Time: 2.37358
Total Iteration Time: 19.40977

Cumulative Model Updates: 6446
Cumulative Timesteps: 54080218

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484.17640
Policy Entropy: 0.08925
Value Function Loss: 2.49958

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.07101
Value Function Update Magnitude: 0.15681

Collected Steps per Second: 14185.92946
Overall Steps per Second: 2552.98299

Timestep Collection Time: 3.52476
Timestep Consumption Time: 16.06096
PPO Batch Consumption Time: 2.35672
Total Iteration Time: 19.58572

Cumulative Model Updates: 6452
Cumulative Timesteps: 54130220

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.25261
Policy Entropy: 0.08716
Value Function Loss: 2.51044

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11740
Policy Update Magnitude: 0.06538
Value Function Update Magnitude: 0.13522

Collected Steps per Second: 12943.66517
Overall Steps per Second: 2524.98170

Timestep Collection Time: 3.86784
Timestep Consumption Time: 15.95963
PPO Batch Consumption Time: 2.36501
Total Iteration Time: 19.82747

Cumulative Model Updates: 6458
Cumulative Timesteps: 54180284

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510.92551
Policy Entropy: 0.08746
Value Function Loss: 2.54481

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.05970
Value Function Update Magnitude: 0.12734

Collected Steps per Second: 14891.46769
Overall Steps per Second: 2602.72118

Timestep Collection Time: 3.36072
Timestep Consumption Time: 15.86762
PPO Batch Consumption Time: 2.36463
Total Iteration Time: 19.22834

Cumulative Model Updates: 6464
Cumulative Timesteps: 54230330

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.46295
Policy Entropy: 0.08594
Value Function Loss: 2.52867

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.05204
Value Function Update Magnitude: 0.13278

Collected Steps per Second: 12678.87581
Overall Steps per Second: 2535.89024

Timestep Collection Time: 3.94735
Timestep Consumption Time: 15.78852
PPO Batch Consumption Time: 2.30810
Total Iteration Time: 19.73587

Cumulative Model Updates: 6470
Cumulative Timesteps: 54280378

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444.62601
Policy Entropy: 0.08508
Value Function Loss: 2.55060

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.04665
Value Function Update Magnitude: 0.13453

Collected Steps per Second: 12660.67690
Overall Steps per Second: 2539.90704

Timestep Collection Time: 3.95587
Timestep Consumption Time: 15.76296
PPO Batch Consumption Time: 2.35228
Total Iteration Time: 19.71883

Cumulative Model Updates: 6476
Cumulative Timesteps: 54330462

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684.31752
Policy Entropy: 0.08691
Value Function Loss: 2.59164

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14097
Policy Update Magnitude: 0.04494
Value Function Update Magnitude: 0.14132

Collected Steps per Second: 12931.91455
Overall Steps per Second: 2531.32944

Timestep Collection Time: 3.86888
Timestep Consumption Time: 15.89623
PPO Batch Consumption Time: 2.33486
Total Iteration Time: 19.76511

Cumulative Model Updates: 6482
Cumulative Timesteps: 54380494

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.61069
Policy Entropy: 0.08523
Value Function Loss: 2.53594

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12310
Policy Update Magnitude: 0.05265
Value Function Update Magnitude: 0.12972

Collected Steps per Second: 12583.12061
Overall Steps per Second: 2499.56345

Timestep Collection Time: 3.98041
Timestep Consumption Time: 16.05749
PPO Batch Consumption Time: 2.36935
Total Iteration Time: 20.03790

Cumulative Model Updates: 6488
Cumulative Timesteps: 54430580

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384.84397
Policy Entropy: 0.08493
Value Function Loss: 2.45188

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12698
Policy Update Magnitude: 0.06619
Value Function Update Magnitude: 0.13530

Collected Steps per Second: 13413.58562
Overall Steps per Second: 2537.39117

Timestep Collection Time: 3.73114
Timestep Consumption Time: 15.99305
PPO Batch Consumption Time: 2.35174
Total Iteration Time: 19.72420

Cumulative Model Updates: 6494
Cumulative Timesteps: 54480628

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607.31687
Policy Entropy: 0.08241
Value Function Loss: 2.45087

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 0.06865
Value Function Update Magnitude: 0.14200

Collected Steps per Second: 13388.42658
Overall Steps per Second: 2511.94118

Timestep Collection Time: 3.73711
Timestep Consumption Time: 16.18135
PPO Batch Consumption Time: 2.37688
Total Iteration Time: 19.91846

Cumulative Model Updates: 6500
Cumulative Timesteps: 54530662

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 54530662...
Checkpoint 54530662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 760.30099
Policy Entropy: 0.08237
Value Function Loss: 2.53318

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.13954
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.14691

Collected Steps per Second: 14839.45871
Overall Steps per Second: 2610.58123

Timestep Collection Time: 3.37101
Timestep Consumption Time: 15.79100
PPO Batch Consumption Time: 2.35735
Total Iteration Time: 19.16202

Cumulative Model Updates: 6506
Cumulative Timesteps: 54580686

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393.41857
Policy Entropy: 0.08314
Value Function Loss: 2.53090

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14007
Policy Update Magnitude: 0.05504
Value Function Update Magnitude: 0.15326

Collected Steps per Second: 16650.75070
Overall Steps per Second: 2581.76225

Timestep Collection Time: 3.00683
Timestep Consumption Time: 16.38535
PPO Batch Consumption Time: 2.40430
Total Iteration Time: 19.39218

Cumulative Model Updates: 6512
Cumulative Timesteps: 54630752

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.68173
Policy Entropy: 0.08204
Value Function Loss: 2.54649

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12136
Policy Update Magnitude: 0.05686
Value Function Update Magnitude: 0.18214

Collected Steps per Second: 16053.70292
Overall Steps per Second: 2622.31791

Timestep Collection Time: 3.11916
Timestep Consumption Time: 15.97616
PPO Batch Consumption Time: 2.38900
Total Iteration Time: 19.09532

Cumulative Model Updates: 6518
Cumulative Timesteps: 54680826

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.34375
Policy Entropy: 0.07979
Value Function Loss: 2.51824

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12290
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.18721

Collected Steps per Second: 16084.59415
Overall Steps per Second: 2563.24452

Timestep Collection Time: 3.11292
Timestep Consumption Time: 16.42092
PPO Batch Consumption Time: 2.38903
Total Iteration Time: 19.53384

Cumulative Model Updates: 6524
Cumulative Timesteps: 54730896

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.16478
Policy Entropy: 0.08292
Value Function Loss: 2.56637

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.05516
Value Function Update Magnitude: 0.18076

Collected Steps per Second: 13774.45515
Overall Steps per Second: 2552.89133

Timestep Collection Time: 3.63107
Timestep Consumption Time: 15.96083
PPO Batch Consumption Time: 2.35695
Total Iteration Time: 19.59190

Cumulative Model Updates: 6530
Cumulative Timesteps: 54780912

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539.17025
Policy Entropy: 0.08250
Value Function Loss: 2.54366

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14246
Policy Update Magnitude: 0.05329
Value Function Update Magnitude: 0.17325

Collected Steps per Second: 17178.10485
Overall Steps per Second: 2624.57298

Timestep Collection Time: 2.91557
Timestep Consumption Time: 16.16715
PPO Batch Consumption Time: 2.36480
Total Iteration Time: 19.08272

Cumulative Model Updates: 6536
Cumulative Timesteps: 54830996

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.04636
Policy Entropy: 0.08285
Value Function Loss: 2.58442

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.13100

Collected Steps per Second: 12644.91548
Overall Steps per Second: 2533.65088

Timestep Collection Time: 3.95875
Timestep Consumption Time: 15.79852
PPO Batch Consumption Time: 2.32850
Total Iteration Time: 19.75726

Cumulative Model Updates: 6542
Cumulative Timesteps: 54881054

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.76398
Policy Entropy: 0.08048
Value Function Loss: 2.56784

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.06282
Value Function Update Magnitude: 0.11694

Collected Steps per Second: 12662.39723
Overall Steps per Second: 1701.45314

Timestep Collection Time: 3.95407
Timestep Consumption Time: 25.47254
PPO Batch Consumption Time: 2.43035
Total Iteration Time: 29.42661

Cumulative Model Updates: 6548
Cumulative Timesteps: 54931122

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609.59014
Policy Entropy: 0.07992
Value Function Loss: 2.57030

Mean KL Divergence: 0.02925
SB3 Clip Fraction: 0.32310
Policy Update Magnitude: 0.06163
Value Function Update Magnitude: 0.11058

Collected Steps per Second: 13055.59273
Overall Steps per Second: 2530.96359

Timestep Collection Time: 3.83575
Timestep Consumption Time: 15.95039
PPO Batch Consumption Time: 2.34499
Total Iteration Time: 19.78614

Cumulative Model Updates: 6554
Cumulative Timesteps: 54981200

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.08466
Policy Entropy: 0.08047
Value Function Loss: 2.60115

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.21155
Policy Update Magnitude: 0.04226
Value Function Update Magnitude: 0.12379

Collected Steps per Second: 14099.71539
Overall Steps per Second: 2585.48816

Timestep Collection Time: 3.54887
Timestep Consumption Time: 15.80454
PPO Batch Consumption Time: 2.35843
Total Iteration Time: 19.35341

Cumulative Model Updates: 6560
Cumulative Timesteps: 55031238

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 55031238...
Checkpoint 55031238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358.18197
Policy Entropy: 0.08123
Value Function Loss: 2.64348

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.15016
Policy Update Magnitude: 0.04453
Value Function Update Magnitude: 0.12882

Collected Steps per Second: 12669.35973
Overall Steps per Second: 2456.72216

Timestep Collection Time: 3.95158
Timestep Consumption Time: 16.42679
PPO Batch Consumption Time: 2.41793
Total Iteration Time: 20.37837

Cumulative Model Updates: 6566
Cumulative Timesteps: 55081302

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.99608
Policy Entropy: 0.07688
Value Function Loss: 2.63579

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.07986
Value Function Update Magnitude: 0.13015

Collected Steps per Second: 12634.10497
Overall Steps per Second: 983.80332

Timestep Collection Time: 3.96055
Timestep Consumption Time: 46.90124
PPO Batch Consumption Time: 2.35851
Total Iteration Time: 50.86179

Cumulative Model Updates: 6572
Cumulative Timesteps: 55131340

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.09503
Policy Entropy: 0.07575
Value Function Loss: 2.51891

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.16862
Policy Update Magnitude: 0.09369
Value Function Update Magnitude: 0.17927

Collected Steps per Second: 13129.39188
Overall Steps per Second: 2489.50470

Timestep Collection Time: 3.81099
Timestep Consumption Time: 16.28779
PPO Batch Consumption Time: 2.39884
Total Iteration Time: 20.09878

Cumulative Model Updates: 6578
Cumulative Timesteps: 55181376

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.06631
Policy Entropy: 0.07667
Value Function Loss: 2.41694

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14802
Policy Update Magnitude: 0.06694
Value Function Update Magnitude: 0.15682

Collected Steps per Second: 12683.71486
Overall Steps per Second: 2116.85830

Timestep Collection Time: 3.94805
Timestep Consumption Time: 19.70776
PPO Batch Consumption Time: 2.41672
Total Iteration Time: 23.65581

Cumulative Model Updates: 6584
Cumulative Timesteps: 55231452

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.72044
Policy Entropy: 0.07544
Value Function Loss: 2.43340

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.15140
Policy Update Magnitude: 0.06785
Value Function Update Magnitude: 0.16568

Collected Steps per Second: 13603.60929
Overall Steps per Second: 2496.47382

Timestep Collection Time: 3.67770
Timestep Consumption Time: 16.36257
PPO Batch Consumption Time: 2.40727
Total Iteration Time: 20.04027

Cumulative Model Updates: 6590
Cumulative Timesteps: 55281482

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657.22081
Policy Entropy: 0.07739
Value Function Loss: 2.49973

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.06415
Value Function Update Magnitude: 0.14920

Collected Steps per Second: 13026.08370
Overall Steps per Second: 2065.81355

Timestep Collection Time: 3.84060
Timestep Consumption Time: 20.37649
PPO Batch Consumption Time: 2.44896
Total Iteration Time: 24.21709

Cumulative Model Updates: 6596
Cumulative Timesteps: 55331510

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.92572
Policy Entropy: 0.07466
Value Function Loss: 2.56270

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.20425
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.13830

Collected Steps per Second: 12837.15137
Overall Steps per Second: 2484.86804

Timestep Collection Time: 3.89635
Timestep Consumption Time: 16.23269
PPO Batch Consumption Time: 2.43018
Total Iteration Time: 20.12904

Cumulative Model Updates: 6602
Cumulative Timesteps: 55381528

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428.90471
Policy Entropy: 0.07409
Value Function Loss: 2.53127

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.05654
Value Function Update Magnitude: 0.12773

Collected Steps per Second: 12965.81040
Overall Steps per Second: 844.81487

Timestep Collection Time: 3.85691
Timestep Consumption Time: 55.33712
PPO Batch Consumption Time: 2.39192
Total Iteration Time: 59.19403

Cumulative Model Updates: 6608
Cumulative Timesteps: 55431536

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.67291
Policy Entropy: 0.07341
Value Function Loss: 2.55506

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.20937
Policy Update Magnitude: 0.05853
Value Function Update Magnitude: 0.12030

Collected Steps per Second: 12869.39749
Overall Steps per Second: 2477.89659

Timestep Collection Time: 3.88938
Timestep Consumption Time: 16.31082
PPO Batch Consumption Time: 2.41123
Total Iteration Time: 20.20020

Cumulative Model Updates: 6614
Cumulative Timesteps: 55481590

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.02644
Policy Entropy: 0.07417
Value Function Loss: 2.55976

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.04712
Value Function Update Magnitude: 0.13942

Collected Steps per Second: 13605.96236
Overall Steps per Second: 2446.64276

Timestep Collection Time: 3.67501
Timestep Consumption Time: 16.76198
PPO Batch Consumption Time: 2.41533
Total Iteration Time: 20.43698

Cumulative Model Updates: 6620
Cumulative Timesteps: 55531592

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 55531592...
Checkpoint 55531592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.72734
Policy Entropy: 0.07525
Value Function Loss: 2.62594

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.05852
Value Function Update Magnitude: 0.14557

Collected Steps per Second: 12720.78047
Overall Steps per Second: 2491.74714

Timestep Collection Time: 3.93309
Timestep Consumption Time: 16.14599
PPO Batch Consumption Time: 2.38680
Total Iteration Time: 20.07908

Cumulative Model Updates: 6626
Cumulative Timesteps: 55581624

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415.34736
Policy Entropy: 0.07669
Value Function Loss: 2.60104

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.14088

Collected Steps per Second: 13691.35379
Overall Steps per Second: 2545.65790

Timestep Collection Time: 3.65209
Timestep Consumption Time: 15.98999
PPO Batch Consumption Time: 2.35478
Total Iteration Time: 19.64207

Cumulative Model Updates: 6632
Cumulative Timesteps: 55631626

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.92728
Policy Entropy: 0.07731
Value Function Loss: 2.56988

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.14843
Policy Update Magnitude: 0.05462
Value Function Update Magnitude: 0.13772

Collected Steps per Second: 13059.98946
Overall Steps per Second: 2546.11298

Timestep Collection Time: 3.82987
Timestep Consumption Time: 15.81498
PPO Batch Consumption Time: 2.32701
Total Iteration Time: 19.64485

Cumulative Model Updates: 6638
Cumulative Timesteps: 55681644

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.32736
Policy Entropy: 0.07923
Value Function Loss: 2.50030

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.15824
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.14007

Collected Steps per Second: 12770.40823
Overall Steps per Second: 2557.76345

Timestep Collection Time: 3.91890
Timestep Consumption Time: 15.64741
PPO Batch Consumption Time: 2.34807
Total Iteration Time: 19.56631

Cumulative Model Updates: 6644
Cumulative Timesteps: 55731690

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.02390
Policy Entropy: 0.08004
Value Function Loss: 2.49231

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14081
Policy Update Magnitude: 0.04921
Value Function Update Magnitude: 0.14763

Collected Steps per Second: 16817.94906
Overall Steps per Second: 2567.97857

Timestep Collection Time: 2.97408
Timestep Consumption Time: 16.50349
PPO Batch Consumption Time: 2.42701
Total Iteration Time: 19.47758

Cumulative Model Updates: 6650
Cumulative Timesteps: 55781708

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 451.71384
Policy Entropy: 0.07618
Value Function Loss: 2.49784

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.20528
Policy Update Magnitude: 0.04476
Value Function Update Magnitude: 0.14028

Collected Steps per Second: 12833.75487
Overall Steps per Second: 2586.77889

Timestep Collection Time: 3.89613
Timestep Consumption Time: 15.43370
PPO Batch Consumption Time: 2.29688
Total Iteration Time: 19.32983

Cumulative Model Updates: 6656
Cumulative Timesteps: 55831710

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.35734
Policy Entropy: 0.07579
Value Function Loss: 2.52769

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.04342
Value Function Update Magnitude: 0.13421

Collected Steps per Second: 13338.16465
Overall Steps per Second: 2578.07310

Timestep Collection Time: 3.75584
Timestep Consumption Time: 15.67573
PPO Batch Consumption Time: 2.31248
Total Iteration Time: 19.43157

Cumulative Model Updates: 6662
Cumulative Timesteps: 55881806

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.77619
Policy Entropy: 0.07137
Value Function Loss: 2.56423

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.04756
Value Function Update Magnitude: 0.13195

Collected Steps per Second: 14494.68196
Overall Steps per Second: 2698.72165

Timestep Collection Time: 3.45313
Timestep Consumption Time: 15.09343
PPO Batch Consumption Time: 2.23691
Total Iteration Time: 18.54656

Cumulative Model Updates: 6668
Cumulative Timesteps: 55931858

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.37995
Policy Entropy: 0.07181
Value Function Loss: 2.58894

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.04580
Value Function Update Magnitude: 0.12559

Collected Steps per Second: 13319.39849
Overall Steps per Second: 2634.76360

Timestep Collection Time: 3.75633
Timestep Consumption Time: 15.23285
PPO Batch Consumption Time: 2.24472
Total Iteration Time: 18.98918

Cumulative Model Updates: 6674
Cumulative Timesteps: 55981890

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.09703
Policy Entropy: 0.07043
Value Function Loss: 2.60790

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.12700

Collected Steps per Second: 12915.13798
Overall Steps per Second: 2637.73887

Timestep Collection Time: 3.87328
Timestep Consumption Time: 15.09144
PPO Batch Consumption Time: 2.23679
Total Iteration Time: 18.96473

Cumulative Model Updates: 6680
Cumulative Timesteps: 56031914

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 56031914...
Checkpoint 56031914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 558.31968
Policy Entropy: 0.06685
Value Function Loss: 2.53681

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14206
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.11140

Collected Steps per Second: 13515.07582
Overall Steps per Second: 2549.43949

Timestep Collection Time: 3.70046
Timestep Consumption Time: 15.91640
PPO Batch Consumption Time: 2.34065
Total Iteration Time: 19.61686

Cumulative Model Updates: 6686
Cumulative Timesteps: 56081926

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.92220
Policy Entropy: 0.06603
Value Function Loss: 2.49681

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.05787
Value Function Update Magnitude: 0.10171

Collected Steps per Second: 12838.20127
Overall Steps per Second: 2502.83588

Timestep Collection Time: 3.89821
Timestep Consumption Time: 16.09751
PPO Batch Consumption Time: 2.37803
Total Iteration Time: 19.99572

Cumulative Model Updates: 6692
Cumulative Timesteps: 56131972

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.97820
Policy Entropy: 0.06801
Value Function Loss: 2.53018

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.04874
Value Function Update Magnitude: 0.12065

Collected Steps per Second: 14932.77617
Overall Steps per Second: 2533.01027

Timestep Collection Time: 3.34928
Timestep Consumption Time: 16.39561
PPO Batch Consumption Time: 2.42900
Total Iteration Time: 19.74489

Cumulative Model Updates: 6698
Cumulative Timesteps: 56181986

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462.93532
Policy Entropy: 0.06592
Value Function Loss: 2.55470

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.10460
Policy Update Magnitude: 0.04840
Value Function Update Magnitude: 0.15291

Collected Steps per Second: 12661.70449
Overall Steps per Second: 2457.08400

Timestep Collection Time: 3.95381
Timestep Consumption Time: 16.42075
PPO Batch Consumption Time: 2.38967
Total Iteration Time: 20.37456

Cumulative Model Updates: 6704
Cumulative Timesteps: 56232048

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.49543
Policy Entropy: 0.06546
Value Function Loss: 2.49608

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12502
Policy Update Magnitude: 0.06736
Value Function Update Magnitude: 0.17100

Collected Steps per Second: 13392.22238
Overall Steps per Second: 2459.35936

Timestep Collection Time: 3.73620
Timestep Consumption Time: 16.60894
PPO Batch Consumption Time: 2.42580
Total Iteration Time: 20.34514

Cumulative Model Updates: 6710
Cumulative Timesteps: 56282084

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 623.26921
Policy Entropy: 0.06317
Value Function Loss: 2.49213

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.17898
Policy Update Magnitude: 0.05537
Value Function Update Magnitude: 0.14863

Collected Steps per Second: 14643.10964
Overall Steps per Second: 2506.68555

Timestep Collection Time: 3.41799
Timestep Consumption Time: 16.54862
PPO Batch Consumption Time: 2.42964
Total Iteration Time: 19.96660

Cumulative Model Updates: 6716
Cumulative Timesteps: 56332134

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.97269
Policy Entropy: 0.06234
Value Function Loss: 2.54323

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10302
Policy Update Magnitude: 0.05618
Value Function Update Magnitude: 0.11265

Collected Steps per Second: 13192.91237
Overall Steps per Second: 2502.33825

Timestep Collection Time: 3.79295
Timestep Consumption Time: 16.20435
PPO Batch Consumption Time: 2.37706
Total Iteration Time: 19.99730

Cumulative Model Updates: 6722
Cumulative Timesteps: 56382174

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.72054
Policy Entropy: 0.06236
Value Function Loss: 2.56310

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.06827
Value Function Update Magnitude: 0.12161

Collected Steps per Second: 12626.68865
Overall Steps per Second: 2463.16587

Timestep Collection Time: 3.96509
Timestep Consumption Time: 16.36078
PPO Batch Consumption Time: 2.43820
Total Iteration Time: 20.32587

Cumulative Model Updates: 6728
Cumulative Timesteps: 56432240

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.33361
Policy Entropy: 0.06178
Value Function Loss: 2.52091

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.06290
Value Function Update Magnitude: 0.14793

Collected Steps per Second: 12931.15477
Overall Steps per Second: 1210.79281

Timestep Collection Time: 3.87204
Timestep Consumption Time: 37.48103
PPO Batch Consumption Time: 2.33900
Total Iteration Time: 41.35307

Cumulative Model Updates: 6734
Cumulative Timesteps: 56482310

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.21167
Policy Entropy: 0.05939
Value Function Loss: 2.52831

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10700
Policy Update Magnitude: 0.05894
Value Function Update Magnitude: 0.14541

Collected Steps per Second: 12565.84311
Overall Steps per Second: 2513.36456

Timestep Collection Time: 3.98238
Timestep Consumption Time: 15.92798
PPO Batch Consumption Time: 2.37842
Total Iteration Time: 19.91036

Cumulative Model Updates: 6740
Cumulative Timesteps: 56532352

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 56532352...
Checkpoint 56532352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.24826
Policy Entropy: 0.05965
Value Function Loss: 2.63472

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06936
Policy Update Magnitude: 0.06195
Value Function Update Magnitude: 0.13281

Collected Steps per Second: 12914.58738
Overall Steps per Second: 1611.48233

Timestep Collection Time: 3.87748
Timestep Consumption Time: 27.19702
PPO Batch Consumption Time: 2.37374
Total Iteration Time: 31.07450

Cumulative Model Updates: 6746
Cumulative Timesteps: 56582428

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.18660
Policy Entropy: 0.05879
Value Function Loss: 2.68459

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.06934
Value Function Update Magnitude: 0.13574

Collected Steps per Second: 12598.00137
Overall Steps per Second: 2489.23888

Timestep Collection Time: 3.97047
Timestep Consumption Time: 16.12402
PPO Batch Consumption Time: 2.40892
Total Iteration Time: 20.09450

Cumulative Model Updates: 6752
Cumulative Timesteps: 56632448

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.25214
Policy Entropy: 0.05998
Value Function Loss: 2.66725

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.10321
Policy Update Magnitude: 0.06245
Value Function Update Magnitude: 0.13658

Collected Steps per Second: 12964.30194
Overall Steps per Second: 2482.49072

Timestep Collection Time: 3.86060
Timestep Consumption Time: 16.30060
PPO Batch Consumption Time: 2.39838
Total Iteration Time: 20.16120

Cumulative Model Updates: 6758
Cumulative Timesteps: 56682498

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665.27863
Policy Entropy: 0.06156
Value Function Loss: 2.61847

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11550
Policy Update Magnitude: 0.05739
Value Function Update Magnitude: 0.14351

Collected Steps per Second: 12713.55936
Overall Steps per Second: 2421.65706

Timestep Collection Time: 3.94130
Timestep Consumption Time: 16.75031
PPO Batch Consumption Time: 2.47495
Total Iteration Time: 20.69162

Cumulative Model Updates: 6764
Cumulative Timesteps: 56732606

Timesteps Collected: 50108
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.04720
Policy Entropy: 0.06089
Value Function Loss: 2.59281

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11619
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.14937

Collected Steps per Second: 13432.86965
Overall Steps per Second: 2514.02972

Timestep Collection Time: 3.72728
Timestep Consumption Time: 16.18816
PPO Batch Consumption Time: 2.37810
Total Iteration Time: 19.91544

Cumulative Model Updates: 6770
Cumulative Timesteps: 56782674

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.96458
Policy Entropy: 0.06028
Value Function Loss: 2.54399

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.20097
Policy Update Magnitude: 0.07626
Value Function Update Magnitude: 0.13978

Collected Steps per Second: 12874.84817
Overall Steps per Second: 2461.55550

Timestep Collection Time: 3.88851
Timestep Consumption Time: 16.44985
PPO Batch Consumption Time: 2.42642
Total Iteration Time: 20.33836

Cumulative Model Updates: 6776
Cumulative Timesteps: 56832738

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.63166
Policy Entropy: 0.05719
Value Function Loss: 2.56777

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.26042
Policy Update Magnitude: 0.05362
Value Function Update Magnitude: 0.13097

Collected Steps per Second: 12958.73392
Overall Steps per Second: 2558.24150

Timestep Collection Time: 3.86072
Timestep Consumption Time: 15.69569
PPO Batch Consumption Time: 2.35609
Total Iteration Time: 19.55640

Cumulative Model Updates: 6782
Cumulative Timesteps: 56882768

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.18611
Policy Entropy: 0.05545
Value Function Loss: 2.62817

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13209
Policy Update Magnitude: 0.04531
Value Function Update Magnitude: 0.12096

Collected Steps per Second: 12672.71682
Overall Steps per Second: 2431.84533

Timestep Collection Time: 3.95069
Timestep Consumption Time: 16.63697
PPO Batch Consumption Time: 2.45784
Total Iteration Time: 20.58766

Cumulative Model Updates: 6788
Cumulative Timesteps: 56932834

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.62109
Policy Entropy: 0.05510
Value Function Loss: 2.65364

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11371
Policy Update Magnitude: 0.05335
Value Function Update Magnitude: 0.11430

Collected Steps per Second: 12595.86411
Overall Steps per Second: 2449.43468

Timestep Collection Time: 3.97289
Timestep Consumption Time: 16.45713
PPO Batch Consumption Time: 2.42768
Total Iteration Time: 20.43002

Cumulative Model Updates: 6794
Cumulative Timesteps: 56982876

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590.47945
Policy Entropy: 0.05536
Value Function Loss: 2.68861

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.11310
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.10910

Collected Steps per Second: 13432.86778
Overall Steps per Second: 2432.97843

Timestep Collection Time: 3.72653
Timestep Consumption Time: 16.84825
PPO Batch Consumption Time: 2.48734
Total Iteration Time: 20.57478

Cumulative Model Updates: 6800
Cumulative Timesteps: 57032934

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 57032934...
Checkpoint 57032934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443.15744
Policy Entropy: 0.05521
Value Function Loss: 2.60575

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11246
Policy Update Magnitude: 0.06413
Value Function Update Magnitude: 0.10495

Collected Steps per Second: 12836.98396
Overall Steps per Second: 1790.54050

Timestep Collection Time: 3.90201
Timestep Consumption Time: 24.07279
PPO Batch Consumption Time: 2.33943
Total Iteration Time: 27.97479

Cumulative Model Updates: 6806
Cumulative Timesteps: 57083024

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.75705
Policy Entropy: 0.05371
Value Function Loss: 2.56004

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.16099
Policy Update Magnitude: 0.05502
Value Function Update Magnitude: 0.11409

Collected Steps per Second: 13446.59307
Overall Steps per Second: 854.48670

Timestep Collection Time: 3.71960
Timestep Consumption Time: 54.81378
PPO Batch Consumption Time: 2.45165
Total Iteration Time: 58.53339

Cumulative Model Updates: 6812
Cumulative Timesteps: 57133040

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.56182
Policy Entropy: 0.05385
Value Function Loss: 2.52357

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.15788
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.11756

Collected Steps per Second: 12832.16394
Overall Steps per Second: 2439.45340

Timestep Collection Time: 3.90129
Timestep Consumption Time: 16.62052
PPO Batch Consumption Time: 2.44975
Total Iteration Time: 20.52181

Cumulative Model Updates: 6818
Cumulative Timesteps: 57183102

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.89870
Policy Entropy: 0.05402
Value Function Loss: 2.52623

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14688
Policy Update Magnitude: 0.04197
Value Function Update Magnitude: 0.13188

Collected Steps per Second: 13548.79867
Overall Steps per Second: 1990.28861

Timestep Collection Time: 3.69464
Timestep Consumption Time: 21.45648
PPO Batch Consumption Time: 2.38410
Total Iteration Time: 25.15113

Cumulative Model Updates: 6824
Cumulative Timesteps: 57233160

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 545.37057
Policy Entropy: 0.05459
Value Function Loss: 2.57641

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.04439
Value Function Update Magnitude: 0.12667

Collected Steps per Second: 12715.97079
Overall Steps per Second: 2450.32440

Timestep Collection Time: 3.93285
Timestep Consumption Time: 16.47669
PPO Batch Consumption Time: 2.42198
Total Iteration Time: 20.40954

Cumulative Model Updates: 6830
Cumulative Timesteps: 57283170

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425.78678
Policy Entropy: 0.05561
Value Function Loss: 2.63250

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12897
Policy Update Magnitude: 0.04980
Value Function Update Magnitude: 0.11790

Collected Steps per Second: 12677.56879
Overall Steps per Second: 655.85407

Timestep Collection Time: 3.94981
Timestep Consumption Time: 72.39949
PPO Batch Consumption Time: 2.32016
Total Iteration Time: 76.34930

Cumulative Model Updates: 6836
Cumulative Timesteps: 57333244

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.55830
Policy Entropy: 0.05589
Value Function Loss: 2.68604

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.04988
Value Function Update Magnitude: 0.12776

Collected Steps per Second: 12676.37613
Overall Steps per Second: 2524.55767

Timestep Collection Time: 3.94908
Timestep Consumption Time: 15.88014
PPO Batch Consumption Time: 2.33071
Total Iteration Time: 19.82922

Cumulative Model Updates: 6842
Cumulative Timesteps: 57383304

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443.09410
Policy Entropy: 0.05287
Value Function Loss: 2.61804

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.14784

Collected Steps per Second: 12592.11870
Overall Steps per Second: 2470.02646

Timestep Collection Time: 3.97566
Timestep Consumption Time: 16.29214
PPO Batch Consumption Time: 2.40894
Total Iteration Time: 20.26780

Cumulative Model Updates: 6848
Cumulative Timesteps: 57433366

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547.23968
Policy Entropy: 0.05165
Value Function Loss: 2.62757

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14561
Policy Update Magnitude: 0.04955
Value Function Update Magnitude: 0.12153

Collected Steps per Second: 13385.62569
Overall Steps per Second: 384.65146

Timestep Collection Time: 3.73595
Timestep Consumption Time: 126.27266
PPO Batch Consumption Time: 2.42415
Total Iteration Time: 130.00861

Cumulative Model Updates: 6854
Cumulative Timesteps: 57483374

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.76877
Policy Entropy: 0.05072
Value Function Loss: 2.59234

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14510
Policy Update Magnitude: 0.04909
Value Function Update Magnitude: 0.11094

Collected Steps per Second: 13003.77744
Overall Steps per Second: 2438.68622

Timestep Collection Time: 3.84750
Timestep Consumption Time: 16.66847
PPO Batch Consumption Time: 2.46459
Total Iteration Time: 20.51596

Cumulative Model Updates: 6860
Cumulative Timesteps: 57533406

Timesteps Collected: 50032
--------END ITERATION REPORT--------


Saving checkpoint 57533406...
Checkpoint 57533406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656.18245
Policy Entropy: 0.05118
Value Function Loss: 2.67558

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12217
Policy Update Magnitude: 0.05075
Value Function Update Magnitude: 0.10960

Collected Steps per Second: 12482.16483
Overall Steps per Second: 323.56071

Timestep Collection Time: 4.01036
Timestep Consumption Time: 150.69940
PPO Batch Consumption Time: 2.34776
Total Iteration Time: 154.70976

Cumulative Model Updates: 6866
Cumulative Timesteps: 57583464

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446.10844
Policy Entropy: 0.05335
Value Function Loss: 2.64039

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.11798
Policy Update Magnitude: 0.05688
Value Function Update Magnitude: 0.11186

Collected Steps per Second: 13006.02233
Overall Steps per Second: 2487.62658

Timestep Collection Time: 3.84483
Timestep Consumption Time: 16.25706
PPO Batch Consumption Time: 2.38932
Total Iteration Time: 20.10189

Cumulative Model Updates: 6872
Cumulative Timesteps: 57633470

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1053.00562
Policy Entropy: 0.05148
Value Function Loss: 2.62700

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12093
Policy Update Magnitude: 0.06272
Value Function Update Magnitude: 0.11228

Collected Steps per Second: 12672.53616
Overall Steps per Second: 1403.47847

Timestep Collection Time: 3.94870
Timestep Consumption Time: 31.70557
PPO Batch Consumption Time: 2.42030
Total Iteration Time: 35.65427

Cumulative Model Updates: 6878
Cumulative Timesteps: 57683510

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657.36270
Policy Entropy: 0.04868
Value Function Loss: 2.54686

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.05150
Value Function Update Magnitude: 0.14628

Collected Steps per Second: 13576.39528
Overall Steps per Second: 2350.76080

Timestep Collection Time: 3.68448
Timestep Consumption Time: 17.59459
PPO Batch Consumption Time: 2.41570
Total Iteration Time: 21.27907

Cumulative Model Updates: 6884
Cumulative Timesteps: 57733532

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671.82525
Policy Entropy: 0.04862
Value Function Loss: 2.52336

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.05133
Value Function Update Magnitude: 0.13632

Collected Steps per Second: 12967.23790
Overall Steps per Second: 2460.12627

Timestep Collection Time: 3.85818
Timestep Consumption Time: 16.47817
PPO Batch Consumption Time: 2.43986
Total Iteration Time: 20.33635

Cumulative Model Updates: 6890
Cumulative Timesteps: 57783562

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670.04077
Policy Entropy: 0.04699
Value Function Loss: 2.58192

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.11603

Collected Steps per Second: 13391.88366
Overall Steps per Second: 2471.29637

Timestep Collection Time: 3.73749
Timestep Consumption Time: 16.51585
PPO Batch Consumption Time: 2.42998
Total Iteration Time: 20.25334

Cumulative Model Updates: 6896
Cumulative Timesteps: 57833614

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398.39922
Policy Entropy: 0.04870
Value Function Loss: 2.61197

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13556
Policy Update Magnitude: 0.04998
Value Function Update Magnitude: 0.11686

Collected Steps per Second: 12798.40333
Overall Steps per Second: 2471.59674

Timestep Collection Time: 3.91252
Timestep Consumption Time: 16.34726
PPO Batch Consumption Time: 2.40583
Total Iteration Time: 20.25978

Cumulative Model Updates: 6902
Cumulative Timesteps: 57883688

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.68416
Policy Entropy: 0.04832
Value Function Loss: 2.63827

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.15186
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.11730

Collected Steps per Second: 12568.56347
Overall Steps per Second: 2520.09023

Timestep Collection Time: 3.98057
Timestep Consumption Time: 15.87190
PPO Batch Consumption Time: 2.36977
Total Iteration Time: 19.85246

Cumulative Model Updates: 6908
Cumulative Timesteps: 57933718

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.89302
Policy Entropy: 0.04965
Value Function Loss: 2.57611

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14796
Policy Update Magnitude: 0.04516
Value Function Update Magnitude: 0.11455

Collected Steps per Second: 12976.94727
Overall Steps per Second: 2473.84499

Timestep Collection Time: 3.86177
Timestep Consumption Time: 16.39576
PPO Batch Consumption Time: 2.41416
Total Iteration Time: 20.25753

Cumulative Model Updates: 6914
Cumulative Timesteps: 57983832

Timesteps Collected: 50114
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.26572
Policy Entropy: 0.04792
Value Function Loss: 2.53026

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.04256
Value Function Update Magnitude: 0.12498

Collected Steps per Second: 12809.38314
Overall Steps per Second: 2505.25917

Timestep Collection Time: 3.90464
Timestep Consumption Time: 16.05976
PPO Batch Consumption Time: 2.40018
Total Iteration Time: 19.96440

Cumulative Model Updates: 6920
Cumulative Timesteps: 58033848

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 58033848...
Checkpoint 58033848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.29507
Policy Entropy: 0.04877
Value Function Loss: 2.49227

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.04357
Value Function Update Magnitude: 0.13214

Collected Steps per Second: 12767.12133
Overall Steps per Second: 2452.19536

Timestep Collection Time: 3.92430
Timestep Consumption Time: 16.50719
PPO Batch Consumption Time: 2.41897
Total Iteration Time: 20.43149

Cumulative Model Updates: 6926
Cumulative Timesteps: 58083950

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.42924
Policy Entropy: 0.04487
Value Function Loss: 2.52884

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12708
Policy Update Magnitude: 0.04816
Value Function Update Magnitude: 0.17504

Collected Steps per Second: 12499.93923
Overall Steps per Second: 2478.89435

Timestep Collection Time: 4.00290
Timestep Consumption Time: 16.18191
PPO Batch Consumption Time: 2.42671
Total Iteration Time: 20.18481

Cumulative Model Updates: 6932
Cumulative Timesteps: 58133986

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.96906
Policy Entropy: 0.04479
Value Function Loss: 2.58956

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12087
Policy Update Magnitude: 0.04964
Value Function Update Magnitude: 0.15161

Collected Steps per Second: 13044.64462
Overall Steps per Second: 2451.48542

Timestep Collection Time: 3.83790
Timestep Consumption Time: 16.58401
PPO Batch Consumption Time: 2.45417
Total Iteration Time: 20.42190

Cumulative Model Updates: 6938
Cumulative Timesteps: 58184050

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.03344
Policy Entropy: 0.04376
Value Function Loss: 2.64952

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.05837
Value Function Update Magnitude: 0.12297

Collected Steps per Second: 13815.42151
Overall Steps per Second: 2060.37565

Timestep Collection Time: 3.62218
Timestep Consumption Time: 20.66562
PPO Batch Consumption Time: 2.37596
Total Iteration Time: 24.28780

Cumulative Model Updates: 6944
Cumulative Timesteps: 58234092

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.57924
Policy Entropy: 0.04383
Value Function Loss: 2.62456

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.05807
Value Function Update Magnitude: 0.11602

Collected Steps per Second: 14922.63926
Overall Steps per Second: 2521.81332

Timestep Collection Time: 3.35303
Timestep Consumption Time: 16.48825
PPO Batch Consumption Time: 2.41372
Total Iteration Time: 19.84128

Cumulative Model Updates: 6950
Cumulative Timesteps: 58284128

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 829.54353
Policy Entropy: 0.04459
Value Function Loss: 2.65786

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.05557
Value Function Update Magnitude: 0.11448

Collected Steps per Second: 13501.99525
Overall Steps per Second: 2441.24866

Timestep Collection Time: 3.70553
Timestep Consumption Time: 16.78890
PPO Batch Consumption Time: 2.47895
Total Iteration Time: 20.49443

Cumulative Model Updates: 6956
Cumulative Timesteps: 58334160

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880.42640
Policy Entropy: 0.04228
Value Function Loss: 2.60230

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.05355
Value Function Update Magnitude: 0.11233

Collected Steps per Second: 14354.55376
Overall Steps per Second: 2481.21139

Timestep Collection Time: 3.48322
Timestep Consumption Time: 16.66823
PPO Batch Consumption Time: 2.44642
Total Iteration Time: 20.15145

Cumulative Model Updates: 6962
Cumulative Timesteps: 58384160

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541.69515
Policy Entropy: 0.04161
Value Function Loss: 2.53657

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14939
Policy Update Magnitude: 0.05584
Value Function Update Magnitude: 0.12990

Collected Steps per Second: 13193.70481
Overall Steps per Second: 2484.30674

Timestep Collection Time: 3.79241
Timestep Consumption Time: 16.34842
PPO Batch Consumption Time: 2.41474
Total Iteration Time: 20.14083

Cumulative Model Updates: 6968
Cumulative Timesteps: 58434196

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574.90667
Policy Entropy: 0.04078
Value Function Loss: 2.50693

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.04900
Value Function Update Magnitude: 0.11585

Collected Steps per Second: 12847.15810
Overall Steps per Second: 2513.16509

Timestep Collection Time: 3.89285
Timestep Consumption Time: 16.00716
PPO Batch Consumption Time: 2.39291
Total Iteration Time: 19.90001

Cumulative Model Updates: 6974
Cumulative Timesteps: 58484208

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.69986
Policy Entropy: 0.04169
Value Function Loss: 2.55466

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12361
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.11173

Collected Steps per Second: 12698.05978
Overall Steps per Second: 2510.47273

Timestep Collection Time: 3.93777
Timestep Consumption Time: 15.97960
PPO Batch Consumption Time: 2.34567
Total Iteration Time: 19.91736

Cumulative Model Updates: 6980
Cumulative Timesteps: 58534210

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 58534210...
Checkpoint 58534210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.79361
Policy Entropy: 0.03913
Value Function Loss: 2.62814

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.05551
Value Function Update Magnitude: 0.11432

Collected Steps per Second: 12772.38968
Overall Steps per Second: 2585.35103

Timestep Collection Time: 3.91924
Timestep Consumption Time: 15.44293
PPO Batch Consumption Time: 2.31018
Total Iteration Time: 19.36217

Cumulative Model Updates: 6986
Cumulative Timesteps: 58584268

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.04078
Policy Entropy: 0.03975
Value Function Loss: 2.59784

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.11936

Collected Steps per Second: 12915.71562
Overall Steps per Second: 2533.46196

Timestep Collection Time: 3.87776
Timestep Consumption Time: 15.89124
PPO Batch Consumption Time: 2.33652
Total Iteration Time: 19.76900

Cumulative Model Updates: 6992
Cumulative Timesteps: 58634352

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463.47339
Policy Entropy: 0.04100
Value Function Loss: 2.57798

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.05609
Value Function Update Magnitude: 0.11801

Collected Steps per Second: 15016.87581
Overall Steps per Second: 2670.03617

Timestep Collection Time: 3.33079
Timestep Consumption Time: 15.40229
PPO Batch Consumption Time: 2.28285
Total Iteration Time: 18.73308

Cumulative Model Updates: 6998
Cumulative Timesteps: 58684370

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 793.45685
Policy Entropy: 0.04088
Value Function Loss: 2.57851

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14809
Policy Update Magnitude: 0.05114
Value Function Update Magnitude: 0.11627

Collected Steps per Second: 12629.55421
Overall Steps per Second: 2462.01877

Timestep Collection Time: 3.96245
Timestep Consumption Time: 16.36396
PPO Batch Consumption Time: 2.40678
Total Iteration Time: 20.32641

Cumulative Model Updates: 7004
Cumulative Timesteps: 58734414

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.64655
Policy Entropy: 0.04233
Value Function Loss: 2.61687

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.15580
Policy Update Magnitude: 0.04894
Value Function Update Magnitude: 0.11478

Collected Steps per Second: 12836.65099
Overall Steps per Second: 2501.18888

Timestep Collection Time: 3.90335
Timestep Consumption Time: 16.12952
PPO Batch Consumption Time: 2.38820
Total Iteration Time: 20.03287

Cumulative Model Updates: 7010
Cumulative Timesteps: 58784520

Timesteps Collected: 50106
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664.12513
Policy Entropy: 0.04029
Value Function Loss: 2.51535

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.15575
Policy Update Magnitude: 0.04741
Value Function Update Magnitude: 0.12464

Collected Steps per Second: 13430.95881
Overall Steps per Second: 2516.89595

Timestep Collection Time: 3.72364
Timestep Consumption Time: 16.14687
PPO Batch Consumption Time: 2.37582
Total Iteration Time: 19.87051

Cumulative Model Updates: 7016
Cumulative Timesteps: 58834532

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 829.40318
Policy Entropy: 0.04029
Value Function Loss: 2.55072

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14779
Policy Update Magnitude: 0.04678
Value Function Update Magnitude: 0.15066

Collected Steps per Second: 12614.73481
Overall Steps per Second: 2452.54867

Timestep Collection Time: 3.96742
Timestep Consumption Time: 16.43910
PPO Batch Consumption Time: 2.42913
Total Iteration Time: 20.40653

Cumulative Model Updates: 7022
Cumulative Timesteps: 58884580

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.19108
Policy Entropy: 0.04018
Value Function Loss: 2.53821

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.13876
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.13257

Collected Steps per Second: 13544.73875
Overall Steps per Second: 2482.58882

Timestep Collection Time: 3.69752
Timestep Consumption Time: 16.47577
PPO Batch Consumption Time: 2.44412
Total Iteration Time: 20.17330

Cumulative Model Updates: 7028
Cumulative Timesteps: 58934662

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508.54800
Policy Entropy: 0.03782
Value Function Loss: 2.56363

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12161
Policy Update Magnitude: 0.06698
Value Function Update Magnitude: 0.12600

Collected Steps per Second: 13356.94566
Overall Steps per Second: 2434.77524

Timestep Collection Time: 3.74502
Timestep Consumption Time: 16.79979
PPO Batch Consumption Time: 2.47388
Total Iteration Time: 20.54481

Cumulative Model Updates: 7034
Cumulative Timesteps: 58984684

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 831.13074
Policy Entropy: 0.03791
Value Function Loss: 2.50631

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.05891
Value Function Update Magnitude: 0.14319

Collected Steps per Second: 12798.69592
Overall Steps per Second: 2476.11125

Timestep Collection Time: 3.90930
Timestep Consumption Time: 16.29738
PPO Batch Consumption Time: 2.44040
Total Iteration Time: 20.20668

Cumulative Model Updates: 7040
Cumulative Timesteps: 59034718

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 59034718...
Checkpoint 59034718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478.37799
Policy Entropy: 0.03650
Value Function Loss: 2.55730

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13034
Policy Update Magnitude: 0.05838
Value Function Update Magnitude: 0.15735

Collected Steps per Second: 14700.14213
Overall Steps per Second: 2486.87842

Timestep Collection Time: 3.40527
Timestep Consumption Time: 16.72358
PPO Batch Consumption Time: 2.44706
Total Iteration Time: 20.12885

Cumulative Model Updates: 7046
Cumulative Timesteps: 59084776

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466.72944
Policy Entropy: 0.03434
Value Function Loss: 2.64515

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14384
Policy Update Magnitude: 0.05009
Value Function Update Magnitude: 0.14211

Collected Steps per Second: 15630.73350
Overall Steps per Second: 2569.28856

Timestep Collection Time: 3.20241
Timestep Consumption Time: 16.28003
PPO Batch Consumption Time: 2.42613
Total Iteration Time: 19.48244

Cumulative Model Updates: 7052
Cumulative Timesteps: 59134832

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.77304
Policy Entropy: 0.03533
Value Function Loss: 2.64760

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.04807
Value Function Update Magnitude: 0.14271

Collected Steps per Second: 15375.58156
Overall Steps per Second: 2524.97782

Timestep Collection Time: 3.25282
Timestep Consumption Time: 16.55488
PPO Batch Consumption Time: 2.43205
Total Iteration Time: 19.80770

Cumulative Model Updates: 7058
Cumulative Timesteps: 59184846

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736.33186
Policy Entropy: 0.03477
Value Function Loss: 2.63404

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.06634
Value Function Update Magnitude: 0.12385

Collected Steps per Second: 13250.68028
Overall Steps per Second: 2471.73579

Timestep Collection Time: 3.77520
Timestep Consumption Time: 16.46321
PPO Batch Consumption Time: 2.44266
Total Iteration Time: 20.23841

Cumulative Model Updates: 7064
Cumulative Timesteps: 59234870

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 814.14812
Policy Entropy: 0.03424
Value Function Loss: 2.67574

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.19601
Policy Update Magnitude: 0.06317
Value Function Update Magnitude: 0.12847

Collected Steps per Second: 15150.32218
Overall Steps per Second: 2562.64286

Timestep Collection Time: 3.30448
Timestep Consumption Time: 16.23160
PPO Batch Consumption Time: 2.36807
Total Iteration Time: 19.53608

Cumulative Model Updates: 7070
Cumulative Timesteps: 59284934

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.13088
Policy Entropy: 0.03560
Value Function Loss: 2.64436

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.17988
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.16320

Collected Steps per Second: 12910.95455
Overall Steps per Second: 1543.41082

Timestep Collection Time: 3.87593
Timestep Consumption Time: 28.54706
PPO Batch Consumption Time: 2.35793
Total Iteration Time: 32.42299

Cumulative Model Updates: 7076
Cumulative Timesteps: 59334976

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666.71905
Policy Entropy: 0.03415
Value Function Loss: 2.59915

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.16277
Policy Update Magnitude: 0.05174
Value Function Update Magnitude: 0.13988

Collected Steps per Second: 12588.07938
Overall Steps per Second: 2468.55616

Timestep Collection Time: 3.97440
Timestep Consumption Time: 16.29251
PPO Batch Consumption Time: 2.43523
Total Iteration Time: 20.26691

Cumulative Model Updates: 7082
Cumulative Timesteps: 59385006

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.52389
Policy Entropy: 0.03394
Value Function Loss: 2.57419

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13662
Policy Update Magnitude: 0.04551
Value Function Update Magnitude: 0.13495

Collected Steps per Second: 12923.81070
Overall Steps per Second: 2447.33437

Timestep Collection Time: 3.87130
Timestep Consumption Time: 16.57216
PPO Batch Consumption Time: 2.44538
Total Iteration Time: 20.44347

Cumulative Model Updates: 7088
Cumulative Timesteps: 59435038

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.70131
Policy Entropy: 0.03417
Value Function Loss: 2.51029

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.05262
Value Function Update Magnitude: 0.12830

Collected Steps per Second: 12479.83827
Overall Steps per Second: 2526.45455

Timestep Collection Time: 4.01816
Timestep Consumption Time: 15.83021
PPO Batch Consumption Time: 2.36172
Total Iteration Time: 19.84837

Cumulative Model Updates: 7094
Cumulative Timesteps: 59485184

Timesteps Collected: 50146
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665.72759
Policy Entropy: 0.03043
Value Function Loss: 2.54213

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.15189
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.11959

Collected Steps per Second: 12763.92410
Overall Steps per Second: 636.03315

Timestep Collection Time: 3.92293
Timestep Consumption Time: 74.80252
PPO Batch Consumption Time: 2.41755
Total Iteration Time: 78.72546

Cumulative Model Updates: 7100
Cumulative Timesteps: 59535256

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 59535256...
Checkpoint 59535256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.26223
Policy Entropy: 0.03252
Value Function Loss: 2.53429

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14694
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.11305

Collected Steps per Second: 13370.27638
Overall Steps per Second: 2472.57076

Timestep Collection Time: 3.74368
Timestep Consumption Time: 16.50003
PPO Batch Consumption Time: 2.43975
Total Iteration Time: 20.24371

Cumulative Model Updates: 7106
Cumulative Timesteps: 59585310

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.33793
Policy Entropy: 0.03259
Value Function Loss: 2.61417

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.06642
Value Function Update Magnitude: 0.11906

Collected Steps per Second: 14677.97093
Overall Steps per Second: 1649.60704

Timestep Collection Time: 3.40865
Timestep Consumption Time: 26.92100
PPO Batch Consumption Time: 2.39341
Total Iteration Time: 30.32965

Cumulative Model Updates: 7112
Cumulative Timesteps: 59635342

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 921.40247
Policy Entropy: 0.03422
Value Function Loss: 2.58208

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11688
Policy Update Magnitude: 0.06517
Value Function Update Magnitude: 0.12445

Collected Steps per Second: 13208.70079
Overall Steps per Second: 1732.82808

Timestep Collection Time: 3.79174
Timestep Consumption Time: 25.11130
PPO Batch Consumption Time: 2.47555
Total Iteration Time: 28.90304

Cumulative Model Updates: 7118
Cumulative Timesteps: 59685426

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.10654
Policy Entropy: 0.03353
Value Function Loss: 2.66250

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.16450
Policy Update Magnitude: 0.06848
Value Function Update Magnitude: 0.09681

Collected Steps per Second: 12860.85839
Overall Steps per Second: 2454.43728

Timestep Collection Time: 3.88932
Timestep Consumption Time: 16.49010
PPO Batch Consumption Time: 2.46638
Total Iteration Time: 20.37942

Cumulative Model Updates: 7124
Cumulative Timesteps: 59735446

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.63872
Policy Entropy: 0.03095
Value Function Loss: 2.61276

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.19800
Policy Update Magnitude: 0.06681
Value Function Update Magnitude: 0.11160

Collected Steps per Second: 12978.95125
Overall Steps per Second: 2470.72077

Timestep Collection Time: 3.85763
Timestep Consumption Time: 16.40690
PPO Batch Consumption Time: 2.41471
Total Iteration Time: 20.26453

Cumulative Model Updates: 7130
Cumulative Timesteps: 59785514

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.46036
Policy Entropy: 0.03073
Value Function Loss: 2.61021

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.23037
Policy Update Magnitude: 0.06369
Value Function Update Magnitude: 0.16631

Collected Steps per Second: 12907.66136
Overall Steps per Second: 2437.31506

Timestep Collection Time: 3.87754
Timestep Consumption Time: 16.65735
PPO Batch Consumption Time: 2.46647
Total Iteration Time: 20.53489

Cumulative Model Updates: 7136
Cumulative Timesteps: 59835564

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730.62339
Policy Entropy: 0.02891
Value Function Loss: 2.53752

Mean KL Divergence: 0.02368
SB3 Clip Fraction: 0.29604
Policy Update Magnitude: 0.05190
Value Function Update Magnitude: 0.17647

Collected Steps per Second: 13587.83647
Overall Steps per Second: 2480.45027

Timestep Collection Time: 3.68064
Timestep Consumption Time: 16.48182
PPO Batch Consumption Time: 2.42632
Total Iteration Time: 20.16247

Cumulative Model Updates: 7142
Cumulative Timesteps: 59885576

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.16814
Policy Entropy: 0.03002
Value Function Loss: 2.54425

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.18626
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.14970

Collected Steps per Second: 12728.09987
Overall Steps per Second: 1689.49456

Timestep Collection Time: 3.92973
Timestep Consumption Time: 25.67557
PPO Batch Consumption Time: 2.38764
Total Iteration Time: 29.60530

Cumulative Model Updates: 7148
Cumulative Timesteps: 59935594

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380.87887
Policy Entropy: 0.03023
Value Function Loss: 2.61334

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.16672
Policy Update Magnitude: 0.05004
Value Function Update Magnitude: 0.12348

Collected Steps per Second: 13573.96497
Overall Steps per Second: 2495.81083

Timestep Collection Time: 3.68485
Timestep Consumption Time: 16.35593
PPO Batch Consumption Time: 2.42665
Total Iteration Time: 20.04078

Cumulative Model Updates: 7154
Cumulative Timesteps: 59985612

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 665.36084
Policy Entropy: 0.03095
Value Function Loss: 2.59821

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12463
Policy Update Magnitude: 0.04900
Value Function Update Magnitude: 0.12846

Collected Steps per Second: 12678.70451
Overall Steps per Second: 653.25328

Timestep Collection Time: 3.94583
Timestep Consumption Time: 72.63702
PPO Batch Consumption Time: 2.37222
Total Iteration Time: 76.58285

Cumulative Model Updates: 7160
Cumulative Timesteps: 60035640

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 60035640...
Checkpoint 60035640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647.52617
Policy Entropy: 0.03192
Value Function Loss: 2.59207

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.16706
Policy Update Magnitude: 0.05027
Value Function Update Magnitude: 0.17432

Collected Steps per Second: 12825.32695
Overall Steps per Second: 2516.55798

Timestep Collection Time: 3.89885
Timestep Consumption Time: 15.97115
PPO Batch Consumption Time: 2.37240
Total Iteration Time: 19.87000

Cumulative Model Updates: 7166
Cumulative Timesteps: 60085644

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583.30861
Policy Entropy: 0.03162
Value Function Loss: 2.52961

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.15378
Policy Update Magnitude: 0.05280
Value Function Update Magnitude: 0.15312

Collected Steps per Second: 12828.45976
Overall Steps per Second: 1377.29596

Timestep Collection Time: 3.90008
Timestep Consumption Time: 32.42617
PPO Batch Consumption Time: 2.38283
Total Iteration Time: 36.32625

Cumulative Model Updates: 7172
Cumulative Timesteps: 60135676

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.59026
Policy Entropy: 0.03101
Value Function Loss: 2.45888

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.15998
Policy Update Magnitude: 0.05847
Value Function Update Magnitude: 0.11330

Collected Steps per Second: 12562.68030
Overall Steps per Second: 2486.41287

Timestep Collection Time: 3.98179
Timestep Consumption Time: 16.13635
PPO Batch Consumption Time: 2.40957
Total Iteration Time: 20.11814

Cumulative Model Updates: 7178
Cumulative Timesteps: 60185698

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717.12716
Policy Entropy: 0.03025
Value Function Loss: 2.40389

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.19058
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.10913

Collected Steps per Second: 12957.80475
Overall Steps per Second: 1658.44488

Timestep Collection Time: 3.86223
Timestep Consumption Time: 26.31423
PPO Batch Consumption Time: 2.44247
Total Iteration Time: 30.17646

Cumulative Model Updates: 7184
Cumulative Timesteps: 60235744

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1137.40193
Policy Entropy: 0.03268
Value Function Loss: 2.43529

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.15084
Policy Update Magnitude: 0.05780
Value Function Update Magnitude: 0.11036

Collected Steps per Second: 12834.72416
Overall Steps per Second: 2433.34873

Timestep Collection Time: 3.90129
Timestep Consumption Time: 16.67611
PPO Batch Consumption Time: 2.46263
Total Iteration Time: 20.57740

Cumulative Model Updates: 7190
Cumulative Timesteps: 60285816

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.53430
Policy Entropy: 0.03145
Value Function Loss: 2.45495

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.05722
Value Function Update Magnitude: 0.10169

Collected Steps per Second: 13546.23788
Overall Steps per Second: 2548.16962

Timestep Collection Time: 3.69593
Timestep Consumption Time: 15.95189
PPO Batch Consumption Time: 2.32578
Total Iteration Time: 19.64783

Cumulative Model Updates: 7196
Cumulative Timesteps: 60335882

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.84463
Policy Entropy: 0.03218
Value Function Loss: 2.44883

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.05344
Value Function Update Magnitude: 0.10761

Collected Steps per Second: 12572.24436
Overall Steps per Second: 2519.29694

Timestep Collection Time: 3.97972
Timestep Consumption Time: 15.88058
PPO Batch Consumption Time: 2.34554
Total Iteration Time: 19.86030

Cumulative Model Updates: 7202
Cumulative Timesteps: 60385916

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.38359
Policy Entropy: 0.03251
Value Function Loss: 2.44200

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14849
Policy Update Magnitude: 0.05300
Value Function Update Magnitude: 0.11300

Collected Steps per Second: 12639.39352
Overall Steps per Second: 2580.47024

Timestep Collection Time: 3.96111
Timestep Consumption Time: 15.44078
PPO Batch Consumption Time: 2.30659
Total Iteration Time: 19.40189

Cumulative Model Updates: 7208
Cumulative Timesteps: 60435982

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 820.02130
Policy Entropy: 0.03369
Value Function Loss: 2.53556

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.16246
Policy Update Magnitude: 0.04850
Value Function Update Magnitude: 0.14933

Collected Steps per Second: 12841.62152
Overall Steps per Second: 2066.35706

Timestep Collection Time: 3.90091
Timestep Consumption Time: 20.34175
PPO Batch Consumption Time: 2.45464
Total Iteration Time: 24.24266

Cumulative Model Updates: 7214
Cumulative Timesteps: 60486076

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730.87244
Policy Entropy: 0.03227
Value Function Loss: 2.56391

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12115
Policy Update Magnitude: 0.05657
Value Function Update Magnitude: 0.14668

Collected Steps per Second: 12703.13902
Overall Steps per Second: 2454.80467

Timestep Collection Time: 3.93871
Timestep Consumption Time: 16.44336
PPO Batch Consumption Time: 2.42606
Total Iteration Time: 20.38207

Cumulative Model Updates: 7220
Cumulative Timesteps: 60536110

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 60536110...
Checkpoint 60536110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496.47754
Policy Entropy: 0.03375
Value Function Loss: 2.54446

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.05234
Value Function Update Magnitude: 0.14989

Collected Steps per Second: 13705.13342
Overall Steps per Second: 2137.34332

Timestep Collection Time: 3.65323
Timestep Consumption Time: 19.77211
PPO Batch Consumption Time: 2.44201
Total Iteration Time: 23.42534

Cumulative Model Updates: 7226
Cumulative Timesteps: 60586178

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.03727
Policy Entropy: 0.03152
Value Function Loss: 2.49183

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.05722
Value Function Update Magnitude: 0.16588

Collected Steps per Second: 13197.97095
Overall Steps per Second: 2455.05925

Timestep Collection Time: 3.79164
Timestep Consumption Time: 16.59157
PPO Batch Consumption Time: 2.44567
Total Iteration Time: 20.38321

Cumulative Model Updates: 7232
Cumulative Timesteps: 60636220

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728.53006
Policy Entropy: 0.03217
Value Function Loss: 2.53866

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14570
Policy Update Magnitude: 0.05440
Value Function Update Magnitude: 0.14059

Collected Steps per Second: 12785.17441
Overall Steps per Second: 1241.13022

Timestep Collection Time: 3.91719
Timestep Consumption Time: 36.43474
PPO Batch Consumption Time: 2.44127
Total Iteration Time: 40.35193

Cumulative Model Updates: 7238
Cumulative Timesteps: 60686302

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705.45366
Policy Entropy: 0.03146
Value Function Loss: 2.54088

Mean KL Divergence: 0.01927
SB3 Clip Fraction: 0.24769
Policy Update Magnitude: 0.06155
Value Function Update Magnitude: 0.15011

Collected Steps per Second: 12824.26779
Overall Steps per Second: 2486.01396

Timestep Collection Time: 3.90104
Timestep Consumption Time: 16.22274
PPO Batch Consumption Time: 2.37258
Total Iteration Time: 20.12378

Cumulative Model Updates: 7244
Cumulative Timesteps: 60736330

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 943.44571
Policy Entropy: 0.03237
Value Function Loss: 2.54104

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.16722
Policy Update Magnitude: 0.04527
Value Function Update Magnitude: 0.17375

Collected Steps per Second: 12648.82599
Overall Steps per Second: 357.74074

Timestep Collection Time: 3.95689
Timestep Consumption Time: 135.94890
PPO Batch Consumption Time: 2.44230
Total Iteration Time: 139.90579

Cumulative Model Updates: 7250
Cumulative Timesteps: 60786380

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.97177
Policy Entropy: 0.03063
Value Function Loss: 2.46583

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.15229
Policy Update Magnitude: 0.04126
Value Function Update Magnitude: 0.17409

Collected Steps per Second: 12923.61387
Overall Steps per Second: 2517.20880

Timestep Collection Time: 3.86889
Timestep Consumption Time: 15.99438
PPO Batch Consumption Time: 2.34453
Total Iteration Time: 19.86327

Cumulative Model Updates: 7256
Cumulative Timesteps: 60836380

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 403.62697
Policy Entropy: 0.03169
Value Function Loss: 2.48120

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.16980
Policy Update Magnitude: 0.04390
Value Function Update Magnitude: 0.15063

Collected Steps per Second: 12756.25832
Overall Steps per Second: 1956.23128

Timestep Collection Time: 3.92498
Timestep Consumption Time: 21.66914
PPO Batch Consumption Time: 2.43151
Total Iteration Time: 25.59411

Cumulative Model Updates: 7262
Cumulative Timesteps: 60886448

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.12747
Policy Entropy: 0.03253
Value Function Loss: 2.52471

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.10750
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.14077

Collected Steps per Second: 13160.46398
Overall Steps per Second: 1769.38380

Timestep Collection Time: 3.80336
Timestep Consumption Time: 24.48558
PPO Batch Consumption Time: 2.32017
Total Iteration Time: 28.28894

Cumulative Model Updates: 7268
Cumulative Timesteps: 60936502

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.43221
Policy Entropy: 0.03140
Value Function Loss: 2.55341

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.15858
Policy Update Magnitude: 0.06037
Value Function Update Magnitude: 0.11262

Collected Steps per Second: 12843.47748
Overall Steps per Second: 2461.29900

Timestep Collection Time: 3.89910
Timestep Consumption Time: 16.44707
PPO Batch Consumption Time: 2.43184
Total Iteration Time: 20.34617

Cumulative Model Updates: 7274
Cumulative Timesteps: 60986580

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.88320
Policy Entropy: 0.03226
Value Function Loss: 2.59960

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.22989
Policy Update Magnitude: 0.04901
Value Function Update Magnitude: 0.09872

Collected Steps per Second: 13376.19148
Overall Steps per Second: 2492.84416

Timestep Collection Time: 3.74053
Timestep Consumption Time: 16.33052
PPO Batch Consumption Time: 2.40451
Total Iteration Time: 20.07105

Cumulative Model Updates: 7280
Cumulative Timesteps: 61036614

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 61036614...
Checkpoint 61036614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.68187
Policy Entropy: 0.03093
Value Function Loss: 2.53360

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.23843
Policy Update Magnitude: 0.04048
Value Function Update Magnitude: 0.09589

Collected Steps per Second: 12919.54886
Overall Steps per Second: 2472.70457

Timestep Collection Time: 3.87289
Timestep Consumption Time: 16.36244
PPO Batch Consumption Time: 2.42374
Total Iteration Time: 20.23533

Cumulative Model Updates: 7286
Cumulative Timesteps: 61086650

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.24011
Policy Entropy: 0.03093
Value Function Loss: 2.51644

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.19393
Policy Update Magnitude: 0.04285
Value Function Update Magnitude: 0.10894

Collected Steps per Second: 12628.75698
Overall Steps per Second: 2436.73991

Timestep Collection Time: 3.96381
Timestep Consumption Time: 16.57921
PPO Batch Consumption Time: 2.47093
Total Iteration Time: 20.54302

Cumulative Model Updates: 7292
Cumulative Timesteps: 61136708

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.52214
Policy Entropy: 0.03188
Value Function Loss: 2.43439

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.19132
Policy Update Magnitude: 0.04217
Value Function Update Magnitude: 0.10265

Collected Steps per Second: 12828.96193
Overall Steps per Second: 2468.33515

Timestep Collection Time: 3.89868
Timestep Consumption Time: 16.36437
PPO Batch Consumption Time: 2.41097
Total Iteration Time: 20.26305

Cumulative Model Updates: 7298
Cumulative Timesteps: 61186724

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.87130
Policy Entropy: 0.03139
Value Function Loss: 2.47792

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.04426
Value Function Update Magnitude: 0.12380

Collected Steps per Second: 13016.96157
Overall Steps per Second: 2461.76142

Timestep Collection Time: 3.84375
Timestep Consumption Time: 16.48072
PPO Batch Consumption Time: 2.46777
Total Iteration Time: 20.32447

Cumulative Model Updates: 7304
Cumulative Timesteps: 61236758

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 920.84329
Policy Entropy: 0.03099
Value Function Loss: 2.48167

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15365
Policy Update Magnitude: 0.05184
Value Function Update Magnitude: 0.11852

Collected Steps per Second: 12813.18763
Overall Steps per Second: 546.44684

Timestep Collection Time: 3.90644
Timestep Consumption Time: 87.69259
PPO Batch Consumption Time: 2.39225
Total Iteration Time: 91.59903

Cumulative Model Updates: 7310
Cumulative Timesteps: 61286812

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.41418
Policy Entropy: 0.03070
Value Function Loss: 2.55094

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.12091

Collected Steps per Second: 12845.71368
Overall Steps per Second: 270.99271

Timestep Collection Time: 3.89858
Timestep Consumption Time: 180.90345
PPO Batch Consumption Time: 2.40845
Total Iteration Time: 184.80202

Cumulative Model Updates: 7316
Cumulative Timesteps: 61336892

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441.25936
Policy Entropy: 0.03100
Value Function Loss: 2.47685

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.15300

Collected Steps per Second: 12863.64786
Overall Steps per Second: 2484.25394

Timestep Collection Time: 3.89065
Timestep Consumption Time: 16.25543
PPO Batch Consumption Time: 2.38812
Total Iteration Time: 20.14609

Cumulative Model Updates: 7322
Cumulative Timesteps: 61386940

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1157.81848
Policy Entropy: 0.03121
Value Function Loss: 2.53337

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.06115
Value Function Update Magnitude: 0.14379

Collected Steps per Second: 12675.18584
Overall Steps per Second: 2445.07024

Timestep Collection Time: 3.94629
Timestep Consumption Time: 16.51120
PPO Batch Consumption Time: 2.43188
Total Iteration Time: 20.45749

Cumulative Model Updates: 7328
Cumulative Timesteps: 61436960

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 838.49322
Policy Entropy: 0.03169
Value Function Loss: 2.51877

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.16294
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.11569

Collected Steps per Second: 13444.29011
Overall Steps per Second: 2026.68029

Timestep Collection Time: 3.72173
Timestep Consumption Time: 20.96692
PPO Batch Consumption Time: 2.41919
Total Iteration Time: 24.68865

Cumulative Model Updates: 7334
Cumulative Timesteps: 61486996

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.16820
Policy Entropy: 0.03078
Value Function Loss: 2.57500

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.10441
Policy Update Magnitude: 0.05358
Value Function Update Magnitude: 0.10262

Collected Steps per Second: 12579.53473
Overall Steps per Second: 2518.80672

Timestep Collection Time: 3.98043
Timestep Consumption Time: 15.89882
PPO Batch Consumption Time: 2.33681
Total Iteration Time: 19.87925

Cumulative Model Updates: 7340
Cumulative Timesteps: 61537068

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 61537068...
Checkpoint 61537068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.45954
Policy Entropy: 0.02779
Value Function Loss: 2.57006

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.05328
Value Function Update Magnitude: 0.10486

Collected Steps per Second: 12622.98548
Overall Steps per Second: 434.72793

Timestep Collection Time: 3.96388
Timestep Consumption Time: 111.13339
PPO Batch Consumption Time: 2.35562
Total Iteration Time: 115.09727

Cumulative Model Updates: 7346
Cumulative Timesteps: 61587104

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 824.62323
Policy Entropy: 0.02694
Value Function Loss: 2.56650

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.05541
Value Function Update Magnitude: 0.12019

Collected Steps per Second: 12879.72444
Overall Steps per Second: 2455.79787

Timestep Collection Time: 3.88238
Timestep Consumption Time: 16.47923
PPO Batch Consumption Time: 2.43043
Total Iteration Time: 20.36161

Cumulative Model Updates: 7352
Cumulative Timesteps: 61637108

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.73485
Policy Entropy: 0.02623
Value Function Loss: 2.58866

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.05822
Value Function Update Magnitude: 0.14120

Collected Steps per Second: 12597.50788
Overall Steps per Second: 980.08399

Timestep Collection Time: 3.97174
Timestep Consumption Time: 47.07899
PPO Batch Consumption Time: 2.36732
Total Iteration Time: 51.05073

Cumulative Model Updates: 7358
Cumulative Timesteps: 61687142

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.76100
Policy Entropy: 0.02583
Value Function Loss: 2.60877

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.05562
Value Function Update Magnitude: 0.12289

Collected Steps per Second: 14138.58418
Overall Steps per Second: 2575.16938

Timestep Collection Time: 3.53826
Timestep Consumption Time: 15.88803
PPO Batch Consumption Time: 2.31416
Total Iteration Time: 19.42629

Cumulative Model Updates: 7364
Cumulative Timesteps: 61737168

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.94788
Policy Entropy: 0.02635
Value Function Loss: 2.65444

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.15238
Policy Update Magnitude: 0.05084
Value Function Update Magnitude: 0.10137

Collected Steps per Second: 16336.30253
Overall Steps per Second: 2594.61310

Timestep Collection Time: 3.06177
Timestep Consumption Time: 16.21586
PPO Batch Consumption Time: 2.37958
Total Iteration Time: 19.27763

Cumulative Model Updates: 7370
Cumulative Timesteps: 61787186

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690.16611
Policy Entropy: 0.02623
Value Function Loss: 2.65859

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.04684
Value Function Update Magnitude: 0.09469

Collected Steps per Second: 13899.45200
Overall Steps per Second: 2531.87432

Timestep Collection Time: 3.60216
Timestep Consumption Time: 16.17292
PPO Batch Consumption Time: 2.36697
Total Iteration Time: 19.77507

Cumulative Model Updates: 7376
Cumulative Timesteps: 61837254

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.03919
Policy Entropy: 0.02627
Value Function Loss: 2.60516

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11320
Policy Update Magnitude: 0.07029
Value Function Update Magnitude: 0.09114

Collected Steps per Second: 13434.67592
Overall Steps per Second: 2485.23944

Timestep Collection Time: 3.72707
Timestep Consumption Time: 16.42069
PPO Batch Consumption Time: 2.42498
Total Iteration Time: 20.14776

Cumulative Model Updates: 7382
Cumulative Timesteps: 61887326

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.70995
Policy Entropy: 0.02456
Value Function Loss: 2.56554

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.15293
Policy Update Magnitude: 0.06210
Value Function Update Magnitude: 0.14395

Collected Steps per Second: 13273.94449
Overall Steps per Second: 2500.95959

Timestep Collection Time: 3.77205
Timestep Consumption Time: 16.24826
PPO Batch Consumption Time: 2.40210
Total Iteration Time: 20.02032

Cumulative Model Updates: 7388
Cumulative Timesteps: 61937396

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 489.96837
Policy Entropy: 0.02330
Value Function Loss: 2.57831

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.06057
Value Function Update Magnitude: 0.18425

Collected Steps per Second: 13346.36644
Overall Steps per Second: 2570.23145

Timestep Collection Time: 3.75188
Timestep Consumption Time: 15.73041
PPO Batch Consumption Time: 2.31860
Total Iteration Time: 19.48229

Cumulative Model Updates: 7394
Cumulative Timesteps: 61987470

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.39749
Policy Entropy: 0.02324
Value Function Loss: 2.61271

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.15824
Policy Update Magnitude: 0.05523
Value Function Update Magnitude: 0.14876

Collected Steps per Second: 13045.37713
Overall Steps per Second: 2556.18527

Timestep Collection Time: 3.83707
Timestep Consumption Time: 15.74524
PPO Batch Consumption Time: 2.34318
Total Iteration Time: 19.58231

Cumulative Model Updates: 7400
Cumulative Timesteps: 62037526

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 62037526...
Checkpoint 62037526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556.70698
Policy Entropy: 0.02379
Value Function Loss: 2.62119

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.18137
Policy Update Magnitude: 0.05050
Value Function Update Magnitude: 0.14021

Collected Steps per Second: 12966.77179
Overall Steps per Second: 2474.69200

Timestep Collection Time: 3.85863
Timestep Consumption Time: 16.35964
PPO Batch Consumption Time: 2.42111
Total Iteration Time: 20.21827

Cumulative Model Updates: 7406
Cumulative Timesteps: 62087560

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.79969
Policy Entropy: 0.02386
Value Function Loss: 2.52418

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.16818
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.15744

Collected Steps per Second: 12751.14241
Overall Steps per Second: 2480.27926

Timestep Collection Time: 3.93220
Timestep Consumption Time: 16.28327
PPO Batch Consumption Time: 2.40387
Total Iteration Time: 20.21547

Cumulative Model Updates: 7412
Cumulative Timesteps: 62137700

Timesteps Collected: 50140
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.30133
Policy Entropy: 0.02376
Value Function Loss: 2.49328

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.16753
Policy Update Magnitude: 0.05168
Value Function Update Magnitude: 0.14736

Collected Steps per Second: 15111.37025
Overall Steps per Second: 2597.47987

Timestep Collection Time: 3.30877
Timestep Consumption Time: 15.94066
PPO Batch Consumption Time: 2.33252
Total Iteration Time: 19.24943

Cumulative Model Updates: 7418
Cumulative Timesteps: 62187700

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1067.93828
Policy Entropy: 0.02068
Value Function Loss: 2.54666

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14181
Policy Update Magnitude: 0.07800
Value Function Update Magnitude: 0.11206

Collected Steps per Second: 12768.19240
Overall Steps per Second: 2517.65860

Timestep Collection Time: 3.92005
Timestep Consumption Time: 15.96032
PPO Batch Consumption Time: 2.33446
Total Iteration Time: 19.88038

Cumulative Model Updates: 7424
Cumulative Timesteps: 62237752

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673.08675
Policy Entropy: 0.02212
Value Function Loss: 2.57067

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15818
Policy Update Magnitude: 0.06600
Value Function Update Magnitude: 0.09025

Collected Steps per Second: 15640.18962
Overall Steps per Second: 2619.78446

Timestep Collection Time: 3.20111
Timestep Consumption Time: 15.90962
PPO Batch Consumption Time: 2.38407
Total Iteration Time: 19.11073

Cumulative Model Updates: 7430
Cumulative Timesteps: 62287818

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775.39127
Policy Entropy: 0.02162
Value Function Loss: 2.57313

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.15235
Policy Update Magnitude: 0.05346
Value Function Update Magnitude: 0.07093

Collected Steps per Second: 13924.27318
Overall Steps per Second: 2475.04132

Timestep Collection Time: 3.59358
Timestep Consumption Time: 16.62346
PPO Batch Consumption Time: 2.42231
Total Iteration Time: 20.21704

Cumulative Model Updates: 7436
Cumulative Timesteps: 62337856

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449.06438
Policy Entropy: 0.02079
Value Function Loss: 2.65392

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14387
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.06835

Collected Steps per Second: 12576.45452
Overall Steps per Second: 2521.86856

Timestep Collection Time: 3.98141
Timestep Consumption Time: 15.87371
PPO Batch Consumption Time: 2.37689
Total Iteration Time: 19.85512

Cumulative Model Updates: 7442
Cumulative Timesteps: 62387928

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 839.70273
Policy Entropy: 0.01932
Value Function Loss: 2.66001

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14725
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.07047

Collected Steps per Second: 12919.87478
Overall Steps per Second: 2474.18461

Timestep Collection Time: 3.87635
Timestep Consumption Time: 16.36547
PPO Batch Consumption Time: 2.40844
Total Iteration Time: 20.24182

Cumulative Model Updates: 7448
Cumulative Timesteps: 62438010

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.42532
Policy Entropy: 0.02111
Value Function Loss: 2.62374

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.14636
Policy Update Magnitude: 0.05101
Value Function Update Magnitude: 0.06233

Collected Steps per Second: 13196.09711
Overall Steps per Second: 2529.53808

Timestep Collection Time: 3.79279
Timestep Consumption Time: 15.99343
PPO Batch Consumption Time: 2.39227
Total Iteration Time: 19.78622

Cumulative Model Updates: 7454
Cumulative Timesteps: 62488060

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 733.26213
Policy Entropy: 0.02332
Value Function Loss: 2.58276

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.06039
Value Function Update Magnitude: 0.06065

Collected Steps per Second: 13728.78432
Overall Steps per Second: 2497.89473

Timestep Collection Time: 3.64533
Timestep Consumption Time: 16.38994
PPO Batch Consumption Time: 2.40922
Total Iteration Time: 20.03527

Cumulative Model Updates: 7460
Cumulative Timesteps: 62538106

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 62538106...
Checkpoint 62538106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583.21675
Policy Entropy: 0.02413
Value Function Loss: 2.66035

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14352
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.05892

Collected Steps per Second: 15395.72614
Overall Steps per Second: 2512.97945

Timestep Collection Time: 3.25246
Timestep Consumption Time: 16.67369
PPO Batch Consumption Time: 2.45771
Total Iteration Time: 19.92615

Cumulative Model Updates: 7466
Cumulative Timesteps: 62588180

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471.86901
Policy Entropy: 0.02406
Value Function Loss: 2.66587

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14034
Policy Update Magnitude: 0.04574
Value Function Update Magnitude: 0.05818

Collected Steps per Second: 17556.66640
Overall Steps per Second: 2592.44231

Timestep Collection Time: 2.84838
Timestep Consumption Time: 16.44154
PPO Batch Consumption Time: 2.41592
Total Iteration Time: 19.28992

Cumulative Model Updates: 7472
Cumulative Timesteps: 62638188

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.11883
Policy Entropy: 0.02463
Value Function Loss: 2.77436

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.15397
Policy Update Magnitude: 0.04437
Value Function Update Magnitude: 0.05993

Collected Steps per Second: 12598.60680
Overall Steps per Second: 2483.11393

Timestep Collection Time: 3.97092
Timestep Consumption Time: 16.17637
PPO Batch Consumption Time: 2.39515
Total Iteration Time: 20.14728

Cumulative Model Updates: 7478
Cumulative Timesteps: 62688216

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.59029
Policy Entropy: 0.02512
Value Function Loss: 2.63393

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.15058
Policy Update Magnitude: 0.04353
Value Function Update Magnitude: 0.05930

Collected Steps per Second: 12540.66868
Overall Steps per Second: 2581.76340

Timestep Collection Time: 3.99325
Timestep Consumption Time: 15.40357
PPO Batch Consumption Time: 2.29595
Total Iteration Time: 19.39682

Cumulative Model Updates: 7484
Cumulative Timesteps: 62738294

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 893.04368
Policy Entropy: 0.02673
Value Function Loss: 2.65145

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.14894
Policy Update Magnitude: 0.04561
Value Function Update Magnitude: 0.06763

Collected Steps per Second: 13733.95380
Overall Steps per Second: 2523.08006

Timestep Collection Time: 3.64527
Timestep Consumption Time: 16.19714
PPO Batch Consumption Time: 2.38205
Total Iteration Time: 19.84241

Cumulative Model Updates: 7490
Cumulative Timesteps: 62788358

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.02765
Policy Entropy: 0.02539
Value Function Loss: 2.51146

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.04541
Value Function Update Magnitude: 0.06242

Collected Steps per Second: 14987.94268
Overall Steps per Second: 2635.24367

Timestep Collection Time: 3.33868
Timestep Consumption Time: 15.65007
PPO Batch Consumption Time: 2.34433
Total Iteration Time: 18.98876

Cumulative Model Updates: 7496
Cumulative Timesteps: 62838398

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 871.61033
Policy Entropy: 0.02666
Value Function Loss: 2.68033

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.06098

Collected Steps per Second: 16723.09409
Overall Steps per Second: 2676.88262

Timestep Collection Time: 2.99777
Timestep Consumption Time: 15.72998
PPO Batch Consumption Time: 2.29488
Total Iteration Time: 18.72775

Cumulative Model Updates: 7502
Cumulative Timesteps: 62888530

Timesteps Collected: 50132
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667.90952
Policy Entropy: 0.02541
Value Function Loss: 2.70488

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.05166
Value Function Update Magnitude: 0.05976

Collected Steps per Second: 13978.26071
Overall Steps per Second: 2529.09974

Timestep Collection Time: 3.58342
Timestep Consumption Time: 16.22204
PPO Batch Consumption Time: 2.37904
Total Iteration Time: 19.80547

Cumulative Model Updates: 7508
Cumulative Timesteps: 62938620

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 742.85261
Policy Entropy: 0.02598
Value Function Loss: 2.79378

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12343
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.05814

Collected Steps per Second: 15271.34785
Overall Steps per Second: 2526.44492

Timestep Collection Time: 3.27463
Timestep Consumption Time: 16.51919
PPO Batch Consumption Time: 2.40660
Total Iteration Time: 19.79382

Cumulative Model Updates: 7514
Cumulative Timesteps: 62988628

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 666.60575
Policy Entropy: 0.02489
Value Function Loss: 2.69346

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.04641
Value Function Update Magnitude: 0.05721

Collected Steps per Second: 13124.26179
Overall Steps per Second: 2509.99789

Timestep Collection Time: 3.81340
Timestep Consumption Time: 16.12606
PPO Batch Consumption Time: 2.37961
Total Iteration Time: 19.93946

Cumulative Model Updates: 7520
Cumulative Timesteps: 63038676

Timesteps Collected: 50048
--------END ITERATION REPORT--------


Saving checkpoint 63038676...
Checkpoint 63038676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702.00419
Policy Entropy: 0.02797
Value Function Loss: 2.67446

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.05680

Collected Steps per Second: 12844.53114
Overall Steps per Second: 2519.12252

Timestep Collection Time: 3.89286
Timestep Consumption Time: 15.95611
PPO Batch Consumption Time: 2.37075
Total Iteration Time: 19.84898

Cumulative Model Updates: 7526
Cumulative Timesteps: 63088678

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 504.69425
Policy Entropy: 0.02688
Value Function Loss: 2.59782

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.04664
Value Function Update Magnitude: 0.05676

Collected Steps per Second: 13414.94324
Overall Steps per Second: 2517.24670

Timestep Collection Time: 3.72734
Timestep Consumption Time: 16.13643
PPO Batch Consumption Time: 2.39079
Total Iteration Time: 19.86377

Cumulative Model Updates: 7532
Cumulative Timesteps: 63138680

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.23548
Policy Entropy: 0.02880
Value Function Loss: 2.69436

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.05525
Value Function Update Magnitude: 0.05989

Collected Steps per Second: 13299.17486
Overall Steps per Second: 2528.50736

Timestep Collection Time: 3.76038
Timestep Consumption Time: 16.01808
PPO Batch Consumption Time: 2.38568
Total Iteration Time: 19.77847

Cumulative Model Updates: 7538
Cumulative Timesteps: 63188690

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.31292
Policy Entropy: 0.02909
Value Function Loss: 2.64572

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14433
Policy Update Magnitude: 0.05519
Value Function Update Magnitude: 0.06120

Collected Steps per Second: 14340.76162
Overall Steps per Second: 2513.90274

Timestep Collection Time: 3.48866
Timestep Consumption Time: 16.41267
PPO Batch Consumption Time: 2.38956
Total Iteration Time: 19.90133

Cumulative Model Updates: 7544
Cumulative Timesteps: 63238720

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.13080
Policy Entropy: 0.03160
Value Function Loss: 2.69264

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.15130
Policy Update Magnitude: 0.05196
Value Function Update Magnitude: 0.05950

Collected Steps per Second: 15737.82853
Overall Steps per Second: 2608.56716

Timestep Collection Time: 3.17706
Timestep Consumption Time: 15.99055
PPO Batch Consumption Time: 2.34695
Total Iteration Time: 19.16761

Cumulative Model Updates: 7550
Cumulative Timesteps: 63288720

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 913.57829
Policy Entropy: 0.03224
Value Function Loss: 2.62264

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.14773
Policy Update Magnitude: 0.05258
Value Function Update Magnitude: 0.06353

Collected Steps per Second: 13275.34065
Overall Steps per Second: 2544.40728

Timestep Collection Time: 3.77015
Timestep Consumption Time: 15.90044
PPO Batch Consumption Time: 2.35314
Total Iteration Time: 19.67059

Cumulative Model Updates: 7556
Cumulative Timesteps: 63338770

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1175.57913
Policy Entropy: 0.03449
Value Function Loss: 2.66254

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.16672
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.05999

Collected Steps per Second: 12783.39335
Overall Steps per Second: 2551.53430

Timestep Collection Time: 3.91664
Timestep Consumption Time: 15.70606
PPO Batch Consumption Time: 2.31646
Total Iteration Time: 19.62270

Cumulative Model Updates: 7562
Cumulative Timesteps: 63388838

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635.47668
Policy Entropy: 0.03528
Value Function Loss: 2.63073

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.06669
Value Function Update Magnitude: 0.05918

Collected Steps per Second: 12154.75822
Overall Steps per Second: 2567.47849

Timestep Collection Time: 4.12020
Timestep Consumption Time: 15.38532
PPO Batch Consumption Time: 2.29520
Total Iteration Time: 19.50552

Cumulative Model Updates: 7568
Cumulative Timesteps: 63438918

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480.44903
Policy Entropy: 0.03603
Value Function Loss: 2.67350

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.15101
Policy Update Magnitude: 0.06414
Value Function Update Magnitude: 0.05842

Collected Steps per Second: 14479.46899
Overall Steps per Second: 2609.00776

Timestep Collection Time: 3.45800
Timestep Consumption Time: 15.73320
PPO Batch Consumption Time: 2.28554
Total Iteration Time: 19.19120

Cumulative Model Updates: 7574
Cumulative Timesteps: 63488988

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511.51829
Policy Entropy: 0.03533
Value Function Loss: 2.60959

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.06320
Value Function Update Magnitude: 0.05382

Collected Steps per Second: 14184.20538
Overall Steps per Second: 2636.02072

Timestep Collection Time: 3.52674
Timestep Consumption Time: 15.45035
PPO Batch Consumption Time: 2.29805
Total Iteration Time: 18.97709

Cumulative Model Updates: 7580
Cumulative Timesteps: 63539012

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 63539012...
Checkpoint 63539012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.93116
Policy Entropy: 0.03570
Value Function Loss: 2.61521

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.17165
Policy Update Magnitude: 0.05786
Value Function Update Magnitude: 0.05460

Collected Steps per Second: 13265.45036
Overall Steps per Second: 2490.08174

Timestep Collection Time: 3.77507
Timestep Consumption Time: 16.33592
PPO Batch Consumption Time: 2.40358
Total Iteration Time: 20.11099

Cumulative Model Updates: 7586
Cumulative Timesteps: 63589090

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 991.78603
Policy Entropy: 0.03826
Value Function Loss: 2.62291

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.16153
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.05991

Collected Steps per Second: 15055.36209
Overall Steps per Second: 2576.47517

Timestep Collection Time: 3.32214
Timestep Consumption Time: 16.09043
PPO Batch Consumption Time: 2.42059
Total Iteration Time: 19.41257

Cumulative Model Updates: 7592
Cumulative Timesteps: 63639106

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1062.30511
Policy Entropy: 0.03948
Value Function Loss: 2.66619

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13665
Policy Update Magnitude: 0.04682
Value Function Update Magnitude: 0.05844

Collected Steps per Second: 14258.62063
Overall Steps per Second: 2547.99657

Timestep Collection Time: 3.50805
Timestep Consumption Time: 16.12306
PPO Batch Consumption Time: 2.35331
Total Iteration Time: 19.63111

Cumulative Model Updates: 7598
Cumulative Timesteps: 63689126

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514.46711
Policy Entropy: 0.03865
Value Function Loss: 2.73786

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.04571
Value Function Update Magnitude: 0.05686

Collected Steps per Second: 12849.65213
Overall Steps per Second: 2561.78247

Timestep Collection Time: 3.89676
Timestep Consumption Time: 15.64901
PPO Batch Consumption Time: 2.29757
Total Iteration Time: 19.54577

Cumulative Model Updates: 7604
Cumulative Timesteps: 63739198

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.88782
Policy Entropy: 0.03963
Value Function Loss: 2.75192

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.14935
Policy Update Magnitude: 0.05160
Value Function Update Magnitude: 0.05988

Collected Steps per Second: 13326.75316
Overall Steps per Second: 2554.86517

Timestep Collection Time: 3.75650
Timestep Consumption Time: 15.83827
PPO Batch Consumption Time: 2.34024
Total Iteration Time: 19.59477

Cumulative Model Updates: 7610
Cumulative Timesteps: 63789260

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 895.04034
Policy Entropy: 0.03882
Value Function Loss: 2.71718

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.17378
Policy Update Magnitude: 0.06204
Value Function Update Magnitude: 0.06029

Collected Steps per Second: 12800.45929
Overall Steps per Second: 2557.85978

Timestep Collection Time: 3.90814
Timestep Consumption Time: 15.64962
PPO Batch Consumption Time: 2.30103
Total Iteration Time: 19.55776

Cumulative Model Updates: 7616
Cumulative Timesteps: 63839286

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 865.46794
Policy Entropy: 0.03734
Value Function Loss: 2.60323

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11360
Policy Update Magnitude: 0.06956
Value Function Update Magnitude: 0.07852

Collected Steps per Second: 15040.51262
Overall Steps per Second: 2573.91864

Timestep Collection Time: 3.32542
Timestep Consumption Time: 16.10643
PPO Batch Consumption Time: 2.34353
Total Iteration Time: 19.43185

Cumulative Model Updates: 7622
Cumulative Timesteps: 63889302

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.83558
Policy Entropy: 0.03527
Value Function Loss: 2.54406

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.17066
Policy Update Magnitude: 0.07285
Value Function Update Magnitude: 0.06926

Collected Steps per Second: 13184.27900
Overall Steps per Second: 2454.64776

Timestep Collection Time: 3.79846
Timestep Consumption Time: 16.60365
PPO Batch Consumption Time: 2.44017
Total Iteration Time: 20.40211

Cumulative Model Updates: 7628
Cumulative Timesteps: 63939382

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.16147
Policy Entropy: 0.03733
Value Function Loss: 2.62334

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12447
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.06676

Collected Steps per Second: 13101.20855
Overall Steps per Second: 2497.96110

Timestep Collection Time: 3.81843
Timestep Consumption Time: 16.20831
PPO Batch Consumption Time: 2.40228
Total Iteration Time: 20.02673

Cumulative Model Updates: 7634
Cumulative Timesteps: 63989408

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998.77223
Policy Entropy: 0.03970
Value Function Loss: 2.63497

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.06093
Value Function Update Magnitude: 0.06080

Collected Steps per Second: 12909.15185
Overall Steps per Second: 2494.80589

Timestep Collection Time: 3.87462
Timestep Consumption Time: 16.17424
PPO Batch Consumption Time: 2.37831
Total Iteration Time: 20.04885

Cumulative Model Updates: 7640
Cumulative Timesteps: 64039426

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 64039426...
Checkpoint 64039426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.41840
Policy Entropy: 0.04025
Value Function Loss: 2.72146

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10828
Policy Update Magnitude: 0.06629
Value Function Update Magnitude: 0.06375

Collected Steps per Second: 12599.17477
Overall Steps per Second: 2536.87698

Timestep Collection Time: 3.96947
Timestep Consumption Time: 15.74454
PPO Batch Consumption Time: 2.30017
Total Iteration Time: 19.71400

Cumulative Model Updates: 7646
Cumulative Timesteps: 64089438

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.16841
Policy Entropy: 0.04422
Value Function Loss: 2.75359

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.06802
Value Function Update Magnitude: 0.07038

Collected Steps per Second: 14023.66376
Overall Steps per Second: 2511.24597

Timestep Collection Time: 3.56654
Timestep Consumption Time: 16.35026
PPO Batch Consumption Time: 2.42187
Total Iteration Time: 19.91681

Cumulative Model Updates: 7652
Cumulative Timesteps: 64139454

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 813.65700
Policy Entropy: 0.04346
Value Function Loss: 2.74367

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.15051
Policy Update Magnitude: 0.06534
Value Function Update Magnitude: 0.07016

Collected Steps per Second: 15726.88448
Overall Steps per Second: 2548.46623

Timestep Collection Time: 3.18296
Timestep Consumption Time: 16.45945
PPO Batch Consumption Time: 2.43252
Total Iteration Time: 19.64240

Cumulative Model Updates: 7658
Cumulative Timesteps: 64189512

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370.43496
Policy Entropy: 0.04524
Value Function Loss: 2.70629

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.16582
Policy Update Magnitude: 0.06316
Value Function Update Magnitude: 0.06127

Collected Steps per Second: 15821.74874
Overall Steps per Second: 2472.63284

Timestep Collection Time: 3.16185
Timestep Consumption Time: 17.07003
PPO Batch Consumption Time: 2.57088
Total Iteration Time: 20.23188

Cumulative Model Updates: 7664
Cumulative Timesteps: 64239538

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.78451
Policy Entropy: 0.04514
Value Function Loss: 2.59680

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.17040
Policy Update Magnitude: 0.06526
Value Function Update Magnitude: 0.05931

Collected Steps per Second: 13724.87306
Overall Steps per Second: 2602.18933

Timestep Collection Time: 3.64827
Timestep Consumption Time: 15.59399
PPO Batch Consumption Time: 2.29636
Total Iteration Time: 19.24226

Cumulative Model Updates: 7670
Cumulative Timesteps: 64289610

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 733.53718
Policy Entropy: 0.04565
Value Function Loss: 2.65856

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12261
Policy Update Magnitude: 0.07147
Value Function Update Magnitude: 0.06167

Collected Steps per Second: 13166.42418
Overall Steps per Second: 2599.11404

Timestep Collection Time: 3.80042
Timestep Consumption Time: 15.45152
PPO Batch Consumption Time: 2.31024
Total Iteration Time: 19.25194

Cumulative Model Updates: 7676
Cumulative Timesteps: 64339648

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664.99642
Policy Entropy: 0.04699
Value Function Loss: 2.60385

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.15311
Policy Update Magnitude: 0.06866
Value Function Update Magnitude: 0.06549

Collected Steps per Second: 13653.44054
Overall Steps per Second: 2610.63967

Timestep Collection Time: 3.66340
Timestep Consumption Time: 15.49589
PPO Batch Consumption Time: 2.25995
Total Iteration Time: 19.15929

Cumulative Model Updates: 7682
Cumulative Timesteps: 64389666

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 882.32150
Policy Entropy: 0.04737
Value Function Loss: 2.69765

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.15209
Policy Update Magnitude: 0.05422
Value Function Update Magnitude: 0.06257

Collected Steps per Second: 13412.01789
Overall Steps per Second: 2594.29222

Timestep Collection Time: 3.73024
Timestep Consumption Time: 15.55441
PPO Batch Consumption Time: 2.28789
Total Iteration Time: 19.28464

Cumulative Model Updates: 7688
Cumulative Timesteps: 64439696

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 788.46356
Policy Entropy: 0.05165
Value Function Loss: 2.70301

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.05782
Value Function Update Magnitude: 0.06126

Collected Steps per Second: 14136.86512
Overall Steps per Second: 2611.90004

Timestep Collection Time: 3.53897
Timestep Consumption Time: 15.61566
PPO Batch Consumption Time: 2.29116
Total Iteration Time: 19.15464

Cumulative Model Updates: 7694
Cumulative Timesteps: 64489726

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492.21559
Policy Entropy: 0.05395
Value Function Loss: 2.70721

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.06124

Collected Steps per Second: 14430.83393
Overall Steps per Second: 2585.00095

Timestep Collection Time: 3.46771
Timestep Consumption Time: 15.89089
PPO Batch Consumption Time: 2.31892
Total Iteration Time: 19.35860

Cumulative Model Updates: 7700
Cumulative Timesteps: 64539768

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 64539768...
Checkpoint 64539768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663.19982
Policy Entropy: 0.05710
Value Function Loss: 2.65550

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12147
Policy Update Magnitude: 0.07124
Value Function Update Magnitude: 0.06535

Collected Steps per Second: 13548.05704
Overall Steps per Second: 2605.82596

Timestep Collection Time: 3.69367
Timestep Consumption Time: 15.51023
PPO Batch Consumption Time: 2.28417
Total Iteration Time: 19.20389

Cumulative Model Updates: 7706
Cumulative Timesteps: 64589810

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723.76318
Policy Entropy: 0.05793
Value Function Loss: 2.59684

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14951
Policy Update Magnitude: 0.07263
Value Function Update Magnitude: 0.06610

Collected Steps per Second: 13243.64417
Overall Steps per Second: 2534.34313

Timestep Collection Time: 3.78249
Timestep Consumption Time: 15.98357
PPO Batch Consumption Time: 2.37212
Total Iteration Time: 19.76607

Cumulative Model Updates: 7712
Cumulative Timesteps: 64639904

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 809.46218
Policy Entropy: 0.05798
Value Function Loss: 2.62407

Mean KL Divergence: 0.02159
SB3 Clip Fraction: 0.25501
Policy Update Magnitude: 0.07509
Value Function Update Magnitude: 0.06058

Collected Steps per Second: 13463.18068
Overall Steps per Second: 2582.37610

Timestep Collection Time: 3.72022
Timestep Consumption Time: 15.67510
PPO Batch Consumption Time: 2.32275
Total Iteration Time: 19.39532

Cumulative Model Updates: 7718
Cumulative Timesteps: 64689990

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.44802
Policy Entropy: 0.05840
Value Function Loss: 2.63572

Mean KL Divergence: 0.02119
SB3 Clip Fraction: 0.26650
Policy Update Magnitude: 0.05800
Value Function Update Magnitude: 0.05945

Collected Steps per Second: 13470.36317
Overall Steps per Second: 2535.41057

Timestep Collection Time: 3.71571
Timestep Consumption Time: 16.02547
PPO Batch Consumption Time: 2.34633
Total Iteration Time: 19.74118

Cumulative Model Updates: 7724
Cumulative Timesteps: 64740042

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.91129
Policy Entropy: 0.06076
Value Function Loss: 2.68060

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.15970
Policy Update Magnitude: 0.05903
Value Function Update Magnitude: 0.06497

Collected Steps per Second: 12989.30512
Overall Steps per Second: 2579.87494

Timestep Collection Time: 3.85209
Timestep Consumption Time: 15.54265
PPO Batch Consumption Time: 2.32153
Total Iteration Time: 19.39474

Cumulative Model Updates: 7730
Cumulative Timesteps: 64790078

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.06965
Policy Entropy: 0.06109
Value Function Loss: 2.67250

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.15706
Policy Update Magnitude: 0.06816
Value Function Update Magnitude: 0.06525

Collected Steps per Second: 13214.31305
Overall Steps per Second: 2525.42261

Timestep Collection Time: 3.78711
Timestep Consumption Time: 16.02898
PPO Batch Consumption Time: 2.36235
Total Iteration Time: 19.81609

Cumulative Model Updates: 7736
Cumulative Timesteps: 64840122

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.76649
Policy Entropy: 0.06212
Value Function Loss: 2.63885

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.06547
Value Function Update Magnitude: 0.06500

Collected Steps per Second: 15050.81768
Overall Steps per Second: 2607.73392

Timestep Collection Time: 3.32607
Timestep Consumption Time: 15.87068
PPO Batch Consumption Time: 2.32717
Total Iteration Time: 19.19674

Cumulative Model Updates: 7742
Cumulative Timesteps: 64890182

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376.60849
Policy Entropy: 0.06322
Value Function Loss: 2.60375

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.06232
Value Function Update Magnitude: 0.06090

Collected Steps per Second: 14005.82014
Overall Steps per Second: 2529.36498

Timestep Collection Time: 3.57251
Timestep Consumption Time: 16.20953
PPO Batch Consumption Time: 2.38752
Total Iteration Time: 19.78204

Cumulative Model Updates: 7748
Cumulative Timesteps: 64940218

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.86904
Policy Entropy: 0.06454
Value Function Loss: 2.62281

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14739
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.05895

Collected Steps per Second: 14025.78151
Overall Steps per Second: 1351.09354

Timestep Collection Time: 3.56501
Timestep Consumption Time: 33.44353
PPO Batch Consumption Time: 2.39027
Total Iteration Time: 37.00854

Cumulative Model Updates: 7754
Cumulative Timesteps: 64990220

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 429.84263
Policy Entropy: 0.06522
Value Function Loss: 2.64768

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.15921
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.06176

Collected Steps per Second: 13903.90498
Overall Steps per Second: 2543.52741

Timestep Collection Time: 3.59712
Timestep Consumption Time: 16.06613
PPO Batch Consumption Time: 2.38959
Total Iteration Time: 19.66324

Cumulative Model Updates: 7760
Cumulative Timesteps: 65040234

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 65040234...
Checkpoint 65040234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 922.08318
Policy Entropy: 0.06846
Value Function Loss: 2.58912

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.15684
Policy Update Magnitude: 0.04842
Value Function Update Magnitude: 0.06290

Collected Steps per Second: 13217.96144
Overall Steps per Second: 2568.12461

Timestep Collection Time: 3.78530
Timestep Consumption Time: 15.69740
PPO Batch Consumption Time: 2.32078
Total Iteration Time: 19.48270

Cumulative Model Updates: 7766
Cumulative Timesteps: 65090268

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 970.57555
Policy Entropy: 0.06738
Value Function Loss: 2.52960

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.14847
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.05687

Collected Steps per Second: 13014.47237
Overall Steps per Second: 2551.27402

Timestep Collection Time: 3.84618
Timestep Consumption Time: 15.77382
PPO Batch Consumption Time: 2.35908
Total Iteration Time: 19.62000

Cumulative Model Updates: 7772
Cumulative Timesteps: 65140324

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.03431
Policy Entropy: 0.07000
Value Function Loss: 2.56716

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.16750
Policy Update Magnitude: 0.07357
Value Function Update Magnitude: 0.05635

Collected Steps per Second: 13101.64738
Overall Steps per Second: 2469.74285

Timestep Collection Time: 3.81967
Timestep Consumption Time: 16.44317
PPO Batch Consumption Time: 2.40237
Total Iteration Time: 20.26284

Cumulative Model Updates: 7778
Cumulative Timesteps: 65190368

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523.66387
Policy Entropy: 0.07164
Value Function Loss: 2.58825

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.15049
Policy Update Magnitude: 0.06790
Value Function Update Magnitude: 0.05808

Collected Steps per Second: 12758.80195
Overall Steps per Second: 2459.85160

Timestep Collection Time: 3.92310
Timestep Consumption Time: 16.42529
PPO Batch Consumption Time: 2.42985
Total Iteration Time: 20.34838

Cumulative Model Updates: 7784
Cumulative Timesteps: 65240422

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663.38271
Policy Entropy: 0.07451
Value Function Loss: 2.63853

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14558
Policy Update Magnitude: 0.05986
Value Function Update Magnitude: 0.05947

Collected Steps per Second: 13752.17220
Overall Steps per Second: 2482.58957

Timestep Collection Time: 3.63797
Timestep Consumption Time: 16.51437
PPO Batch Consumption Time: 2.43648
Total Iteration Time: 20.15234

Cumulative Model Updates: 7790
Cumulative Timesteps: 65290452

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.28986
Policy Entropy: 0.07716
Value Function Loss: 2.58182

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10871
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.05892

Collected Steps per Second: 13065.85110
Overall Steps per Second: 2464.68193

Timestep Collection Time: 3.82922
Timestep Consumption Time: 16.47036
PPO Batch Consumption Time: 2.44153
Total Iteration Time: 20.29958

Cumulative Model Updates: 7796
Cumulative Timesteps: 65340484

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.69398
Policy Entropy: 0.07562
Value Function Loss: 2.49033

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.16032
Policy Update Magnitude: 0.06840
Value Function Update Magnitude: 0.06179

Collected Steps per Second: 12739.89590
Overall Steps per Second: 653.03175

Timestep Collection Time: 3.92876
Timestep Consumption Time: 72.71682
PPO Batch Consumption Time: 2.29990
Total Iteration Time: 76.64558

Cumulative Model Updates: 7802
Cumulative Timesteps: 65390536

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.39262
Policy Entropy: 0.07520
Value Function Loss: 2.41775

Mean KL Divergence: 0.03030
SB3 Clip Fraction: 0.32123
Policy Update Magnitude: 0.06283
Value Function Update Magnitude: 0.06196

Collected Steps per Second: 12989.98667
Overall Steps per Second: 2533.54460

Timestep Collection Time: 3.85343
Timestep Consumption Time: 15.90387
PPO Batch Consumption Time: 2.32717
Total Iteration Time: 19.75730

Cumulative Model Updates: 7808
Cumulative Timesteps: 65440592

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1179.31615
Policy Entropy: 0.07425
Value Function Loss: 2.56345

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.25892
Policy Update Magnitude: 0.05176
Value Function Update Magnitude: 0.05883

Collected Steps per Second: 12738.44952
Overall Steps per Second: 2526.34975

Timestep Collection Time: 3.93219
Timestep Consumption Time: 15.89484
PPO Batch Consumption Time: 2.33613
Total Iteration Time: 19.82703

Cumulative Model Updates: 7814
Cumulative Timesteps: 65490682

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1211.28388
Policy Entropy: 0.07691
Value Function Loss: 2.67048

Mean KL Divergence: 0.02290
SB3 Clip Fraction: 0.25225
Policy Update Magnitude: 0.04777
Value Function Update Magnitude: 0.06196

Collected Steps per Second: 13441.64199
Overall Steps per Second: 1840.55545

Timestep Collection Time: 3.72514
Timestep Consumption Time: 23.47969
PPO Batch Consumption Time: 2.42959
Total Iteration Time: 27.20483

Cumulative Model Updates: 7820
Cumulative Timesteps: 65540754

Timesteps Collected: 50072
--------END ITERATION REPORT--------


Saving checkpoint 65540754...
Checkpoint 65540754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.71191
Policy Entropy: 0.08014
Value Function Loss: 2.69416

Mean KL Divergence: 0.02816
SB3 Clip Fraction: 0.29814
Policy Update Magnitude: 0.04977
Value Function Update Magnitude: 0.06172

Collected Steps per Second: 12853.97359
Overall Steps per Second: 2433.13146

Timestep Collection Time: 3.89171
Timestep Consumption Time: 16.66780
PPO Batch Consumption Time: 2.46590
Total Iteration Time: 20.55951

Cumulative Model Updates: 7826
Cumulative Timesteps: 65590778

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.34754
Policy Entropy: 0.08333
Value Function Loss: 2.62789

Mean KL Divergence: 0.02297
SB3 Clip Fraction: 0.25665
Policy Update Magnitude: 0.05619
Value Function Update Magnitude: 0.06382

Collected Steps per Second: 12816.00787
Overall Steps per Second: 2473.32196

Timestep Collection Time: 3.90512
Timestep Consumption Time: 16.33002
PPO Batch Consumption Time: 2.44228
Total Iteration Time: 20.23513

Cumulative Model Updates: 7832
Cumulative Timesteps: 65640826

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 859.87200
Policy Entropy: 0.08478
Value Function Loss: 2.61100

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.21075
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.06539

Collected Steps per Second: 12975.78985
Overall Steps per Second: 2507.91532

Timestep Collection Time: 3.85487
Timestep Consumption Time: 16.08998
PPO Batch Consumption Time: 2.36182
Total Iteration Time: 19.94485

Cumulative Model Updates: 7838
Cumulative Timesteps: 65690846

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779.26761
Policy Entropy: 0.08666
Value Function Loss: 2.61631

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.19160
Policy Update Magnitude: 0.05360
Value Function Update Magnitude: 0.06379

Collected Steps per Second: 12681.90357
Overall Steps per Second: 2542.37196

Timestep Collection Time: 3.94909
Timestep Consumption Time: 15.74984
PPO Batch Consumption Time: 2.35512
Total Iteration Time: 19.69893

Cumulative Model Updates: 7844
Cumulative Timesteps: 65740928

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.63597
Policy Entropy: 0.08874
Value Function Loss: 2.57827

Mean KL Divergence: 0.01870
SB3 Clip Fraction: 0.23273
Policy Update Magnitude: 0.04792
Value Function Update Magnitude: 0.05933

Collected Steps per Second: 13160.63511
Overall Steps per Second: 664.97899

Timestep Collection Time: 3.80316
Timestep Consumption Time: 71.46538
PPO Batch Consumption Time: 2.39211
Total Iteration Time: 75.26854

Cumulative Model Updates: 7850
Cumulative Timesteps: 65790980

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699.16448
Policy Entropy: 0.09059
Value Function Loss: 2.56524

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.16637
Policy Update Magnitude: 0.04854
Value Function Update Magnitude: 0.05895

Collected Steps per Second: 12803.55113
Overall Steps per Second: 787.67370

Timestep Collection Time: 3.90548
Timestep Consumption Time: 59.57766
PPO Batch Consumption Time: 2.39438
Total Iteration Time: 63.48314

Cumulative Model Updates: 7856
Cumulative Timesteps: 65840984

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.27893
Policy Entropy: 0.09265
Value Function Loss: 2.55899

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.18512
Policy Update Magnitude: 0.04831
Value Function Update Magnitude: 0.05891

Collected Steps per Second: 13265.19989
Overall Steps per Second: 2543.63666

Timestep Collection Time: 3.77620
Timestep Consumption Time: 15.91687
PPO Batch Consumption Time: 2.34418
Total Iteration Time: 19.69306

Cumulative Model Updates: 7862
Cumulative Timesteps: 65891076

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.94082
Policy Entropy: 0.09501
Value Function Loss: 2.55227

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15889
Policy Update Magnitude: 0.05181
Value Function Update Magnitude: 0.06136

Collected Steps per Second: 12974.46725
Overall Steps per Second: 2454.94308

Timestep Collection Time: 3.85403
Timestep Consumption Time: 16.51467
PPO Batch Consumption Time: 2.44144
Total Iteration Time: 20.36870

Cumulative Model Updates: 7868
Cumulative Timesteps: 65941080

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.37563
Policy Entropy: 0.09785
Value Function Loss: 2.57286

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15654
Policy Update Magnitude: 0.05010
Value Function Update Magnitude: 0.06599

Collected Steps per Second: 13433.38105
Overall Steps per Second: 2489.05521

Timestep Collection Time: 3.72311
Timestep Consumption Time: 16.37045
PPO Batch Consumption Time: 2.41176
Total Iteration Time: 20.09357

Cumulative Model Updates: 7874
Cumulative Timesteps: 65991094

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 881.66541
Policy Entropy: 0.09707
Value Function Loss: 2.50274

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14150
Policy Update Magnitude: 0.06497
Value Function Update Magnitude: 0.06416

Collected Steps per Second: 12815.39517
Overall Steps per Second: 2479.70606

Timestep Collection Time: 3.90640
Timestep Consumption Time: 16.28229
PPO Batch Consumption Time: 2.40584
Total Iteration Time: 20.18868

Cumulative Model Updates: 7880
Cumulative Timesteps: 66041156

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 66041156...
Checkpoint 66041156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 432.37803
Policy Entropy: 0.09650
Value Function Loss: 2.58406

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.07086
Value Function Update Magnitude: 0.05889

Collected Steps per Second: 12747.22638
Overall Steps per Second: 2502.09466

Timestep Collection Time: 3.92415
Timestep Consumption Time: 16.06790
PPO Batch Consumption Time: 2.39560
Total Iteration Time: 19.99205

Cumulative Model Updates: 7886
Cumulative Timesteps: 66091178

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.14322
Policy Entropy: 0.09785
Value Function Loss: 2.55922

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.19667
Policy Update Magnitude: 0.07364
Value Function Update Magnitude: 0.06352

Collected Steps per Second: 12987.96407
Overall Steps per Second: 1422.44691

Timestep Collection Time: 3.85418
Timestep Consumption Time: 31.33729
PPO Batch Consumption Time: 2.41994
Total Iteration Time: 35.19147

Cumulative Model Updates: 7892
Cumulative Timesteps: 66141236

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 597.98439
Policy Entropy: 0.09857
Value Function Loss: 2.68146

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.22212
Policy Update Magnitude: 0.06510
Value Function Update Magnitude: 0.06463

Collected Steps per Second: 12801.08734
Overall Steps per Second: 2484.15195

Timestep Collection Time: 3.90764
Timestep Consumption Time: 16.22881
PPO Batch Consumption Time: 2.43297
Total Iteration Time: 20.13645

Cumulative Model Updates: 7898
Cumulative Timesteps: 66191258

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590.59869
Policy Entropy: 0.10418
Value Function Loss: 2.61962

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.23986
Policy Update Magnitude: 0.05482
Value Function Update Magnitude: 0.06532

Collected Steps per Second: 12926.92229
Overall Steps per Second: 2460.19120

Timestep Collection Time: 3.87641
Timestep Consumption Time: 16.49193
PPO Batch Consumption Time: 2.43606
Total Iteration Time: 20.36834

Cumulative Model Updates: 7904
Cumulative Timesteps: 66241368

Timesteps Collected: 50110
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.54696
Policy Entropy: 0.10443
Value Function Loss: 2.58872

Mean KL Divergence: 0.02570
SB3 Clip Fraction: 0.28455
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.07213

Collected Steps per Second: 12955.13028
Overall Steps per Second: 1893.53640

Timestep Collection Time: 3.86164
Timestep Consumption Time: 22.55877
PPO Batch Consumption Time: 2.32613
Total Iteration Time: 26.42041

Cumulative Model Updates: 7910
Cumulative Timesteps: 66291396

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593.17737
Policy Entropy: 0.10707
Value Function Loss: 2.54698

Mean KL Divergence: 0.02737
SB3 Clip Fraction: 0.28589
Policy Update Magnitude: 0.04760
Value Function Update Magnitude: 0.07001

Collected Steps per Second: 13153.52386
Overall Steps per Second: 2554.22141

Timestep Collection Time: 3.80689
Timestep Consumption Time: 15.79752
PPO Batch Consumption Time: 2.31810
Total Iteration Time: 19.60441

Cumulative Model Updates: 7916
Cumulative Timesteps: 66341470

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.06503
Policy Entropy: 0.10661
Value Function Loss: 2.50925

Mean KL Divergence: 0.02463
SB3 Clip Fraction: 0.28807
Policy Update Magnitude: 0.04407
Value Function Update Magnitude: 0.07195

Collected Steps per Second: 12836.23785
Overall Steps per Second: 2460.56352

Timestep Collection Time: 3.90083
Timestep Consumption Time: 16.44898
PPO Batch Consumption Time: 2.43303
Total Iteration Time: 20.34981

Cumulative Model Updates: 7922
Cumulative Timesteps: 66391542

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 859.19710
Policy Entropy: 0.10512
Value Function Loss: 2.43654

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.20555
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.06891

Collected Steps per Second: 13409.08723
Overall Steps per Second: 2507.16529

Timestep Collection Time: 3.73150
Timestep Consumption Time: 16.22570
PPO Batch Consumption Time: 2.38960
Total Iteration Time: 19.95720

Cumulative Model Updates: 7928
Cumulative Timesteps: 66441578

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.79659
Policy Entropy: 0.10590
Value Function Loss: 2.42819

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.21739
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.06603

Collected Steps per Second: 13002.57882
Overall Steps per Second: 2460.75801

Timestep Collection Time: 3.85093
Timestep Consumption Time: 16.49727
PPO Batch Consumption Time: 2.44696
Total Iteration Time: 20.34820

Cumulative Model Updates: 7934
Cumulative Timesteps: 66491650

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.64757
Policy Entropy: 0.10654
Value Function Loss: 2.42094

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.16821
Policy Update Magnitude: 0.05249
Value Function Update Magnitude: 0.06421

Collected Steps per Second: 12649.01340
Overall Steps per Second: 2457.47861

Timestep Collection Time: 3.95620
Timestep Consumption Time: 16.40695
PPO Batch Consumption Time: 2.45720
Total Iteration Time: 20.36315

Cumulative Model Updates: 7940
Cumulative Timesteps: 66541692

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 66541692...
Checkpoint 66541692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726.40361
Policy Entropy: 0.10923
Value Function Loss: 2.46250

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.06964
Value Function Update Magnitude: 0.06468

Collected Steps per Second: 12712.18270
Overall Steps per Second: 2447.31670

Timestep Collection Time: 3.93465
Timestep Consumption Time: 16.50324
PPO Batch Consumption Time: 2.44124
Total Iteration Time: 20.43789

Cumulative Model Updates: 7946
Cumulative Timesteps: 66591710

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.33493
Policy Entropy: 0.10878
Value Function Loss: 2.43043

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10229
Policy Update Magnitude: 0.06395
Value Function Update Magnitude: 0.06406

Collected Steps per Second: 12799.72090
Overall Steps per Second: 2530.26360

Timestep Collection Time: 3.91165
Timestep Consumption Time: 15.87601
PPO Batch Consumption Time: 2.34412
Total Iteration Time: 19.78766

Cumulative Model Updates: 7952
Cumulative Timesteps: 66641778

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 798.12658
Policy Entropy: 0.11124
Value Function Loss: 2.40712

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.15834
Policy Update Magnitude: 0.05607
Value Function Update Magnitude: 0.05896

Collected Steps per Second: 13740.20580
Overall Steps per Second: 908.28550

Timestep Collection Time: 3.63997
Timestep Consumption Time: 51.42421
PPO Batch Consumption Time: 2.38669
Total Iteration Time: 55.06418

Cumulative Model Updates: 7958
Cumulative Timesteps: 66691792

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 447.23258
Policy Entropy: 0.11029
Value Function Loss: 2.49381

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14380
Policy Update Magnitude: 0.05036
Value Function Update Magnitude: 0.06187

Collected Steps per Second: 12923.76399
Overall Steps per Second: 2534.97041

Timestep Collection Time: 3.86977
Timestep Consumption Time: 15.85906
PPO Batch Consumption Time: 2.32845
Total Iteration Time: 19.72883

Cumulative Model Updates: 7964
Cumulative Timesteps: 66741804

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607.83092
Policy Entropy: 0.11177
Value Function Loss: 2.57462

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.14570
Policy Update Magnitude: 0.05186
Value Function Update Magnitude: 0.06606

Collected Steps per Second: 12544.53016
Overall Steps per Second: 761.03473

Timestep Collection Time: 3.98755
Timestep Consumption Time: 61.74138
PPO Batch Consumption Time: 2.41074
Total Iteration Time: 65.72893

Cumulative Model Updates: 7970
Cumulative Timesteps: 66791826

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.00333
Policy Entropy: 0.11248
Value Function Loss: 2.64383

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.16552
Policy Update Magnitude: 0.06281
Value Function Update Magnitude: 0.07085

Collected Steps per Second: 12898.67082
Overall Steps per Second: 2483.75846

Timestep Collection Time: 3.88521
Timestep Consumption Time: 16.29147
PPO Batch Consumption Time: 2.39541
Total Iteration Time: 20.17668

Cumulative Model Updates: 7976
Cumulative Timesteps: 66841940

Timesteps Collected: 50114
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.18193
Policy Entropy: 0.11339
Value Function Loss: 2.59779

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.16324
Policy Update Magnitude: 0.06069
Value Function Update Magnitude: 0.06902

Collected Steps per Second: 12822.94417
Overall Steps per Second: 465.67136

Timestep Collection Time: 3.90020
Timestep Consumption Time: 103.49743
PPO Batch Consumption Time: 2.39994
Total Iteration Time: 107.39763

Cumulative Model Updates: 7982
Cumulative Timesteps: 66891952

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 861.42180
Policy Entropy: 0.11264
Value Function Loss: 2.57297

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14099
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.07987

Collected Steps per Second: 12829.81702
Overall Steps per Second: 2460.44940

Timestep Collection Time: 3.89842
Timestep Consumption Time: 16.42957
PPO Batch Consumption Time: 2.41902
Total Iteration Time: 20.32799

Cumulative Model Updates: 7988
Cumulative Timesteps: 66941968

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.54233
Policy Entropy: 0.11239
Value Function Loss: 2.49714

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.07095

Collected Steps per Second: 12644.73426
Overall Steps per Second: 1170.17808

Timestep Collection Time: 3.95611
Timestep Consumption Time: 38.79294
PPO Batch Consumption Time: 2.44415
Total Iteration Time: 42.74905

Cumulative Model Updates: 7994
Cumulative Timesteps: 66991992

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.94802
Policy Entropy: 0.11257
Value Function Loss: 2.49414

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12228
Policy Update Magnitude: 0.05725
Value Function Update Magnitude: 0.06940

Collected Steps per Second: 13134.18819
Overall Steps per Second: 2463.92817

Timestep Collection Time: 3.80975
Timestep Consumption Time: 16.49847
PPO Batch Consumption Time: 2.43066
Total Iteration Time: 20.30822

Cumulative Model Updates: 8000
Cumulative Timesteps: 67042030

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 67042030...
Checkpoint 67042030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705.65027
Policy Entropy: 0.11134
Value Function Loss: 2.51472

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.05750
Value Function Update Magnitude: 0.07267

Collected Steps per Second: 12749.40505
Overall Steps per Second: 1683.38590

Timestep Collection Time: 3.92442
Timestep Consumption Time: 25.79782
PPO Batch Consumption Time: 2.39995
Total Iteration Time: 29.72224

Cumulative Model Updates: 8006
Cumulative Timesteps: 67092064

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.47128
Policy Entropy: 0.11285
Value Function Loss: 2.54645

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14278
Policy Update Magnitude: 0.05398
Value Function Update Magnitude: 0.06562

Collected Steps per Second: 13617.12537
Overall Steps per Second: 2512.87094

Timestep Collection Time: 3.67390
Timestep Consumption Time: 16.23480
PPO Batch Consumption Time: 2.38800
Total Iteration Time: 19.90870

Cumulative Model Updates: 8012
Cumulative Timesteps: 67142092

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.05034
Policy Entropy: 0.10990
Value Function Loss: 2.63645

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14828
Policy Update Magnitude: 0.04907
Value Function Update Magnitude: 0.06699

Collected Steps per Second: 12803.53981
Overall Steps per Second: 2475.62339

Timestep Collection Time: 3.90751
Timestep Consumption Time: 16.30154
PPO Batch Consumption Time: 2.39379
Total Iteration Time: 20.20905

Cumulative Model Updates: 8018
Cumulative Timesteps: 67192122

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.29544
Policy Entropy: 0.11027
Value Function Loss: 2.65079

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.06906

Collected Steps per Second: 12624.24961
Overall Steps per Second: 2532.64850

Timestep Collection Time: 3.96142
Timestep Consumption Time: 15.78470
PPO Batch Consumption Time: 2.35737
Total Iteration Time: 19.74613

Cumulative Model Updates: 8024
Cumulative Timesteps: 67242132

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.29677
Policy Entropy: 0.11097
Value Function Loss: 2.65937

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.18025
Policy Update Magnitude: 0.04749
Value Function Update Magnitude: 0.07659

Collected Steps per Second: 12969.13556
Overall Steps per Second: 2475.42025

Timestep Collection Time: 3.85963
Timestep Consumption Time: 16.36159
PPO Batch Consumption Time: 2.40543
Total Iteration Time: 20.22121

Cumulative Model Updates: 8030
Cumulative Timesteps: 67292188

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 960.63517
Policy Entropy: 0.11153
Value Function Loss: 2.63543

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.17365
Policy Update Magnitude: 0.04511
Value Function Update Magnitude: 0.07061

Collected Steps per Second: 12858.57590
Overall Steps per Second: 2446.11377

Timestep Collection Time: 3.89234
Timestep Consumption Time: 16.56868
PPO Batch Consumption Time: 2.45392
Total Iteration Time: 20.46103

Cumulative Model Updates: 8036
Cumulative Timesteps: 67342238

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.87774
Policy Entropy: 0.11313
Value Function Loss: 2.62423

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.16642
Policy Update Magnitude: 0.04327
Value Function Update Magnitude: 0.07003

Collected Steps per Second: 13566.00052
Overall Steps per Second: 2466.50041

Timestep Collection Time: 3.68627
Timestep Consumption Time: 16.58861
PPO Batch Consumption Time: 2.44856
Total Iteration Time: 20.27488

Cumulative Model Updates: 8042
Cumulative Timesteps: 67392246

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 845.09770
Policy Entropy: 0.11475
Value Function Loss: 2.65302

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.16625
Policy Update Magnitude: 0.04753
Value Function Update Magnitude: 0.06889

Collected Steps per Second: 12934.85958
Overall Steps per Second: 2446.99810

Timestep Collection Time: 3.86552
Timestep Consumption Time: 16.56768
PPO Batch Consumption Time: 2.44919
Total Iteration Time: 20.43320

Cumulative Model Updates: 8048
Cumulative Timesteps: 67442246

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559.66420
Policy Entropy: 0.11566
Value Function Loss: 2.55968

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14899
Policy Update Magnitude: 0.04732
Value Function Update Magnitude: 0.06597

Collected Steps per Second: 13641.09001
Overall Steps per Second: 2509.92843

Timestep Collection Time: 3.66848
Timestep Consumption Time: 16.26915
PPO Batch Consumption Time: 2.38983
Total Iteration Time: 19.93762

Cumulative Model Updates: 8054
Cumulative Timesteps: 67492288

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704.68555
Policy Entropy: 0.11641
Value Function Loss: 2.49365

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.15007
Policy Update Magnitude: 0.04782
Value Function Update Magnitude: 0.06859

Collected Steps per Second: 12828.86087
Overall Steps per Second: 555.41777

Timestep Collection Time: 3.90089
Timestep Consumption Time: 86.20065
PPO Batch Consumption Time: 2.41546
Total Iteration Time: 90.10155

Cumulative Model Updates: 8060
Cumulative Timesteps: 67542332

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 67542332...
Checkpoint 67542332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 865.20305
Policy Entropy: 0.11496
Value Function Loss: 2.49953

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.15564
Policy Update Magnitude: 0.04512
Value Function Update Magnitude: 0.07053

Collected Steps per Second: 13836.96287
Overall Steps per Second: 2505.64437

Timestep Collection Time: 3.61582
Timestep Consumption Time: 16.35190
PPO Batch Consumption Time: 2.40810
Total Iteration Time: 19.96772

Cumulative Model Updates: 8066
Cumulative Timesteps: 67592364

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 838.55548
Policy Entropy: 0.11899
Value Function Loss: 2.51262

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15628
Policy Update Magnitude: 0.04650
Value Function Update Magnitude: 0.07076

Collected Steps per Second: 13083.40408
Overall Steps per Second: 856.05237

Timestep Collection Time: 3.82714
Timestep Consumption Time: 54.66461
PPO Batch Consumption Time: 2.37960
Total Iteration Time: 58.49175

Cumulative Model Updates: 8072
Cumulative Timesteps: 67642436

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.05259
Policy Entropy: 0.11821
Value Function Loss: 2.57939

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.15049
Policy Update Magnitude: 0.04899
Value Function Update Magnitude: 0.07155

Collected Steps per Second: 13043.59238
Overall Steps per Second: 2537.61581

Timestep Collection Time: 3.83637
Timestep Consumption Time: 15.88293
PPO Batch Consumption Time: 2.36699
Total Iteration Time: 19.71930

Cumulative Model Updates: 8078
Cumulative Timesteps: 67692476

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1019.24596
Policy Entropy: 0.12039
Value Function Loss: 2.57766

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13735
Policy Update Magnitude: 0.05388
Value Function Update Magnitude: 0.07346

Collected Steps per Second: 13175.41448
Overall Steps per Second: 1215.14727

Timestep Collection Time: 3.79722
Timestep Consumption Time: 37.37474
PPO Batch Consumption Time: 2.44060
Total Iteration Time: 41.17196

Cumulative Model Updates: 8084
Cumulative Timesteps: 67742506

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689.70111
Policy Entropy: 0.12171
Value Function Loss: 2.56929

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.05339
Value Function Update Magnitude: 0.06992

Collected Steps per Second: 12955.90746
Overall Steps per Second: 1492.97568

Timestep Collection Time: 3.85986
Timestep Consumption Time: 29.63566
PPO Batch Consumption Time: 4.62681
Total Iteration Time: 33.49552

Cumulative Model Updates: 8090
Cumulative Timesteps: 67792514

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562.45256
Policy Entropy: 0.12218
Value Function Loss: 2.55051

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.05266
Value Function Update Magnitude: 0.07259

Collected Steps per Second: 13645.82236
Overall Steps per Second: 2458.36767

Timestep Collection Time: 3.66662
Timestep Consumption Time: 16.68591
PPO Batch Consumption Time: 2.45474
Total Iteration Time: 20.35253

Cumulative Model Updates: 8096
Cumulative Timesteps: 67842548

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.03063
Policy Entropy: 0.12359
Value Function Loss: 2.49922

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.15911
Policy Update Magnitude: 0.07211
Value Function Update Magnitude: 0.07009

Collected Steps per Second: 12979.88191
Overall Steps per Second: 1339.20296

Timestep Collection Time: 3.85366
Timestep Consumption Time: 33.49692
PPO Batch Consumption Time: 2.41486
Total Iteration Time: 37.35057

Cumulative Model Updates: 8102
Cumulative Timesteps: 67892568

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 575.63991
Policy Entropy: 0.12270
Value Function Loss: 2.49786

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13537
Policy Update Magnitude: 0.05707
Value Function Update Magnitude: 0.06950

Collected Steps per Second: 13003.26913
Overall Steps per Second: 2508.31039

Timestep Collection Time: 3.85103
Timestep Consumption Time: 16.11300
PPO Batch Consumption Time: 2.41132
Total Iteration Time: 19.96404

Cumulative Model Updates: 8108
Cumulative Timesteps: 67942644

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.55617
Policy Entropy: 0.12288
Value Function Loss: 2.53794

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.14876
Policy Update Magnitude: 0.04910
Value Function Update Magnitude: 0.06435

Collected Steps per Second: 12997.91312
Overall Steps per Second: 1377.59753

Timestep Collection Time: 3.85123
Timestep Consumption Time: 32.48594
PPO Batch Consumption Time: 2.45507
Total Iteration Time: 36.33717

Cumulative Model Updates: 8114
Cumulative Timesteps: 67992702

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.91908
Policy Entropy: 0.12368
Value Function Loss: 2.55764

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.15236
Policy Update Magnitude: 0.04661
Value Function Update Magnitude: 0.06516

Collected Steps per Second: 12828.84199
Overall Steps per Second: 2522.32097

Timestep Collection Time: 3.89809
Timestep Consumption Time: 15.92809
PPO Batch Consumption Time: 2.37527
Total Iteration Time: 19.82618

Cumulative Model Updates: 8120
Cumulative Timesteps: 68042710

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 68042710...
Checkpoint 68042710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 801.52935
Policy Entropy: 0.12670
Value Function Loss: 2.58622

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.15902
Policy Update Magnitude: 0.04579
Value Function Update Magnitude: 0.07183

Collected Steps per Second: 12939.67781
Overall Steps per Second: 2059.30601

Timestep Collection Time: 3.86486
Timestep Consumption Time: 20.42002
PPO Batch Consumption Time: 2.41908
Total Iteration Time: 24.28488

Cumulative Model Updates: 8126
Cumulative Timesteps: 68092720

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.78787
Policy Entropy: 0.12915
Value Function Loss: 2.55562

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.17241
Policy Update Magnitude: 0.05960
Value Function Update Magnitude: 0.06855

Collected Steps per Second: 12893.53723
Overall Steps per Second: 2478.75352

Timestep Collection Time: 3.88396
Timestep Consumption Time: 16.31893
PPO Batch Consumption Time: 2.40422
Total Iteration Time: 20.20290

Cumulative Model Updates: 8132
Cumulative Timesteps: 68142798

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762.89136
Policy Entropy: 0.12993
Value Function Loss: 2.48321

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.15622
Policy Update Magnitude: 0.06897
Value Function Update Magnitude: 0.06917

Collected Steps per Second: 13652.32579
Overall Steps per Second: 1673.33245

Timestep Collection Time: 3.66472
Timestep Consumption Time: 26.23489
PPO Batch Consumption Time: 2.34436
Total Iteration Time: 29.89962

Cumulative Model Updates: 8138
Cumulative Timesteps: 68192830

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.11244
Policy Entropy: 0.12851
Value Function Loss: 2.50362

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08752
Policy Update Magnitude: 0.07559
Value Function Update Magnitude: 0.06743

Collected Steps per Second: 12872.25297
Overall Steps per Second: 2529.22715

Timestep Collection Time: 3.88914
Timestep Consumption Time: 15.90426
PPO Batch Consumption Time: 2.33998
Total Iteration Time: 19.79340

Cumulative Model Updates: 8144
Cumulative Timesteps: 68242892

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.12189
Policy Entropy: 0.12824
Value Function Loss: 2.46556

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.08496
Value Function Update Magnitude: 0.06628

Collected Steps per Second: 12607.95005
Overall Steps per Second: 420.63925

Timestep Collection Time: 3.96940
Timestep Consumption Time: 115.00666
PPO Batch Consumption Time: 2.38037
Total Iteration Time: 118.97606

Cumulative Model Updates: 8150
Cumulative Timesteps: 68292938

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 864.73581
Policy Entropy: 0.12884
Value Function Loss: 2.51956

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.17313
Policy Update Magnitude: 0.07570
Value Function Update Magnitude: 0.06716

Collected Steps per Second: 12875.67394
Overall Steps per Second: 2538.68338

Timestep Collection Time: 3.88547
Timestep Consumption Time: 15.82081
PPO Batch Consumption Time: 2.31875
Total Iteration Time: 19.70628

Cumulative Model Updates: 8156
Cumulative Timesteps: 68342966

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 903.36571
Policy Entropy: 0.12927
Value Function Loss: 2.46668

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.19149
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.07058

Collected Steps per Second: 12925.11207
Overall Steps per Second: 767.66048

Timestep Collection Time: 3.87060
Timestep Consumption Time: 61.29883
PPO Batch Consumption Time: 2.35926
Total Iteration Time: 65.16944

Cumulative Model Updates: 8162
Cumulative Timesteps: 68392994

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.17084
Policy Entropy: 0.13154
Value Function Loss: 2.54913

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.18596
Policy Update Magnitude: 0.04625
Value Function Update Magnitude: 0.06944

Collected Steps per Second: 13327.64651
Overall Steps per Second: 2523.96451

Timestep Collection Time: 3.75220
Timestep Consumption Time: 16.06107
PPO Batch Consumption Time: 2.36177
Total Iteration Time: 19.81327

Cumulative Model Updates: 8168
Cumulative Timesteps: 68443002

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 877.06817
Policy Entropy: 0.12937
Value Function Loss: 2.47801

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.19392
Policy Update Magnitude: 0.04538
Value Function Update Magnitude: 0.07109

Collected Steps per Second: 12829.63954
Overall Steps per Second: 197.26340

Timestep Collection Time: 3.90783
Timestep Consumption Time: 250.24981
PPO Batch Consumption Time: 2.37722
Total Iteration Time: 254.15764

Cumulative Model Updates: 8174
Cumulative Timesteps: 68493138

Timesteps Collected: 50136
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761.50210
Policy Entropy: 0.12896
Value Function Loss: 2.50731

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.16137
Policy Update Magnitude: 0.04428
Value Function Update Magnitude: 0.06799

Collected Steps per Second: 13385.27260
Overall Steps per Second: 2499.28958

Timestep Collection Time: 3.74053
Timestep Consumption Time: 16.29236
PPO Batch Consumption Time: 2.39076
Total Iteration Time: 20.03289

Cumulative Model Updates: 8180
Cumulative Timesteps: 68543206

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 68543206...
Checkpoint 68543206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 808.19242
Policy Entropy: 0.12997
Value Function Loss: 2.46056

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14891
Policy Update Magnitude: 0.05187
Value Function Update Magnitude: 0.06885

Collected Steps per Second: 12910.51014
Overall Steps per Second: 1911.07304

Timestep Collection Time: 3.87390
Timestep Consumption Time: 22.29674
PPO Batch Consumption Time: 2.30508
Total Iteration Time: 26.17064

Cumulative Model Updates: 8186
Cumulative Timesteps: 68593220

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.61147
Policy Entropy: 0.13130
Value Function Loss: 2.58327

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.06511
Value Function Update Magnitude: 0.07770

Collected Steps per Second: 13647.73460
Overall Steps per Second: 2530.28480

Timestep Collection Time: 3.66889
Timestep Consumption Time: 16.12019
PPO Batch Consumption Time: 2.35374
Total Iteration Time: 19.78908

Cumulative Model Updates: 8192
Cumulative Timesteps: 68643292

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525.10339
Policy Entropy: 0.13344
Value Function Loss: 2.51481

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14978
Policy Update Magnitude: 0.06580
Value Function Update Magnitude: 0.07833

Collected Steps per Second: 12940.10475
Overall Steps per Second: 2453.56413

Timestep Collection Time: 3.87431
Timestep Consumption Time: 16.55882
PPO Batch Consumption Time: 2.41240
Total Iteration Time: 20.43313

Cumulative Model Updates: 8198
Cumulative Timesteps: 68693426

Timesteps Collected: 50134
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.57688
Policy Entropy: 0.13454
Value Function Loss: 2.50143

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14241
Policy Update Magnitude: 0.06745
Value Function Update Magnitude: 0.07576

Collected Steps per Second: 12969.13102
Overall Steps per Second: 2493.81568

Timestep Collection Time: 3.85870
Timestep Consumption Time: 16.20854
PPO Batch Consumption Time: 2.42130
Total Iteration Time: 20.06724

Cumulative Model Updates: 8204
Cumulative Timesteps: 68743470

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624.40572
Policy Entropy: 0.13520
Value Function Loss: 2.47098

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11186
Policy Update Magnitude: 0.07878
Value Function Update Magnitude: 0.06905

Collected Steps per Second: 12580.29221
Overall Steps per Second: 2437.42130

Timestep Collection Time: 3.97590
Timestep Consumption Time: 16.54497
PPO Batch Consumption Time: 2.44104
Total Iteration Time: 20.52087

Cumulative Model Updates: 8210
Cumulative Timesteps: 68793488

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 862.34778
Policy Entropy: 0.13711
Value Function Loss: 2.55405

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11656
Policy Update Magnitude: 0.07164
Value Function Update Magnitude: 0.08348

Collected Steps per Second: 12665.76878
Overall Steps per Second: 2513.07783

Timestep Collection Time: 3.95160
Timestep Consumption Time: 15.96422
PPO Batch Consumption Time: 2.38337
Total Iteration Time: 19.91582

Cumulative Model Updates: 8216
Cumulative Timesteps: 68843538

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 830.03829
Policy Entropy: 0.13965
Value Function Loss: 2.60099

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 0.07216
Value Function Update Magnitude: 0.09239

Collected Steps per Second: 13105.93590
Overall Steps per Second: 1623.69841

Timestep Collection Time: 3.81995
Timestep Consumption Time: 27.01336
PPO Batch Consumption Time: 2.41918
Total Iteration Time: 30.83331

Cumulative Model Updates: 8222
Cumulative Timesteps: 68893602

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1024.70875
Policy Entropy: 0.13861
Value Function Loss: 2.53054

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.07074
Value Function Update Magnitude: 0.09082

Collected Steps per Second: 12632.55612
Overall Steps per Second: 2512.23393

Timestep Collection Time: 3.95834
Timestep Consumption Time: 15.94585
PPO Batch Consumption Time: 2.34883
Total Iteration Time: 19.90420

Cumulative Model Updates: 8228
Cumulative Timesteps: 68943606

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730.36829
Policy Entropy: 0.13925
Value Function Loss: 2.43927

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.15277
Policy Update Magnitude: 0.05839
Value Function Update Magnitude: 0.07560

Collected Steps per Second: 14020.06303
Overall Steps per Second: 2525.31485

Timestep Collection Time: 3.56974
Timestep Consumption Time: 16.24878
PPO Batch Consumption Time: 2.39729
Total Iteration Time: 19.81852

Cumulative Model Updates: 8234
Cumulative Timesteps: 68993654

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.00996
Policy Entropy: 0.14015
Value Function Loss: 2.39647

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.15224
Policy Update Magnitude: 0.05287
Value Function Update Magnitude: 0.06993

Collected Steps per Second: 12676.58269
Overall Steps per Second: 2508.88752

Timestep Collection Time: 3.94917
Timestep Consumption Time: 16.00469
PPO Batch Consumption Time: 2.36028
Total Iteration Time: 19.95386

Cumulative Model Updates: 8240
Cumulative Timesteps: 69043716

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 69043716...
Checkpoint 69043716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 543.11591
Policy Entropy: 0.13915
Value Function Loss: 2.45756

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.16025
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.07170

Collected Steps per Second: 13514.34344
Overall Steps per Second: 2464.58248

Timestep Collection Time: 3.70066
Timestep Consumption Time: 16.59162
PPO Batch Consumption Time: 2.45351
Total Iteration Time: 20.29228

Cumulative Model Updates: 8246
Cumulative Timesteps: 69093728

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.20629
Policy Entropy: 0.13866
Value Function Loss: 2.45129

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.16277
Policy Update Magnitude: 0.04927
Value Function Update Magnitude: 0.07282

Collected Steps per Second: 12856.29834
Overall Steps per Second: 2445.18918

Timestep Collection Time: 3.89334
Timestep Consumption Time: 16.57706
PPO Batch Consumption Time: 2.44144
Total Iteration Time: 20.47040

Cumulative Model Updates: 8252
Cumulative Timesteps: 69143782

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.34296
Policy Entropy: 0.13987
Value Function Loss: 2.43723

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.16702
Policy Update Magnitude: 0.04773
Value Function Update Magnitude: 0.07082

Collected Steps per Second: 12999.30200
Overall Steps per Second: 2556.08234

Timestep Collection Time: 3.84805
Timestep Consumption Time: 15.72174
PPO Batch Consumption Time: 2.34710
Total Iteration Time: 19.56979

Cumulative Model Updates: 8258
Cumulative Timesteps: 69193804

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 474.84153
Policy Entropy: 0.13939
Value Function Loss: 2.46040

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.17022
Policy Update Magnitude: 0.04598
Value Function Update Magnitude: 0.06822

Collected Steps per Second: 12739.42289
Overall Steps per Second: 2458.37930

Timestep Collection Time: 3.93283
Timestep Consumption Time: 16.44726
PPO Batch Consumption Time: 2.42248
Total Iteration Time: 20.38009

Cumulative Model Updates: 8264
Cumulative Timesteps: 69243906

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1117.14853
Policy Entropy: 0.14213
Value Function Loss: 2.48729

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15713
Policy Update Magnitude: 0.04993
Value Function Update Magnitude: 0.06782

Collected Steps per Second: 12901.05140
Overall Steps per Second: 2502.34260

Timestep Collection Time: 3.87627
Timestep Consumption Time: 16.10820
PPO Batch Consumption Time: 2.41036
Total Iteration Time: 19.98447

Cumulative Model Updates: 8270
Cumulative Timesteps: 69293914

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.97743
Policy Entropy: 0.14250
Value Function Loss: 2.49004

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14608
Policy Update Magnitude: 0.05282
Value Function Update Magnitude: 0.06915

Collected Steps per Second: 12922.89352
Overall Steps per Second: 2479.84249

Timestep Collection Time: 3.87514
Timestep Consumption Time: 16.31889
PPO Batch Consumption Time: 2.39685
Total Iteration Time: 20.19402

Cumulative Model Updates: 8276
Cumulative Timesteps: 69343992

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667.83637
Policy Entropy: 0.14165
Value Function Loss: 2.45421

Mean KL Divergence: 0.02147
SB3 Clip Fraction: 0.24711
Policy Update Magnitude: 0.04838
Value Function Update Magnitude: 0.06971

Collected Steps per Second: 12665.22165
Overall Steps per Second: 2511.57280

Timestep Collection Time: 3.95256
Timestep Consumption Time: 15.97918
PPO Batch Consumption Time: 2.40400
Total Iteration Time: 19.93173

Cumulative Model Updates: 8282
Cumulative Timesteps: 69394052

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.46775
Policy Entropy: 0.14026
Value Function Loss: 2.47422

Mean KL Divergence: 0.02873
SB3 Clip Fraction: 0.26483
Policy Update Magnitude: 0.03910
Value Function Update Magnitude: 0.07253

Collected Steps per Second: 16706.49558
Overall Steps per Second: 2566.31328

Timestep Collection Time: 2.99728
Timestep Consumption Time: 16.51476
PPO Batch Consumption Time: 2.42506
Total Iteration Time: 19.51204

Cumulative Model Updates: 8288
Cumulative Timesteps: 69444126

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 456.21096
Policy Entropy: 0.13960
Value Function Loss: 2.50191

Mean KL Divergence: 0.02822
SB3 Clip Fraction: 0.26302
Policy Update Magnitude: 0.04064
Value Function Update Magnitude: 0.07012

Collected Steps per Second: 13814.62965
Overall Steps per Second: 2467.39194

Timestep Collection Time: 3.62152
Timestep Consumption Time: 16.65495
PPO Batch Consumption Time: 2.43326
Total Iteration Time: 20.27647

Cumulative Model Updates: 8294
Cumulative Timesteps: 69494156

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.28491
Policy Entropy: 0.14013
Value Function Loss: 2.52725

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11170
Policy Update Magnitude: 0.06562
Value Function Update Magnitude: 0.06670

Collected Steps per Second: 13214.00425
Overall Steps per Second: 2485.05859

Timestep Collection Time: 3.78825
Timestep Consumption Time: 16.35534
PPO Batch Consumption Time: 2.38916
Total Iteration Time: 20.14359

Cumulative Model Updates: 8300
Cumulative Timesteps: 69544214

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 69544214...
Checkpoint 69544214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 772.60009
Policy Entropy: 0.14029
Value Function Loss: 2.54963

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.15620
Policy Update Magnitude: 0.06586
Value Function Update Magnitude: 0.07032

Collected Steps per Second: 13585.48914
Overall Steps per Second: 2502.30259

Timestep Collection Time: 3.68202
Timestep Consumption Time: 16.30837
PPO Batch Consumption Time: 2.38699
Total Iteration Time: 19.99039

Cumulative Model Updates: 8306
Cumulative Timesteps: 69594236

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.13004
Policy Entropy: 0.14133
Value Function Loss: 2.58438

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13821
Policy Update Magnitude: 0.06517
Value Function Update Magnitude: 0.07063

Collected Steps per Second: 12475.51883
Overall Steps per Second: 2548.02560

Timestep Collection Time: 4.01218
Timestep Consumption Time: 15.63205
PPO Batch Consumption Time: 2.34215
Total Iteration Time: 19.64423

Cumulative Model Updates: 8312
Cumulative Timesteps: 69644290

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.82007
Policy Entropy: 0.14196
Value Function Loss: 2.58055

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.18496
Policy Update Magnitude: 0.06316
Value Function Update Magnitude: 0.07374

Collected Steps per Second: 12615.54078
Overall Steps per Second: 2553.28635

Timestep Collection Time: 3.96416
Timestep Consumption Time: 15.62236
PPO Batch Consumption Time: 2.29839
Total Iteration Time: 19.58652

Cumulative Model Updates: 8318
Cumulative Timesteps: 69694300

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.01397
Policy Entropy: 0.14409
Value Function Loss: 2.55015

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.17043
Policy Update Magnitude: 0.05648
Value Function Update Magnitude: 0.07385

Collected Steps per Second: 12209.00179
Overall Steps per Second: 2494.51837

Timestep Collection Time: 4.09681
Timestep Consumption Time: 15.95435
PPO Batch Consumption Time: 2.38133
Total Iteration Time: 20.05117

Cumulative Model Updates: 8324
Cumulative Timesteps: 69744318

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455.50578
Policy Entropy: 0.14467
Value Function Loss: 2.49140

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.15936
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.06728

Collected Steps per Second: 12475.79711
Overall Steps per Second: 2507.77633

Timestep Collection Time: 4.01032
Timestep Consumption Time: 15.94042
PPO Batch Consumption Time: 2.34120
Total Iteration Time: 19.95074

Cumulative Model Updates: 8330
Cumulative Timesteps: 69794350

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.46443
Policy Entropy: 0.14461
Value Function Loss: 2.56514

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.19025
Policy Update Magnitude: 0.05680
Value Function Update Magnitude: 0.07008

Collected Steps per Second: 15576.50560
Overall Steps per Second: 2607.08744

Timestep Collection Time: 3.21227
Timestep Consumption Time: 15.98002
PPO Batch Consumption Time: 2.38607
Total Iteration Time: 19.19230

Cumulative Model Updates: 8336
Cumulative Timesteps: 69844386

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711.59704
Policy Entropy: 0.14415
Value Function Loss: 2.53125

Mean KL Divergence: 0.02615
SB3 Clip Fraction: 0.28246
Policy Update Magnitude: 0.05487
Value Function Update Magnitude: 0.07149

Collected Steps per Second: 13927.52602
Overall Steps per Second: 2506.15731

Timestep Collection Time: 3.59303
Timestep Consumption Time: 16.37459
PPO Batch Consumption Time: 2.39844
Total Iteration Time: 19.96762

Cumulative Model Updates: 8342
Cumulative Timesteps: 69894428

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.07149
Policy Entropy: 0.14529
Value Function Loss: 2.54552

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.06845

Collected Steps per Second: 13052.84460
Overall Steps per Second: 2478.39182

Timestep Collection Time: 3.83395
Timestep Consumption Time: 16.35817
PPO Batch Consumption Time: 2.42543
Total Iteration Time: 20.19213

Cumulative Model Updates: 8348
Cumulative Timesteps: 69944472

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711.17292
Policy Entropy: 0.14508
Value Function Loss: 2.47916

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.05536
Value Function Update Magnitude: 0.06899

Collected Steps per Second: 14501.81867
Overall Steps per Second: 2500.94788

Timestep Collection Time: 3.45336
Timestep Consumption Time: 16.57105
PPO Batch Consumption Time: 2.42878
Total Iteration Time: 20.02441

Cumulative Model Updates: 8354
Cumulative Timesteps: 69994552

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647.13908
Policy Entropy: 0.14605
Value Function Loss: 2.48301

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.17427
Policy Update Magnitude: 0.05455
Value Function Update Magnitude: 0.07255

Collected Steps per Second: 12925.68898
Overall Steps per Second: 2497.66153

Timestep Collection Time: 3.86950
Timestep Consumption Time: 16.15563
PPO Batch Consumption Time: 2.39564
Total Iteration Time: 20.02513

Cumulative Model Updates: 8360
Cumulative Timesteps: 70044568

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 70044568...
Checkpoint 70044568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.09188
Policy Entropy: 0.14867
Value Function Loss: 2.46256

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.18012
Policy Update Magnitude: 0.05518
Value Function Update Magnitude: 0.06933

Collected Steps per Second: 13386.60216
Overall Steps per Second: 2556.96959

Timestep Collection Time: 3.73911
Timestep Consumption Time: 15.83640
PPO Batch Consumption Time: 2.32187
Total Iteration Time: 19.57552

Cumulative Model Updates: 8366
Cumulative Timesteps: 70094622

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.95973
Policy Entropy: 0.14975
Value Function Loss: 2.49711

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.17869
Policy Update Magnitude: 0.05032
Value Function Update Magnitude: 0.07216

Collected Steps per Second: 12721.87777
Overall Steps per Second: 2560.23513

Timestep Collection Time: 3.93370
Timestep Consumption Time: 15.61295
PPO Batch Consumption Time: 2.30081
Total Iteration Time: 19.54664

Cumulative Model Updates: 8372
Cumulative Timesteps: 70144666

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.07002
Policy Entropy: 0.15189
Value Function Loss: 2.45357

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.17153
Policy Update Magnitude: 0.05094
Value Function Update Magnitude: 0.07539

Collected Steps per Second: 12397.84700
Overall Steps per Second: 2523.91446

Timestep Collection Time: 4.03425
Timestep Consumption Time: 15.78259
PPO Batch Consumption Time: 2.36548
Total Iteration Time: 19.81684

Cumulative Model Updates: 8378
Cumulative Timesteps: 70194682

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.72801
Policy Entropy: 0.15103
Value Function Loss: 2.44686

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.16270
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.06931

Collected Steps per Second: 13950.47899
Overall Steps per Second: 2477.63980

Timestep Collection Time: 3.58869
Timestep Consumption Time: 16.61763
PPO Batch Consumption Time: 2.43644
Total Iteration Time: 20.20633

Cumulative Model Updates: 8384
Cumulative Timesteps: 70244746

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.04040
Policy Entropy: 0.15147
Value Function Loss: 2.42050

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.17771
Policy Update Magnitude: 0.05706
Value Function Update Magnitude: 0.06624

Collected Steps per Second: 13181.64759
Overall Steps per Second: 2484.95595

Timestep Collection Time: 3.79315
Timestep Consumption Time: 16.32793
PPO Batch Consumption Time: 2.44720
Total Iteration Time: 20.12108

Cumulative Model Updates: 8390
Cumulative Timesteps: 70294746

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 739.24166
Policy Entropy: 0.15144
Value Function Loss: 2.50441

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.17831
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.06626

Collected Steps per Second: 13929.92766
Overall Steps per Second: 2499.17666

Timestep Collection Time: 3.59485
Timestep Consumption Time: 16.44215
PPO Batch Consumption Time: 2.42561
Total Iteration Time: 20.03700

Cumulative Model Updates: 8396
Cumulative Timesteps: 70344822

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410.08617
Policy Entropy: 0.14975
Value Function Loss: 2.53090

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.17748
Policy Update Magnitude: 0.06381
Value Function Update Magnitude: 0.06722

Collected Steps per Second: 14952.55254
Overall Steps per Second: 2550.96264

Timestep Collection Time: 3.34578
Timestep Consumption Time: 16.26564
PPO Batch Consumption Time: 2.42595
Total Iteration Time: 19.61142

Cumulative Model Updates: 8402
Cumulative Timesteps: 70394850

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.34792
Policy Entropy: 0.15210
Value Function Loss: 2.58535

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14844
Policy Update Magnitude: 0.05753
Value Function Update Magnitude: 0.07213

Collected Steps per Second: 14399.77866
Overall Steps per Second: 2527.99360

Timestep Collection Time: 3.47311
Timestep Consumption Time: 16.31017
PPO Batch Consumption Time: 2.41531
Total Iteration Time: 19.78328

Cumulative Model Updates: 8408
Cumulative Timesteps: 70444862

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.61391
Policy Entropy: 0.15193
Value Function Loss: 2.56864

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13636
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.07335

Collected Steps per Second: 12698.36086
Overall Steps per Second: 2477.67158

Timestep Collection Time: 3.94082
Timestep Consumption Time: 16.25636
PPO Batch Consumption Time: 2.39910
Total Iteration Time: 20.19719

Cumulative Model Updates: 8414
Cumulative Timesteps: 70494904

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.74595
Policy Entropy: 0.15312
Value Function Loss: 2.53075

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.16925
Policy Update Magnitude: 0.05764
Value Function Update Magnitude: 0.08113

Collected Steps per Second: 13448.19681
Overall Steps per Second: 2528.96448

Timestep Collection Time: 3.71871
Timestep Consumption Time: 16.05618
PPO Batch Consumption Time: 2.35882
Total Iteration Time: 19.77489

Cumulative Model Updates: 8420
Cumulative Timesteps: 70544914

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 70544914...
Checkpoint 70544914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.50819
Policy Entropy: 0.15063
Value Function Loss: 2.51213

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.05878
Value Function Update Magnitude: 0.07121

Collected Steps per Second: 12451.91169
Overall Steps per Second: 2570.45231

Timestep Collection Time: 4.01721
Timestep Consumption Time: 15.44317
PPO Batch Consumption Time: 2.26985
Total Iteration Time: 19.46039

Cumulative Model Updates: 8426
Cumulative Timesteps: 70594936

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.58515
Policy Entropy: 0.15113
Value Function Loss: 2.51790

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.05865
Value Function Update Magnitude: 0.06837

Collected Steps per Second: 13559.52187
Overall Steps per Second: 2549.88184

Timestep Collection Time: 3.69231
Timestep Consumption Time: 15.94232
PPO Batch Consumption Time: 2.33190
Total Iteration Time: 19.63464

Cumulative Model Updates: 8432
Cumulative Timesteps: 70645002

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.05026
Policy Entropy: 0.15141
Value Function Loss: 2.56569

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.06075
Value Function Update Magnitude: 0.07016

Collected Steps per Second: 12972.31513
Overall Steps per Second: 2479.38202

Timestep Collection Time: 3.85606
Timestep Consumption Time: 16.31913
PPO Batch Consumption Time: 2.41112
Total Iteration Time: 20.17519

Cumulative Model Updates: 8438
Cumulative Timesteps: 70695024

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.16357
Policy Entropy: 0.15131
Value Function Loss: 2.52049

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.06228
Value Function Update Magnitude: 0.07346

Collected Steps per Second: 15751.52591
Overall Steps per Second: 2601.33458

Timestep Collection Time: 3.17468
Timestep Consumption Time: 16.04853
PPO Batch Consumption Time: 2.40749
Total Iteration Time: 19.22321

Cumulative Model Updates: 8444
Cumulative Timesteps: 70745030

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.43382
Policy Entropy: 0.15101
Value Function Loss: 2.48621

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.06698
Value Function Update Magnitude: 0.07566

Collected Steps per Second: 14729.18714
Overall Steps per Second: 2527.22044

Timestep Collection Time: 3.39652
Timestep Consumption Time: 16.39914
PPO Batch Consumption Time: 2.41640
Total Iteration Time: 19.79566

Cumulative Model Updates: 8450
Cumulative Timesteps: 70795058

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.77273
Policy Entropy: 0.15099
Value Function Loss: 2.35729

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.14935
Policy Update Magnitude: 0.07168
Value Function Update Magnitude: 0.11872

Collected Steps per Second: 13821.62945
Overall Steps per Second: 2522.66837

Timestep Collection Time: 3.61998
Timestep Consumption Time: 16.21378
PPO Batch Consumption Time: 2.36210
Total Iteration Time: 19.83376

Cumulative Model Updates: 8456
Cumulative Timesteps: 70845092

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 521.66536
Policy Entropy: 0.15031
Value Function Loss: 2.34114

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.13536

Collected Steps per Second: 13425.50617
Overall Steps per Second: 2509.63049

Timestep Collection Time: 3.72872
Timestep Consumption Time: 16.21844
PPO Batch Consumption Time: 2.39909
Total Iteration Time: 19.94716

Cumulative Model Updates: 8462
Cumulative Timesteps: 70895152

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.65192
Policy Entropy: 0.15054
Value Function Loss: 2.30645

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14086
Policy Update Magnitude: 0.04863
Value Function Update Magnitude: 0.12018

Collected Steps per Second: 13192.35690
Overall Steps per Second: 2455.38409

Timestep Collection Time: 3.79295
Timestep Consumption Time: 16.58594
PPO Batch Consumption Time: 2.43543
Total Iteration Time: 20.37889

Cumulative Model Updates: 8468
Cumulative Timesteps: 70945190

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.00584
Policy Entropy: 0.14948
Value Function Loss: 2.34813

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.12790

Collected Steps per Second: 13025.99042
Overall Steps per Second: 2507.88008

Timestep Collection Time: 3.84324
Timestep Consumption Time: 16.11864
PPO Batch Consumption Time: 2.39408
Total Iteration Time: 19.96188

Cumulative Model Updates: 8474
Cumulative Timesteps: 70995252

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.56531
Policy Entropy: 0.14947
Value Function Loss: 2.33054

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.15467
Policy Update Magnitude: 0.04829
Value Function Update Magnitude: 0.15129

Collected Steps per Second: 14096.46719
Overall Steps per Second: 2461.94768

Timestep Collection Time: 3.54770
Timestep Consumption Time: 16.76549
PPO Batch Consumption Time: 2.45445
Total Iteration Time: 20.31319

Cumulative Model Updates: 8480
Cumulative Timesteps: 71045262

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 71045262...
Checkpoint 71045262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.29558
Policy Entropy: 0.14816
Value Function Loss: 2.37919

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.16290
Policy Update Magnitude: 0.04649
Value Function Update Magnitude: 0.15141

Collected Steps per Second: 14256.22200
Overall Steps per Second: 2507.47437

Timestep Collection Time: 3.50808
Timestep Consumption Time: 16.43709
PPO Batch Consumption Time: 2.42311
Total Iteration Time: 19.94517

Cumulative Model Updates: 8486
Cumulative Timesteps: 71095274

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.22656
Policy Entropy: 0.14976
Value Function Loss: 2.38170

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14866
Policy Update Magnitude: 0.04793
Value Function Update Magnitude: 0.13125

Collected Steps per Second: 13691.67006
Overall Steps per Second: 2521.81406

Timestep Collection Time: 3.65697
Timestep Consumption Time: 16.19779
PPO Batch Consumption Time: 2.39890
Total Iteration Time: 19.85475

Cumulative Model Updates: 8492
Cumulative Timesteps: 71145344

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.38402
Policy Entropy: 0.14891
Value Function Loss: 2.43313

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.14681
Policy Update Magnitude: 0.05620
Value Function Update Magnitude: 0.13003

Collected Steps per Second: 12924.47155
Overall Steps per Second: 2603.87578

Timestep Collection Time: 3.87142
Timestep Consumption Time: 15.34455
PPO Batch Consumption Time: 2.25302
Total Iteration Time: 19.21597

Cumulative Model Updates: 8498
Cumulative Timesteps: 71195380

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 926.26586
Policy Entropy: 0.14923
Value Function Loss: 2.36445

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12699
Policy Update Magnitude: 0.07366
Value Function Update Magnitude: 0.15718

Collected Steps per Second: 12781.33238
Overall Steps per Second: 2556.28401

Timestep Collection Time: 3.91571
Timestep Consumption Time: 15.66271
PPO Batch Consumption Time: 2.33998
Total Iteration Time: 19.57842

Cumulative Model Updates: 8504
Cumulative Timesteps: 71245428

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.16014
Policy Entropy: 0.14763
Value Function Loss: 2.34682

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09541
Policy Update Magnitude: 0.07416
Value Function Update Magnitude: 0.16321

Collected Steps per Second: 12914.57588
Overall Steps per Second: 2572.69509

Timestep Collection Time: 3.87593
Timestep Consumption Time: 15.58071
PPO Batch Consumption Time: 2.29012
Total Iteration Time: 19.45664

Cumulative Model Updates: 8510
Cumulative Timesteps: 71295484

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689.08167
Policy Entropy: 0.14694
Value Function Loss: 2.24549

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.19415
Policy Update Magnitude: 0.08174
Value Function Update Magnitude: 0.16926

Collected Steps per Second: 14048.83888
Overall Steps per Second: 2506.29785

Timestep Collection Time: 3.56428
Timestep Consumption Time: 16.41499
PPO Batch Consumption Time: 2.43776
Total Iteration Time: 19.97927

Cumulative Model Updates: 8516
Cumulative Timesteps: 71345558

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 814.47913
Policy Entropy: 0.14650
Value Function Loss: 2.29924

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.06583
Value Function Update Magnitude: 0.13643

Collected Steps per Second: 13197.75491
Overall Steps per Second: 2453.76489

Timestep Collection Time: 3.79155
Timestep Consumption Time: 16.60160
PPO Batch Consumption Time: 2.43404
Total Iteration Time: 20.39315

Cumulative Model Updates: 8522
Cumulative Timesteps: 71395598

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.73991
Policy Entropy: 0.14762
Value Function Loss: 2.32798

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.19747
Policy Update Magnitude: 0.05595
Value Function Update Magnitude: 0.11851

Collected Steps per Second: 12534.86135
Overall Steps per Second: 2432.30377

Timestep Collection Time: 3.99318
Timestep Consumption Time: 16.58566
PPO Batch Consumption Time: 2.43276
Total Iteration Time: 20.57884

Cumulative Model Updates: 8528
Cumulative Timesteps: 71445652

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.42715
Policy Entropy: 0.14940
Value Function Loss: 2.34423

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.15133
Policy Update Magnitude: 0.05047
Value Function Update Magnitude: 0.11047

Collected Steps per Second: 15871.25780
Overall Steps per Second: 2540.34382

Timestep Collection Time: 3.15350
Timestep Consumption Time: 16.54856
PPO Batch Consumption Time: 2.40469
Total Iteration Time: 19.70206

Cumulative Model Updates: 8534
Cumulative Timesteps: 71495702

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.34811
Policy Entropy: 0.15088
Value Function Loss: 2.33527

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14355
Policy Update Magnitude: 0.04481
Value Function Update Magnitude: 0.13599

Collected Steps per Second: 13373.23363
Overall Steps per Second: 2552.30136

Timestep Collection Time: 3.73896
Timestep Consumption Time: 15.85199
PPO Batch Consumption Time: 2.35218
Total Iteration Time: 19.59095

Cumulative Model Updates: 8540
Cumulative Timesteps: 71545704

Timesteps Collected: 50002
--------END ITERATION REPORT--------


Saving checkpoint 71545704...
Checkpoint 71545704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1102.84971
Policy Entropy: 0.15018
Value Function Loss: 2.33519

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14006
Policy Update Magnitude: 0.04594
Value Function Update Magnitude: 0.16274

Collected Steps per Second: 12495.11465
Overall Steps per Second: 2483.24400

Timestep Collection Time: 4.00653
Timestep Consumption Time: 16.15339
PPO Batch Consumption Time: 2.41236
Total Iteration Time: 20.15992

Cumulative Model Updates: 8546
Cumulative Timesteps: 71595766

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.31304
Policy Entropy: 0.15029
Value Function Loss: 2.34327

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.10256
Policy Update Magnitude: 0.05324
Value Function Update Magnitude: 0.18628

Collected Steps per Second: 13144.65195
Overall Steps per Second: 2482.48762

Timestep Collection Time: 3.80505
Timestep Consumption Time: 16.34249
PPO Batch Consumption Time: 2.40564
Total Iteration Time: 20.14753

Cumulative Model Updates: 8552
Cumulative Timesteps: 71645782

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.52260
Policy Entropy: 0.14767
Value Function Loss: 2.31112

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.17713
Policy Update Magnitude: 0.06294
Value Function Update Magnitude: 0.15547

Collected Steps per Second: 13560.87995
Overall Steps per Second: 2530.92708

Timestep Collection Time: 3.68781
Timestep Consumption Time: 16.07174
PPO Batch Consumption Time: 2.41673
Total Iteration Time: 19.75956

Cumulative Model Updates: 8558
Cumulative Timesteps: 71695792

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 766.98095
Policy Entropy: 0.14838
Value Function Loss: 2.34169

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.15473
Policy Update Magnitude: 0.05509
Value Function Update Magnitude: 0.15194

Collected Steps per Second: 14388.44691
Overall Steps per Second: 2541.09967

Timestep Collection Time: 3.48057
Timestep Consumption Time: 16.22743
PPO Batch Consumption Time: 2.40352
Total Iteration Time: 19.70800

Cumulative Model Updates: 8564
Cumulative Timesteps: 71745872

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556.45438
Policy Entropy: 0.14717
Value Function Loss: 2.36175

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.04895
Value Function Update Magnitude: 0.12903

Collected Steps per Second: 13182.38740
Overall Steps per Second: 2457.83496

Timestep Collection Time: 3.79491
Timestep Consumption Time: 16.55877
PPO Batch Consumption Time: 2.46299
Total Iteration Time: 20.35369

Cumulative Model Updates: 8570
Cumulative Timesteps: 71795898

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.49195
Policy Entropy: 0.14674
Value Function Loss: 2.36909

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.15259
Policy Update Magnitude: 0.05173
Value Function Update Magnitude: 0.11660

Collected Steps per Second: 15783.77410
Overall Steps per Second: 2575.27911

Timestep Collection Time: 3.17212
Timestep Consumption Time: 16.26966
PPO Batch Consumption Time: 2.40276
Total Iteration Time: 19.44178

Cumulative Model Updates: 8576
Cumulative Timesteps: 71845966

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.38435
Policy Entropy: 0.14409
Value Function Loss: 2.35030

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.05901
Value Function Update Magnitude: 0.11247

Collected Steps per Second: 14867.09935
Overall Steps per Second: 2580.59219

Timestep Collection Time: 3.36475
Timestep Consumption Time: 16.01995
PPO Batch Consumption Time: 2.35089
Total Iteration Time: 19.38470

Cumulative Model Updates: 8582
Cumulative Timesteps: 71895990

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.75845
Policy Entropy: 0.14298
Value Function Loss: 2.30950

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.05085
Value Function Update Magnitude: 0.11211

Collected Steps per Second: 13371.41313
Overall Steps per Second: 2602.56429

Timestep Collection Time: 3.73977
Timestep Consumption Time: 15.47436
PPO Batch Consumption Time: 2.26417
Total Iteration Time: 19.21413

Cumulative Model Updates: 8588
Cumulative Timesteps: 71945996

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963.43176
Policy Entropy: 0.14455
Value Function Loss: 2.35059

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13677
Policy Update Magnitude: 0.04554
Value Function Update Magnitude: 0.12370

Collected Steps per Second: 14254.62531
Overall Steps per Second: 2597.62330

Timestep Collection Time: 3.51198
Timestep Consumption Time: 15.76025
PPO Batch Consumption Time: 2.28812
Total Iteration Time: 19.27223

Cumulative Model Updates: 8594
Cumulative Timesteps: 71996058

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.28399
Policy Entropy: 0.14501
Value Function Loss: 2.38134

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14327
Policy Update Magnitude: 0.04305
Value Function Update Magnitude: 0.11952

Collected Steps per Second: 12860.66485
Overall Steps per Second: 2482.55951

Timestep Collection Time: 3.88860
Timestep Consumption Time: 16.25593
PPO Batch Consumption Time: 2.42882
Total Iteration Time: 20.14453

Cumulative Model Updates: 8600
Cumulative Timesteps: 72046068

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 72046068...
Checkpoint 72046068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532.43063
Policy Entropy: 0.14698
Value Function Loss: 2.46334

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14808
Policy Update Magnitude: 0.04432
Value Function Update Magnitude: 0.12082

Collected Steps per Second: 12573.23680
Overall Steps per Second: 2445.71024

Timestep Collection Time: 3.98100
Timestep Consumption Time: 16.48504
PPO Batch Consumption Time: 2.42333
Total Iteration Time: 20.46604

Cumulative Model Updates: 8606
Cumulative Timesteps: 72096122

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.78341
Policy Entropy: 0.14514
Value Function Loss: 2.42070

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14111
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.11914

Collected Steps per Second: 14113.98397
Overall Steps per Second: 2557.93636

Timestep Collection Time: 3.54429
Timestep Consumption Time: 16.01210
PPO Batch Consumption Time: 2.38821
Total Iteration Time: 19.55639

Cumulative Model Updates: 8612
Cumulative Timesteps: 72146146

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.93754
Policy Entropy: 0.14345
Value Function Loss: 2.37059

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.05954
Value Function Update Magnitude: 0.10899

Collected Steps per Second: 14171.43308
Overall Steps per Second: 2524.33578

Timestep Collection Time: 3.53669
Timestep Consumption Time: 16.31804
PPO Batch Consumption Time: 2.39481
Total Iteration Time: 19.85473

Cumulative Model Updates: 8618
Cumulative Timesteps: 72196266

Timesteps Collected: 50120
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645.55605
Policy Entropy: 0.14353
Value Function Loss: 2.31085

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.16448
Policy Update Magnitude: 0.06012
Value Function Update Magnitude: 0.15793

Collected Steps per Second: 12766.14002
Overall Steps per Second: 2494.81196

Timestep Collection Time: 3.92053
Timestep Consumption Time: 16.14110
PPO Batch Consumption Time: 2.38202
Total Iteration Time: 20.06163

Cumulative Model Updates: 8624
Cumulative Timesteps: 72246316

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 878.80307
Policy Entropy: 0.14126
Value Function Loss: 2.29483

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.17786
Policy Update Magnitude: 0.06542
Value Function Update Magnitude: 0.14222

Collected Steps per Second: 13173.33028
Overall Steps per Second: 2573.97020

Timestep Collection Time: 3.79843
Timestep Consumption Time: 15.64158
PPO Batch Consumption Time: 2.29273
Total Iteration Time: 19.44001

Cumulative Model Updates: 8630
Cumulative Timesteps: 72296354

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729.02761
Policy Entropy: 0.14406
Value Function Loss: 2.29577

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.05870
Value Function Update Magnitude: 0.12392

Collected Steps per Second: 12907.91263
Overall Steps per Second: 2555.83970

Timestep Collection Time: 3.87623
Timestep Consumption Time: 15.70012
PPO Batch Consumption Time: 2.31657
Total Iteration Time: 19.57635

Cumulative Model Updates: 8636
Cumulative Timesteps: 72346388

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457.71903
Policy Entropy: 0.14242
Value Function Loss: 2.35086

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14512
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.12089

Collected Steps per Second: 12553.25714
Overall Steps per Second: 2539.40948

Timestep Collection Time: 3.98813
Timestep Consumption Time: 15.72669
PPO Batch Consumption Time: 2.35802
Total Iteration Time: 19.71482

Cumulative Model Updates: 8642
Cumulative Timesteps: 72396452

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499.25067
Policy Entropy: 0.14374
Value Function Loss: 2.38404

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.22181
Policy Update Magnitude: 0.06427
Value Function Update Magnitude: 0.11859

Collected Steps per Second: 12568.97063
Overall Steps per Second: 2470.23376

Timestep Collection Time: 3.98314
Timestep Consumption Time: 16.28377
PPO Batch Consumption Time: 2.40406
Total Iteration Time: 20.26691

Cumulative Model Updates: 8648
Cumulative Timesteps: 72446516

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717.25068
Policy Entropy: 0.14515
Value Function Loss: 2.44571

Mean KL Divergence: 0.02769
SB3 Clip Fraction: 0.30319
Policy Update Magnitude: 0.05587
Value Function Update Magnitude: 0.13615

Collected Steps per Second: 15616.35443
Overall Steps per Second: 2525.17893

Timestep Collection Time: 3.20779
Timestep Consumption Time: 16.63001
PPO Batch Consumption Time: 2.44937
Total Iteration Time: 19.83780

Cumulative Model Updates: 8654
Cumulative Timesteps: 72496610

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543.34303
Policy Entropy: 0.14395
Value Function Loss: 2.44115

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.23607
Policy Update Magnitude: 0.04855
Value Function Update Magnitude: 0.15746

Collected Steps per Second: 15357.31268
Overall Steps per Second: 2522.66068

Timestep Collection Time: 3.25734
Timestep Consumption Time: 16.57252
PPO Batch Consumption Time: 2.44285
Total Iteration Time: 19.82986

Cumulative Model Updates: 8660
Cumulative Timesteps: 72546634

Timesteps Collected: 50024
--------END ITERATION REPORT--------


Saving checkpoint 72546634...
Checkpoint 72546634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 833.09786
Policy Entropy: 0.14373
Value Function Loss: 2.50224

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.18946
Policy Update Magnitude: 0.04604
Value Function Update Magnitude: 0.13193

Collected Steps per Second: 12782.32294
Overall Steps per Second: 2470.31417

Timestep Collection Time: 3.91212
Timestep Consumption Time: 16.33065
PPO Batch Consumption Time: 2.40544
Total Iteration Time: 20.24277

Cumulative Model Updates: 8666
Cumulative Timesteps: 72596640

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.50626
Policy Entropy: 0.14235
Value Function Loss: 2.51984

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14643
Policy Update Magnitude: 0.05908
Value Function Update Magnitude: 0.11695

Collected Steps per Second: 15277.91137
Overall Steps per Second: 2516.48460

Timestep Collection Time: 3.27427
Timestep Consumption Time: 16.60425
PPO Batch Consumption Time: 2.42339
Total Iteration Time: 19.87852

Cumulative Model Updates: 8672
Cumulative Timesteps: 72646664

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1038.65831
Policy Entropy: 0.14446
Value Function Loss: 2.45896

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11214
Policy Update Magnitude: 0.05729
Value Function Update Magnitude: 0.11127

Collected Steps per Second: 13277.56072
Overall Steps per Second: 2533.08126

Timestep Collection Time: 3.77042
Timestep Consumption Time: 15.99286
PPO Batch Consumption Time: 2.35844
Total Iteration Time: 19.76328

Cumulative Model Updates: 8678
Cumulative Timesteps: 72696726

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.13338
Policy Entropy: 0.14332
Value Function Loss: 2.39758

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14600
Policy Update Magnitude: 0.05215
Value Function Update Magnitude: 0.11636

Collected Steps per Second: 15530.76240
Overall Steps per Second: 2605.48381

Timestep Collection Time: 3.22199
Timestep Consumption Time: 15.98365
PPO Batch Consumption Time: 2.38766
Total Iteration Time: 19.20565

Cumulative Model Updates: 8684
Cumulative Timesteps: 72746766

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.28901
Policy Entropy: 0.14568
Value Function Loss: 2.29214

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14953
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.12709

Collected Steps per Second: 12660.30223
Overall Steps per Second: 2456.78911

Timestep Collection Time: 3.95662
Timestep Consumption Time: 16.43259
PPO Batch Consumption Time: 2.38471
Total Iteration Time: 20.38921

Cumulative Model Updates: 8690
Cumulative Timesteps: 72796858

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 817.32546
Policy Entropy: 0.14290
Value Function Loss: 2.23324

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.15265
Policy Update Magnitude: 0.04283
Value Function Update Magnitude: 0.12851

Collected Steps per Second: 12700.23957
Overall Steps per Second: 2481.18370

Timestep Collection Time: 3.93772
Timestep Consumption Time: 16.21798
PPO Batch Consumption Time: 2.42361
Total Iteration Time: 20.15570

Cumulative Model Updates: 8696
Cumulative Timesteps: 72846868

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 515.96893
Policy Entropy: 0.14176
Value Function Loss: 2.21876

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15749
Policy Update Magnitude: 0.05247
Value Function Update Magnitude: 0.10907

Collected Steps per Second: 13230.99507
Overall Steps per Second: 2481.75371

Timestep Collection Time: 3.78082
Timestep Consumption Time: 16.37589
PPO Batch Consumption Time: 2.41544
Total Iteration Time: 20.15671

Cumulative Model Updates: 8702
Cumulative Timesteps: 72896892

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 810.45191
Policy Entropy: 0.14199
Value Function Loss: 2.28453

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.17879
Policy Update Magnitude: 0.05056
Value Function Update Magnitude: 0.09999

Collected Steps per Second: 12903.46855
Overall Steps per Second: 2536.13518

Timestep Collection Time: 3.87818
Timestep Consumption Time: 15.85342
PPO Batch Consumption Time: 2.37020
Total Iteration Time: 19.73160

Cumulative Model Updates: 8708
Cumulative Timesteps: 72946934

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 733.32002
Policy Entropy: 0.14142
Value Function Loss: 2.33331

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.17580
Policy Update Magnitude: 0.04860
Value Function Update Magnitude: 0.11331

Collected Steps per Second: 12621.28375
Overall Steps per Second: 2560.86462

Timestep Collection Time: 3.96632
Timestep Consumption Time: 15.58177
PPO Batch Consumption Time: 2.28858
Total Iteration Time: 19.54809

Cumulative Model Updates: 8714
Cumulative Timesteps: 72996994

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.84892
Policy Entropy: 0.13968
Value Function Loss: 2.30189

Mean KL Divergence: 0.02930
SB3 Clip Fraction: 0.31846
Policy Update Magnitude: 0.04276
Value Function Update Magnitude: 0.11798

Collected Steps per Second: 12803.80605
Overall Steps per Second: 2568.54780

Timestep Collection Time: 3.90603
Timestep Consumption Time: 15.56490
PPO Batch Consumption Time: 2.29856
Total Iteration Time: 19.47092

Cumulative Model Updates: 8720
Cumulative Timesteps: 73047006

Timesteps Collected: 50012
--------END ITERATION REPORT--------


Saving checkpoint 73047006...
Checkpoint 73047006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 784.70947
Policy Entropy: 0.14033
Value Function Loss: 2.27928

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14133
Policy Update Magnitude: 0.04151
Value Function Update Magnitude: 0.12643

Collected Steps per Second: 13428.64571
Overall Steps per Second: 2572.60127

Timestep Collection Time: 3.72368
Timestep Consumption Time: 15.71345
PPO Batch Consumption Time: 2.30598
Total Iteration Time: 19.43714

Cumulative Model Updates: 8726
Cumulative Timesteps: 73097010

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1071.19646
Policy Entropy: 0.14164
Value Function Loss: 2.27805

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.04707
Value Function Update Magnitude: 0.12138

Collected Steps per Second: 14940.21165
Overall Steps per Second: 2644.30100

Timestep Collection Time: 3.34815
Timestep Consumption Time: 15.56876
PPO Batch Consumption Time: 2.29783
Total Iteration Time: 18.91691

Cumulative Model Updates: 8732
Cumulative Timesteps: 73147032

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.93729
Policy Entropy: 0.14069
Value Function Loss: 2.31413

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.05209
Value Function Update Magnitude: 0.12987

Collected Steps per Second: 14788.93055
Overall Steps per Second: 2615.94568

Timestep Collection Time: 3.38442
Timestep Consumption Time: 15.74900
PPO Batch Consumption Time: 2.35158
Total Iteration Time: 19.13342

Cumulative Model Updates: 8738
Cumulative Timesteps: 73197084

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 916.25832
Policy Entropy: 0.14139
Value Function Loss: 2.30598

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.18311
Policy Update Magnitude: 0.04939
Value Function Update Magnitude: 0.12258

Collected Steps per Second: 13009.93952
Overall Steps per Second: 2449.39798

Timestep Collection Time: 3.84383
Timestep Consumption Time: 16.57262
PPO Batch Consumption Time: 2.43279
Total Iteration Time: 20.41645

Cumulative Model Updates: 8744
Cumulative Timesteps: 73247092

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598.53277
Policy Entropy: 0.14024
Value Function Loss: 2.34492

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.19704
Policy Update Magnitude: 0.04688
Value Function Update Magnitude: 0.11299

Collected Steps per Second: 13645.13092
Overall Steps per Second: 2529.00493

Timestep Collection Time: 3.66475
Timestep Consumption Time: 16.10824
PPO Batch Consumption Time: 2.40376
Total Iteration Time: 19.77299

Cumulative Model Updates: 8750
Cumulative Timesteps: 73297098

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 919.13381
Policy Entropy: 0.14269
Value Function Loss: 2.33408

Mean KL Divergence: 0.01636
SB3 Clip Fraction: 0.19575
Policy Update Magnitude: 0.04234
Value Function Update Magnitude: 0.10332

Collected Steps per Second: 13633.79314
Overall Steps per Second: 2493.13616

Timestep Collection Time: 3.67161
Timestep Consumption Time: 16.40671
PPO Batch Consumption Time: 2.43904
Total Iteration Time: 20.07833

Cumulative Model Updates: 8756
Cumulative Timesteps: 73347156

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.05784
Policy Entropy: 0.14114
Value Function Loss: 2.35551

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.19701
Policy Update Magnitude: 0.05291
Value Function Update Magnitude: 0.10764

Collected Steps per Second: 13084.49005
Overall Steps per Second: 2488.35736

Timestep Collection Time: 3.82162
Timestep Consumption Time: 16.27356
PPO Batch Consumption Time: 2.44138
Total Iteration Time: 20.09518

Cumulative Model Updates: 8762
Cumulative Timesteps: 73397160

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412.89081
Policy Entropy: 0.14257
Value Function Loss: 2.33135

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.05086
Value Function Update Magnitude: 0.11408

Collected Steps per Second: 12843.86438
Overall Steps per Second: 623.02884

Timestep Collection Time: 3.89727
Timestep Consumption Time: 76.44572
PPO Batch Consumption Time: 2.41138
Total Iteration Time: 80.34299

Cumulative Model Updates: 8768
Cumulative Timesteps: 73447216

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 942.91050
Policy Entropy: 0.14224
Value Function Loss: 2.36442

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.11186
Policy Update Magnitude: 0.05580
Value Function Update Magnitude: 0.12902

Collected Steps per Second: 12597.96172
Overall Steps per Second: 1555.78987

Timestep Collection Time: 3.96953
Timestep Consumption Time: 28.17363
PPO Batch Consumption Time: 2.38729
Total Iteration Time: 32.14316

Cumulative Model Updates: 8774
Cumulative Timesteps: 73497224

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 520.50704
Policy Entropy: 0.14239
Value Function Loss: 2.37240

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.15788
Policy Update Magnitude: 0.06019
Value Function Update Magnitude: 0.12728

Collected Steps per Second: 13375.83844
Overall Steps per Second: 2496.59826

Timestep Collection Time: 3.73883
Timestep Consumption Time: 16.29243
PPO Batch Consumption Time: 2.40176
Total Iteration Time: 20.03126

Cumulative Model Updates: 8780
Cumulative Timesteps: 73547234

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 73547234...
Checkpoint 73547234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638.15796
Policy Entropy: 0.13985
Value Function Loss: 2.40715

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.16400
Policy Update Magnitude: 0.05052
Value Function Update Magnitude: 0.11681

Collected Steps per Second: 12408.45440
Overall Steps per Second: 2426.53609

Timestep Collection Time: 4.03435
Timestep Consumption Time: 16.59588
PPO Batch Consumption Time: 2.44840
Total Iteration Time: 20.63023

Cumulative Model Updates: 8786
Cumulative Timesteps: 73597294

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 969.20200
Policy Entropy: 0.14199
Value Function Loss: 2.40305

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.15007
Policy Update Magnitude: 0.04639
Value Function Update Magnitude: 0.10954

Collected Steps per Second: 13465.44662
Overall Steps per Second: 2518.55392

Timestep Collection Time: 3.71380
Timestep Consumption Time: 16.14204
PPO Batch Consumption Time: 2.37052
Total Iteration Time: 19.85584

Cumulative Model Updates: 8792
Cumulative Timesteps: 73647302

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 529.56760
Policy Entropy: 0.13942
Value Function Loss: 2.46542

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.04312
Value Function Update Magnitude: 0.11233

Collected Steps per Second: 12688.92489
Overall Steps per Second: 2485.37696

Timestep Collection Time: 3.94659
Timestep Consumption Time: 16.20246
PPO Batch Consumption Time: 2.39051
Total Iteration Time: 20.14906

Cumulative Model Updates: 8798
Cumulative Timesteps: 73697380

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.06690
Policy Entropy: 0.14256
Value Function Loss: 2.43674

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.15169
Policy Update Magnitude: 0.04644
Value Function Update Magnitude: 0.14134

Collected Steps per Second: 12281.27377
Overall Steps per Second: 2521.98955

Timestep Collection Time: 4.07694
Timestep Consumption Time: 15.77643
PPO Batch Consumption Time: 2.35352
Total Iteration Time: 19.85337

Cumulative Model Updates: 8804
Cumulative Timesteps: 73747450

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670.58496
Policy Entropy: 0.14025
Value Function Loss: 2.43337

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.05270
Value Function Update Magnitude: 0.12409

Collected Steps per Second: 12559.90047
Overall Steps per Second: 1933.37117

Timestep Collection Time: 3.98634
Timestep Consumption Time: 21.91040
PPO Batch Consumption Time: 2.40604
Total Iteration Time: 25.89673

Cumulative Model Updates: 8810
Cumulative Timesteps: 73797518

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724.76908
Policy Entropy: 0.14077
Value Function Loss: 2.38004

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.05312
Value Function Update Magnitude: 0.11002

Collected Steps per Second: 12883.60191
Overall Steps per Second: 2519.04266

Timestep Collection Time: 3.88882
Timestep Consumption Time: 16.00048
PPO Batch Consumption Time: 2.39570
Total Iteration Time: 19.88930

Cumulative Model Updates: 8816
Cumulative Timesteps: 73847620

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.73505
Policy Entropy: 0.14104
Value Function Loss: 2.41128

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11701
Policy Update Magnitude: 0.06268
Value Function Update Magnitude: 0.10899

Collected Steps per Second: 13009.78605
Overall Steps per Second: 637.59699

Timestep Collection Time: 3.84357
Timestep Consumption Time: 74.58215
PPO Batch Consumption Time: 2.39540
Total Iteration Time: 78.42571

Cumulative Model Updates: 8822
Cumulative Timesteps: 73897624

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 829.79581
Policy Entropy: 0.14185
Value Function Loss: 2.41035

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.05474
Value Function Update Magnitude: 0.10861

Collected Steps per Second: 12664.63001
Overall Steps per Second: 2537.38857

Timestep Collection Time: 3.95132
Timestep Consumption Time: 15.77053
PPO Batch Consumption Time: 2.32193
Total Iteration Time: 19.72185

Cumulative Model Updates: 8828
Cumulative Timesteps: 73947666

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606.97752
Policy Entropy: 0.13957
Value Function Loss: 2.44183

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.15038
Policy Update Magnitude: 0.05333
Value Function Update Magnitude: 0.10349

Collected Steps per Second: 13344.25376
Overall Steps per Second: 1116.14987

Timestep Collection Time: 3.75532
Timestep Consumption Time: 41.14187
PPO Batch Consumption Time: 2.28667
Total Iteration Time: 44.89720

Cumulative Model Updates: 8834
Cumulative Timesteps: 73997778

Timesteps Collected: 50112
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 581.78992
Policy Entropy: 0.14043
Value Function Loss: 2.36322

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.05397
Value Function Update Magnitude: 0.13150

Collected Steps per Second: 12947.73682
Overall Steps per Second: 2452.83719

Timestep Collection Time: 3.86770
Timestep Consumption Time: 16.54865
PPO Batch Consumption Time: 2.43880
Total Iteration Time: 20.41636

Cumulative Model Updates: 8840
Cumulative Timesteps: 74047856

Timesteps Collected: 50078
--------END ITERATION REPORT--------


Saving checkpoint 74047856...
Checkpoint 74047856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633.37587
Policy Entropy: 0.13819
Value Function Loss: 2.32652

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.11160
Policy Update Magnitude: 0.05978
Value Function Update Magnitude: 0.14137

Collected Steps per Second: 15181.27736
Overall Steps per Second: 2570.48175

Timestep Collection Time: 3.29748
Timestep Consumption Time: 16.17747
PPO Batch Consumption Time: 2.39070
Total Iteration Time: 19.47495

Cumulative Model Updates: 8846
Cumulative Timesteps: 74097916

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.89452
Policy Entropy: 0.13787
Value Function Loss: 2.31538

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.11000
Policy Update Magnitude: 0.05832
Value Function Update Magnitude: 0.11714

Collected Steps per Second: 13568.70505
Overall Steps per Second: 2500.68469

Timestep Collection Time: 3.68893
Timestep Consumption Time: 16.32719
PPO Batch Consumption Time: 2.34383
Total Iteration Time: 20.01612

Cumulative Model Updates: 8852
Cumulative Timesteps: 74147970

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.51878
Policy Entropy: 0.13550
Value Function Loss: 2.32678

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11704
Policy Update Magnitude: 0.05572
Value Function Update Magnitude: 0.10919

Collected Steps per Second: 14743.85457
Overall Steps per Second: 2479.47338

Timestep Collection Time: 3.39694
Timestep Consumption Time: 16.80251
PPO Batch Consumption Time: 2.51126
Total Iteration Time: 20.19945

Cumulative Model Updates: 8858
Cumulative Timesteps: 74198054

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 876.71860
Policy Entropy: 0.13330
Value Function Loss: 2.32095

Mean KL Divergence: 0.02741
SB3 Clip Fraction: 0.28599
Policy Update Magnitude: 0.06406
Value Function Update Magnitude: 0.12248

Collected Steps per Second: 14016.20878
Overall Steps per Second: 2653.36906

Timestep Collection Time: 3.57115
Timestep Consumption Time: 15.29317
PPO Batch Consumption Time: 2.24726
Total Iteration Time: 18.86432

Cumulative Model Updates: 8864
Cumulative Timesteps: 74248108

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 957.84467
Policy Entropy: 0.13320
Value Function Loss: 2.26372

Mean KL Divergence: 0.02518
SB3 Clip Fraction: 0.28887
Policy Update Magnitude: 0.05220
Value Function Update Magnitude: 0.11539

Collected Steps per Second: 13066.87919
Overall Steps per Second: 2692.40025

Timestep Collection Time: 3.83228
Timestep Consumption Time: 14.76673
PPO Batch Consumption Time: 2.19764
Total Iteration Time: 18.59902

Cumulative Model Updates: 8870
Cumulative Timesteps: 74298184

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 962.23574
Policy Entropy: 0.13259
Value Function Loss: 2.28458

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.18966
Policy Update Magnitude: 0.04553
Value Function Update Magnitude: 0.14342

Collected Steps per Second: 13592.13557
Overall Steps per Second: 2601.34865

Timestep Collection Time: 3.68066
Timestep Consumption Time: 15.55091
PPO Batch Consumption Time: 2.27717
Total Iteration Time: 19.23156

Cumulative Model Updates: 8876
Cumulative Timesteps: 74348212

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 871.02862
Policy Entropy: 0.13410
Value Function Loss: 2.31964

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.18674
Policy Update Magnitude: 0.04630
Value Function Update Magnitude: 0.12682

Collected Steps per Second: 13184.80249
Overall Steps per Second: 2615.35171

Timestep Collection Time: 3.79604
Timestep Consumption Time: 15.34097
PPO Batch Consumption Time: 2.28400
Total Iteration Time: 19.13701

Cumulative Model Updates: 8882
Cumulative Timesteps: 74398262

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.93033
Policy Entropy: 0.13381
Value Function Loss: 2.35307

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.16246
Policy Update Magnitude: 0.04583
Value Function Update Magnitude: 0.10851

Collected Steps per Second: 15168.46639
Overall Steps per Second: 2621.96789

Timestep Collection Time: 3.29855
Timestep Consumption Time: 15.78406
PPO Batch Consumption Time: 2.29003
Total Iteration Time: 19.08261

Cumulative Model Updates: 8888
Cumulative Timesteps: 74448296

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.56933
Policy Entropy: 0.13308
Value Function Loss: 2.28817

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.16606
Policy Update Magnitude: 0.04655
Value Function Update Magnitude: 0.13446

Collected Steps per Second: 13276.51332
Overall Steps per Second: 2548.33777

Timestep Collection Time: 3.76997
Timestep Consumption Time: 15.87107
PPO Batch Consumption Time: 2.31904
Total Iteration Time: 19.64104

Cumulative Model Updates: 8894
Cumulative Timesteps: 74498348

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 785.24705
Policy Entropy: 0.13538
Value Function Loss: 2.22173

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.17963
Policy Update Magnitude: 0.04161
Value Function Update Magnitude: 0.12274

Collected Steps per Second: 14109.61340
Overall Steps per Second: 2591.69330

Timestep Collection Time: 3.54439
Timestep Consumption Time: 15.75187
PPO Batch Consumption Time: 2.32058
Total Iteration Time: 19.29626

Cumulative Model Updates: 8900
Cumulative Timesteps: 74548358

Timesteps Collected: 50010
--------END ITERATION REPORT--------


Saving checkpoint 74548358...
Checkpoint 74548358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.72062
Policy Entropy: 0.13232
Value Function Loss: 2.29046

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14854
Policy Update Magnitude: 0.04100
Value Function Update Magnitude: 0.11348

Collected Steps per Second: 14120.87210
Overall Steps per Second: 2632.83961

Timestep Collection Time: 3.54511
Timestep Consumption Time: 15.46858
PPO Batch Consumption Time: 2.28328
Total Iteration Time: 19.01369

Cumulative Model Updates: 8906
Cumulative Timesteps: 74598418

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609.44937
Policy Entropy: 0.13157
Value Function Loss: 2.29687

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.15074
Policy Update Magnitude: 0.04163
Value Function Update Magnitude: 0.11022

Collected Steps per Second: 15664.76785
Overall Steps per Second: 2692.12463

Timestep Collection Time: 3.19456
Timestep Consumption Time: 15.39374
PPO Batch Consumption Time: 2.28386
Total Iteration Time: 18.58829

Cumulative Model Updates: 8912
Cumulative Timesteps: 74648460

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777.65476
Policy Entropy: 0.13003
Value Function Loss: 2.32230

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14441
Policy Update Magnitude: 0.04565
Value Function Update Magnitude: 0.10087

Collected Steps per Second: 12766.89688
Overall Steps per Second: 2548.03909

Timestep Collection Time: 3.91701
Timestep Consumption Time: 15.70907
PPO Batch Consumption Time: 2.30469
Total Iteration Time: 19.62607

Cumulative Model Updates: 8918
Cumulative Timesteps: 74698468

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.36164
Policy Entropy: 0.12823
Value Function Loss: 2.24899

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.14934
Policy Update Magnitude: 0.04538
Value Function Update Magnitude: 0.09545

Collected Steps per Second: 13177.10161
Overall Steps per Second: 2595.40095

Timestep Collection Time: 3.79841
Timestep Consumption Time: 15.48647
PPO Batch Consumption Time: 2.30883
Total Iteration Time: 19.28488

Cumulative Model Updates: 8924
Cumulative Timesteps: 74748520

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.53184
Policy Entropy: 0.12809
Value Function Loss: 2.28002

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14072
Policy Update Magnitude: 0.05330
Value Function Update Magnitude: 0.11393

Collected Steps per Second: 15127.10709
Overall Steps per Second: 2458.26225

Timestep Collection Time: 3.30625
Timestep Consumption Time: 17.03902
PPO Batch Consumption Time: 2.38281
Total Iteration Time: 20.34527

Cumulative Model Updates: 8930
Cumulative Timesteps: 74798534

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.49264
Policy Entropy: 0.12636
Value Function Loss: 2.27851

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14847
Policy Update Magnitude: 0.04942
Value Function Update Magnitude: 0.10644

Collected Steps per Second: 13585.37295
Overall Steps per Second: 2540.03465

Timestep Collection Time: 3.68396
Timestep Consumption Time: 16.01971
PPO Batch Consumption Time: 2.36546
Total Iteration Time: 19.70367

Cumulative Model Updates: 8936
Cumulative Timesteps: 74848582

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 781.27196
Policy Entropy: 0.12760
Value Function Loss: 2.36573

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.15447
Policy Update Magnitude: 0.04606
Value Function Update Magnitude: 0.10465

Collected Steps per Second: 13913.45152
Overall Steps per Second: 2677.87342

Timestep Collection Time: 3.59623
Timestep Consumption Time: 15.08874
PPO Batch Consumption Time: 2.22498
Total Iteration Time: 18.68498

Cumulative Model Updates: 8942
Cumulative Timesteps: 74898618

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934.23073
Policy Entropy: 0.12700
Value Function Loss: 2.30427

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.15413
Policy Update Magnitude: 0.04617
Value Function Update Magnitude: 0.11813

Collected Steps per Second: 13306.39621
Overall Steps per Second: 2540.63278

Timestep Collection Time: 3.76270
Timestep Consumption Time: 15.94420
PPO Batch Consumption Time: 2.35400
Total Iteration Time: 19.70690

Cumulative Model Updates: 8948
Cumulative Timesteps: 74948686

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483.21617
Policy Entropy: 0.12754
Value Function Loss: 2.36035

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14263
Policy Update Magnitude: 0.04914
Value Function Update Magnitude: 0.09342

Collected Steps per Second: 13328.47114
Overall Steps per Second: 2561.17227

Timestep Collection Time: 3.75182
Timestep Consumption Time: 15.77283
PPO Batch Consumption Time: 2.35249
Total Iteration Time: 19.52465

Cumulative Model Updates: 8954
Cumulative Timesteps: 74998692

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.50225
Policy Entropy: 0.12538
Value Function Loss: 2.28912

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.04823
Value Function Update Magnitude: 0.08201

Collected Steps per Second: 13513.88764
Overall Steps per Second: 2549.23564

Timestep Collection Time: 3.70093
Timestep Consumption Time: 15.91828
PPO Batch Consumption Time: 2.33944
Total Iteration Time: 19.61921

Cumulative Model Updates: 8960
Cumulative Timesteps: 75048706

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 75048706...
Checkpoint 75048706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 883.17746
Policy Entropy: 0.12573
Value Function Loss: 2.24733

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.14970
Policy Update Magnitude: 0.04472
Value Function Update Magnitude: 0.07346

Collected Steps per Second: 13517.01432
Overall Steps per Second: 2539.75279

Timestep Collection Time: 3.69919
Timestep Consumption Time: 15.98855
PPO Batch Consumption Time: 2.33932
Total Iteration Time: 19.68774

Cumulative Model Updates: 8966
Cumulative Timesteps: 75098708

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.18821
Policy Entropy: 0.12279
Value Function Loss: 2.25846

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.16365
Policy Update Magnitude: 0.04537
Value Function Update Magnitude: 0.06545

Collected Steps per Second: 14539.23654
Overall Steps per Second: 2584.46043

Timestep Collection Time: 3.43925
Timestep Consumption Time: 15.90870
PPO Batch Consumption Time: 2.33578
Total Iteration Time: 19.34795

Cumulative Model Updates: 8972
Cumulative Timesteps: 75148712

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.81282
Policy Entropy: 0.12444
Value Function Loss: 2.28063

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.16878
Policy Update Magnitude: 0.04676
Value Function Update Magnitude: 0.06570

Collected Steps per Second: 12944.18226
Overall Steps per Second: 2526.46365

Timestep Collection Time: 3.86877
Timestep Consumption Time: 15.95262
PPO Batch Consumption Time: 2.34530
Total Iteration Time: 19.82138

Cumulative Model Updates: 8978
Cumulative Timesteps: 75198790

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.86179
Policy Entropy: 0.12127
Value Function Loss: 2.26153

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.17099
Policy Update Magnitude: 0.04572
Value Function Update Magnitude: 0.07068

Collected Steps per Second: 13056.24825
Overall Steps per Second: 2292.19146

Timestep Collection Time: 3.83403
Timestep Consumption Time: 18.00446
PPO Batch Consumption Time: 2.71543
Total Iteration Time: 21.83849

Cumulative Model Updates: 8984
Cumulative Timesteps: 75248848

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.41063
Policy Entropy: 0.12254
Value Function Loss: 2.23530

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.15500
Policy Update Magnitude: 0.04425
Value Function Update Magnitude: 0.07457

Collected Steps per Second: 13287.39418
Overall Steps per Second: 2496.85937

Timestep Collection Time: 3.76703
Timestep Consumption Time: 16.27975
PPO Batch Consumption Time: 2.38971
Total Iteration Time: 20.04678

Cumulative Model Updates: 8990
Cumulative Timesteps: 75298902

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.86798
Policy Entropy: 0.11948
Value Function Loss: 2.17611

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15926
Policy Update Magnitude: 0.05630
Value Function Update Magnitude: 0.07263

Collected Steps per Second: 12984.19748
Overall Steps per Second: 2482.91262

Timestep Collection Time: 3.85700
Timestep Consumption Time: 16.31286
PPO Batch Consumption Time: 2.39898
Total Iteration Time: 20.16986

Cumulative Model Updates: 8996
Cumulative Timesteps: 75348982

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490.04162
Policy Entropy: 0.11982
Value Function Loss: 2.22363

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.15274
Policy Update Magnitude: 0.05665
Value Function Update Magnitude: 0.07382

Collected Steps per Second: 13871.27544
Overall Steps per Second: 2496.24460

Timestep Collection Time: 3.60486
Timestep Consumption Time: 16.42683
PPO Batch Consumption Time: 2.40653
Total Iteration Time: 20.03169

Cumulative Model Updates: 9002
Cumulative Timesteps: 75398986

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 876.64489
Policy Entropy: 0.11764
Value Function Loss: 2.24662

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.15478
Policy Update Magnitude: 0.05898
Value Function Update Magnitude: 0.06638

Collected Steps per Second: 12700.18708
Overall Steps per Second: 2482.77131

Timestep Collection Time: 3.93931
Timestep Consumption Time: 16.21156
PPO Batch Consumption Time: 2.41624
Total Iteration Time: 20.15087

Cumulative Model Updates: 9008
Cumulative Timesteps: 75449016

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 828.30789
Policy Entropy: 0.11729
Value Function Loss: 2.26303

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.16175
Policy Update Magnitude: 0.05603
Value Function Update Magnitude: 0.06443

Collected Steps per Second: 12890.62574
Overall Steps per Second: 1605.20939

Timestep Collection Time: 3.88484
Timestep Consumption Time: 27.31234
PPO Batch Consumption Time: 2.37613
Total Iteration Time: 31.19718

Cumulative Model Updates: 9014
Cumulative Timesteps: 75499094

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532.50267
Policy Entropy: 0.11328
Value Function Loss: 2.26990

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.15255
Policy Update Magnitude: 0.04931
Value Function Update Magnitude: 0.06570

Collected Steps per Second: 13710.14908
Overall Steps per Second: 2490.40356

Timestep Collection Time: 3.64795
Timestep Consumption Time: 16.43473
PPO Batch Consumption Time: 2.40922
Total Iteration Time: 20.08269

Cumulative Model Updates: 9020
Cumulative Timesteps: 75549108

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 75549108...
Checkpoint 75549108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535.52271
Policy Entropy: 0.11458
Value Function Loss: 2.28383

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14980
Policy Update Magnitude: 0.04740
Value Function Update Magnitude: 0.06106

Collected Steps per Second: 13321.00485
Overall Steps per Second: 1273.45745

Timestep Collection Time: 3.75782
Timestep Consumption Time: 35.55091
PPO Batch Consumption Time: 2.52226
Total Iteration Time: 39.30873

Cumulative Model Updates: 9026
Cumulative Timesteps: 75599166

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 962.22753
Policy Entropy: 0.11283
Value Function Loss: 2.29435

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.14617
Policy Update Magnitude: 0.05387
Value Function Update Magnitude: 0.06733

Collected Steps per Second: 13465.87059
Overall Steps per Second: 2490.46959

Timestep Collection Time: 3.71829
Timestep Consumption Time: 16.38635
PPO Batch Consumption Time: 2.42112
Total Iteration Time: 20.10464

Cumulative Model Updates: 9032
Cumulative Timesteps: 75649236

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.86810
Policy Entropy: 0.11273
Value Function Loss: 2.26605

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.15592
Policy Update Magnitude: 0.05472
Value Function Update Magnitude: 0.07242

Collected Steps per Second: 13574.15918
Overall Steps per Second: 2541.42667

Timestep Collection Time: 3.68465
Timestep Consumption Time: 15.99564
PPO Batch Consumption Time: 2.36345
Total Iteration Time: 19.68028

Cumulative Model Updates: 9038
Cumulative Timesteps: 75699252

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 733.31425
Policy Entropy: 0.11075
Value Function Loss: 2.26533

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.15088
Policy Update Magnitude: 0.05365
Value Function Update Magnitude: 0.07147

Collected Steps per Second: 14599.18772
Overall Steps per Second: 2549.53060

Timestep Collection Time: 3.42731
Timestep Consumption Time: 16.19826
PPO Batch Consumption Time: 2.39139
Total Iteration Time: 19.62557

Cumulative Model Updates: 9044
Cumulative Timesteps: 75749288

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.70689
Policy Entropy: 0.10933
Value Function Loss: 2.29190

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.15637
Policy Update Magnitude: 0.05197
Value Function Update Magnitude: 0.06638

Collected Steps per Second: 13873.59497
Overall Steps per Second: 2047.56419

Timestep Collection Time: 3.60988
Timestep Consumption Time: 20.84943
PPO Batch Consumption Time: 2.36956
Total Iteration Time: 24.45931

Cumulative Model Updates: 9050
Cumulative Timesteps: 75799370

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.66224
Policy Entropy: 0.10688
Value Function Loss: 2.37539

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.15346
Policy Update Magnitude: 0.05201
Value Function Update Magnitude: 0.06706

Collected Steps per Second: 13030.77217
Overall Steps per Second: 2496.72781

Timestep Collection Time: 3.83876
Timestep Consumption Time: 16.19626
PPO Batch Consumption Time: 2.42137
Total Iteration Time: 20.03502

Cumulative Model Updates: 9056
Cumulative Timesteps: 75849392

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1061.50303
Policy Entropy: 0.10490
Value Function Loss: 2.35133

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.15852
Policy Update Magnitude: 0.05722
Value Function Update Magnitude: 0.06723

Collected Steps per Second: 13062.04663
Overall Steps per Second: 2518.06949

Timestep Collection Time: 3.82957
Timestep Consumption Time: 16.03565
PPO Batch Consumption Time: 2.35317
Total Iteration Time: 19.86522

Cumulative Model Updates: 9062
Cumulative Timesteps: 75899414

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1313.78185
Policy Entropy: 0.10305
Value Function Loss: 2.32294

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15045
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.06773

Collected Steps per Second: 12755.01334
Overall Steps per Second: 2462.30339

Timestep Collection Time: 3.92285
Timestep Consumption Time: 16.39796
PPO Batch Consumption Time: 2.46135
Total Iteration Time: 20.32081

Cumulative Model Updates: 9068
Cumulative Timesteps: 75949450

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.22369
Policy Entropy: 0.10277
Value Function Loss: 2.24489

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14720
Policy Update Magnitude: 0.05567
Value Function Update Magnitude: 0.06715

Collected Steps per Second: 12857.56531
Overall Steps per Second: 2432.52922

Timestep Collection Time: 3.89032
Timestep Consumption Time: 16.67264
PPO Batch Consumption Time: 2.46067
Total Iteration Time: 20.56296

Cumulative Model Updates: 9074
Cumulative Timesteps: 75999470

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729.81673
Policy Entropy: 0.10042
Value Function Loss: 2.27295

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.15070
Policy Update Magnitude: 0.06039
Value Function Update Magnitude: 0.06193

Collected Steps per Second: 12505.22383
Overall Steps per Second: 2415.20494

Timestep Collection Time: 3.99961
Timestep Consumption Time: 16.70919
PPO Batch Consumption Time: 2.47147
Total Iteration Time: 20.70880

Cumulative Model Updates: 9080
Cumulative Timesteps: 76049486

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 76049486...
Checkpoint 76049486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 742.49214
Policy Entropy: 0.09930
Value Function Loss: 2.30436

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.06004

Collected Steps per Second: 13533.01333
Overall Steps per Second: 2432.05896

Timestep Collection Time: 3.69482
Timestep Consumption Time: 16.86472
PPO Batch Consumption Time: 2.49348
Total Iteration Time: 20.55953

Cumulative Model Updates: 9086
Cumulative Timesteps: 76099488

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.08349
Policy Entropy: 0.09641
Value Function Loss: 2.30156

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.06166
Value Function Update Magnitude: 0.06165

Collected Steps per Second: 13047.98220
Overall Steps per Second: 2456.03832

Timestep Collection Time: 3.83814
Timestep Consumption Time: 16.55242
PPO Batch Consumption Time: 2.44104
Total Iteration Time: 20.39056

Cumulative Model Updates: 9092
Cumulative Timesteps: 76149568

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.76447
Policy Entropy: 0.09537
Value Function Loss: 2.26990

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14284
Policy Update Magnitude: 0.06315
Value Function Update Magnitude: 0.06472

Collected Steps per Second: 12619.52862
Overall Steps per Second: 2430.60241

Timestep Collection Time: 3.96354
Timestep Consumption Time: 16.61490
PPO Batch Consumption Time: 2.48118
Total Iteration Time: 20.57844

Cumulative Model Updates: 9098
Cumulative Timesteps: 76199586

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1272.40425
Policy Entropy: 0.09111
Value Function Loss: 2.19161

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.18990
Policy Update Magnitude: 0.08917
Value Function Update Magnitude: 0.06816

Collected Steps per Second: 12728.14943
Overall Steps per Second: 505.87409

Timestep Collection Time: 3.92893
Timestep Consumption Time: 94.92571
PPO Batch Consumption Time: 2.39084
Total Iteration Time: 98.85464

Cumulative Model Updates: 9104
Cumulative Timesteps: 76249594

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 962.40470
Policy Entropy: 0.09057
Value Function Loss: 2.25053

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.17094
Policy Update Magnitude: 0.07093
Value Function Update Magnitude: 0.06719

Collected Steps per Second: 12707.86688
Overall Steps per Second: 2431.60751

Timestep Collection Time: 3.93457
Timestep Consumption Time: 16.62796
PPO Batch Consumption Time: 2.45945
Total Iteration Time: 20.56253

Cumulative Model Updates: 9110
Cumulative Timesteps: 76299594

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.62875
Policy Entropy: 0.08907
Value Function Loss: 2.26313

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.21375
Policy Update Magnitude: 0.05618
Value Function Update Magnitude: 0.06594

Collected Steps per Second: 13277.03428
Overall Steps per Second: 1074.06510

Timestep Collection Time: 3.76696
Timestep Consumption Time: 42.79819
PPO Batch Consumption Time: 2.34354
Total Iteration Time: 46.56515

Cumulative Model Updates: 9116
Cumulative Timesteps: 76349608

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685.94445
Policy Entropy: 0.08718
Value Function Loss: 2.30631

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.21019
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.06296

Collected Steps per Second: 12741.08214
Overall Steps per Second: 2501.31156

Timestep Collection Time: 3.92761
Timestep Consumption Time: 16.07869
PPO Batch Consumption Time: 2.37335
Total Iteration Time: 20.00630

Cumulative Model Updates: 9122
Cumulative Timesteps: 76399650

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.03085
Policy Entropy: 0.08383
Value Function Loss: 2.22991

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.16462
Policy Update Magnitude: 0.05626
Value Function Update Magnitude: 0.07186

Collected Steps per Second: 13229.96981
Overall Steps per Second: 1801.15980

Timestep Collection Time: 3.78141
Timestep Consumption Time: 23.99402
PPO Batch Consumption Time: 2.41386
Total Iteration Time: 27.77544

Cumulative Model Updates: 9128
Cumulative Timesteps: 76449678

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1102.27267
Policy Entropy: 0.08073
Value Function Loss: 2.25320

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.16339
Policy Update Magnitude: 0.06560
Value Function Update Magnitude: 0.07147

Collected Steps per Second: 12619.66912
Overall Steps per Second: 2462.94335

Timestep Collection Time: 3.97015
Timestep Consumption Time: 16.37218
PPO Batch Consumption Time: 2.40720
Total Iteration Time: 20.34233

Cumulative Model Updates: 9134
Cumulative Timesteps: 76499780

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1125.42213
Policy Entropy: 0.07747
Value Function Loss: 2.27816

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.16393
Policy Update Magnitude: 0.06048
Value Function Update Magnitude: 0.06396

Collected Steps per Second: 12597.60794
Overall Steps per Second: 1378.01205

Timestep Collection Time: 3.96901
Timestep Consumption Time: 32.31515
PPO Batch Consumption Time: 2.39766
Total Iteration Time: 36.28415

Cumulative Model Updates: 9140
Cumulative Timesteps: 76549780

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 76549780...
Checkpoint 76549780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 910.12675
Policy Entropy: 0.07723
Value Function Loss: 2.31527

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.18148
Policy Update Magnitude: 0.05251
Value Function Update Magnitude: 0.06243

Collected Steps per Second: 12871.27381
Overall Steps per Second: 2457.26152

Timestep Collection Time: 3.88757
Timestep Consumption Time: 16.47575
PPO Batch Consumption Time: 2.42828
Total Iteration Time: 20.36332

Cumulative Model Updates: 9146
Cumulative Timesteps: 76599818

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 806.67900
Policy Entropy: 0.07470
Value Function Loss: 2.24910

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.16118
Policy Update Magnitude: 0.06673
Value Function Update Magnitude: 0.06450

Collected Steps per Second: 12607.54039
Overall Steps per Second: 524.06218

Timestep Collection Time: 3.97175
Timestep Consumption Time: 91.57798
PPO Batch Consumption Time: 2.41654
Total Iteration Time: 95.54973

Cumulative Model Updates: 9152
Cumulative Timesteps: 76649892

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 887.80520
Policy Entropy: 0.07285
Value Function Loss: 2.24941

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.16752
Policy Update Magnitude: 0.06129
Value Function Update Magnitude: 0.06728

Collected Steps per Second: 12711.44567
Overall Steps per Second: 2503.56554

Timestep Collection Time: 3.93692
Timestep Consumption Time: 16.05217
PPO Batch Consumption Time: 2.35837
Total Iteration Time: 19.98909

Cumulative Model Updates: 9158
Cumulative Timesteps: 76699936

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 787.68309
Policy Entropy: 0.07304
Value Function Loss: 2.25936

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14176
Policy Update Magnitude: 0.05433
Value Function Update Magnitude: 0.06782

Collected Steps per Second: 12929.95834
Overall Steps per Second: 1440.07553

Timestep Collection Time: 3.86869
Timestep Consumption Time: 30.86699
PPO Batch Consumption Time: 2.41138
Total Iteration Time: 34.73568

Cumulative Model Updates: 9164
Cumulative Timesteps: 76749958

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682.50945
Policy Entropy: 0.06902
Value Function Loss: 2.26737

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14419
Policy Update Magnitude: 0.05297
Value Function Update Magnitude: 0.07106

Collected Steps per Second: 12756.80297
Overall Steps per Second: 2453.26066

Timestep Collection Time: 3.91979
Timestep Consumption Time: 16.46288
PPO Batch Consumption Time: 2.42445
Total Iteration Time: 20.38267

Cumulative Model Updates: 9170
Cumulative Timesteps: 76799962

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.63553
Policy Entropy: 0.06571
Value Function Loss: 2.29990

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14503
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.07379

Collected Steps per Second: 12704.04207
Overall Steps per Second: 920.18871

Timestep Collection Time: 3.93764
Timestep Consumption Time: 50.42512
PPO Batch Consumption Time: 2.37326
Total Iteration Time: 54.36276

Cumulative Model Updates: 9176
Cumulative Timesteps: 76849986

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757.07337
Policy Entropy: 0.06634
Value Function Loss: 2.23308

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.16073
Policy Update Magnitude: 0.05897
Value Function Update Magnitude: 0.06980

Collected Steps per Second: 13405.19028
Overall Steps per Second: 1280.58852

Timestep Collection Time: 3.73094
Timestep Consumption Time: 35.32454
PPO Batch Consumption Time: 2.45588
Total Iteration Time: 39.05548

Cumulative Model Updates: 9182
Cumulative Timesteps: 76900000

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.18417
Policy Entropy: 0.05998
Value Function Loss: 2.24122

Mean KL Divergence: 0.02719
SB3 Clip Fraction: 0.28180
Policy Update Magnitude: 0.06039
Value Function Update Magnitude: 0.06616

Collected Steps per Second: 12803.11504
Overall Steps per Second: 1045.76673

Timestep Collection Time: 3.90811
Timestep Consumption Time: 43.93812
PPO Batch Consumption Time: 2.37690
Total Iteration Time: 47.84623

Cumulative Model Updates: 9188
Cumulative Timesteps: 76950036

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 774.43381
Policy Entropy: 0.06056
Value Function Loss: 2.18617

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.22009
Policy Update Magnitude: 0.05082
Value Function Update Magnitude: 0.06736

Collected Steps per Second: 12622.04058
Overall Steps per Second: 2457.52423

Timestep Collection Time: 3.96576
Timestep Consumption Time: 16.40271
PPO Batch Consumption Time: 2.45868
Total Iteration Time: 20.36847

Cumulative Model Updates: 9194
Cumulative Timesteps: 77000092

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1191.85421
Policy Entropy: 0.05778
Value Function Loss: 2.26997

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.16522
Policy Update Magnitude: 0.04781
Value Function Update Magnitude: 0.06624

Collected Steps per Second: 12616.33905
Overall Steps per Second: 1595.17927

Timestep Collection Time: 3.96803
Timestep Consumption Time: 27.41528
PPO Batch Consumption Time: 2.35566
Total Iteration Time: 31.38331

Cumulative Model Updates: 9200
Cumulative Timesteps: 77050154

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 77050154...
Checkpoint 77050154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1094.55271
Policy Entropy: 0.05544
Value Function Loss: 2.25733

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.17078
Policy Update Magnitude: 0.05048
Value Function Update Magnitude: 0.07088

Collected Steps per Second: 12576.51963
Overall Steps per Second: 2461.15857

Timestep Collection Time: 3.97693
Timestep Consumption Time: 16.34520
PPO Batch Consumption Time: 2.41133
Total Iteration Time: 20.32214

Cumulative Model Updates: 9206
Cumulative Timesteps: 77100170

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1459.99117
Policy Entropy: 0.05385
Value Function Loss: 2.22306

Mean KL Divergence: 0.02451
SB3 Clip Fraction: 0.29637
Policy Update Magnitude: 0.05304
Value Function Update Magnitude: 0.06700

Collected Steps per Second: 13387.93493
Overall Steps per Second: 2469.38543

Timestep Collection Time: 3.73844
Timestep Consumption Time: 16.52976
PPO Batch Consumption Time: 2.43273
Total Iteration Time: 20.26820

Cumulative Model Updates: 9212
Cumulative Timesteps: 77150220

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.83244
Policy Entropy: 0.04951
Value Function Loss: 2.23508

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.21197
Policy Update Magnitude: 0.04032
Value Function Update Magnitude: 0.06500

Collected Steps per Second: 12537.79044
Overall Steps per Second: 2440.31389

Timestep Collection Time: 3.98954
Timestep Consumption Time: 16.50782
PPO Batch Consumption Time: 2.43957
Total Iteration Time: 20.49736

Cumulative Model Updates: 9218
Cumulative Timesteps: 77200240

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 906.59273
Policy Entropy: 0.05101
Value Function Loss: 2.23618

Mean KL Divergence: 0.02390
SB3 Clip Fraction: 0.27368
Policy Update Magnitude: 0.04475
Value Function Update Magnitude: 0.07026

Collected Steps per Second: 12436.73262
Overall Steps per Second: 2546.36931

Timestep Collection Time: 4.02276
Timestep Consumption Time: 15.62482
PPO Batch Consumption Time: 2.32859
Total Iteration Time: 19.64758

Cumulative Model Updates: 9224
Cumulative Timesteps: 77250270

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530.89296
Policy Entropy: 0.04993
Value Function Loss: 2.23923

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.21697
Policy Update Magnitude: 0.03687
Value Function Update Magnitude: 0.06992

Collected Steps per Second: 12907.95996
Overall Steps per Second: 2379.23277

Timestep Collection Time: 3.87745
Timestep Consumption Time: 17.15874
PPO Batch Consumption Time: 2.40974
Total Iteration Time: 21.03619

Cumulative Model Updates: 9230
Cumulative Timesteps: 77300320

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 898.13229
Policy Entropy: 0.04771
Value Function Loss: 2.21201

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.17050
Policy Update Magnitude: 0.04422
Value Function Update Magnitude: 0.06766

Collected Steps per Second: 12783.54502
Overall Steps per Second: 2558.60151

Timestep Collection Time: 3.91300
Timestep Consumption Time: 15.63752
PPO Batch Consumption Time: 2.33676
Total Iteration Time: 19.55052

Cumulative Model Updates: 9236
Cumulative Timesteps: 77350342

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.01675
Policy Entropy: 0.04357
Value Function Loss: 2.23715

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.17315
Policy Update Magnitude: 0.04949
Value Function Update Magnitude: 0.07104

Collected Steps per Second: 12767.72556
Overall Steps per Second: 652.27250

Timestep Collection Time: 3.92004
Timestep Consumption Time: 72.81169
PPO Batch Consumption Time: 2.32809
Total Iteration Time: 76.73173

Cumulative Model Updates: 9242
Cumulative Timesteps: 77400392

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1293.54065
Policy Entropy: 0.04162
Value Function Loss: 2.30769

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14716
Policy Update Magnitude: 0.04783
Value Function Update Magnitude: 0.07064

Collected Steps per Second: 12525.27546
Overall Steps per Second: 2453.29455

Timestep Collection Time: 3.99432
Timestep Consumption Time: 16.39866
PPO Batch Consumption Time: 2.41553
Total Iteration Time: 20.39299

Cumulative Model Updates: 9248
Cumulative Timesteps: 77450422

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1080.85096
Policy Entropy: 0.04146
Value Function Loss: 2.22642

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.17671
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.06931

Collected Steps per Second: 13317.84444
Overall Steps per Second: 1164.24341

Timestep Collection Time: 3.75436
Timestep Consumption Time: 39.19198
PPO Batch Consumption Time: 2.40515
Total Iteration Time: 42.94635

Cumulative Model Updates: 9254
Cumulative Timesteps: 77500422

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 558.59355
Policy Entropy: 0.03568
Value Function Loss: 2.22858

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.06384
Value Function Update Magnitude: 0.06744

Collected Steps per Second: 12829.90500
Overall Steps per Second: 2419.41441

Timestep Collection Time: 3.90135
Timestep Consumption Time: 16.78712
PPO Batch Consumption Time: 2.47525
Total Iteration Time: 20.68848

Cumulative Model Updates: 9260
Cumulative Timesteps: 77550476

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 77550476...
Checkpoint 77550476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 985.76514
Policy Entropy: 0.03202
Value Function Loss: 2.19509

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.18130
Policy Update Magnitude: 0.06374
Value Function Update Magnitude: 0.06517

Collected Steps per Second: 12644.20644
Overall Steps per Second: 814.74556

Timestep Collection Time: 3.96466
Timestep Consumption Time: 57.56375
PPO Batch Consumption Time: 2.39561
Total Iteration Time: 61.52841

Cumulative Model Updates: 9266
Cumulative Timesteps: 77600606

Timesteps Collected: 50130
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1213.72097
Policy Entropy: 0.02962
Value Function Loss: 2.25051

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.17888
Policy Update Magnitude: 0.05092
Value Function Update Magnitude: 0.06579

Collected Steps per Second: 12548.44073
Overall Steps per Second: 1174.19754

Timestep Collection Time: 3.98488
Timestep Consumption Time: 38.60080
PPO Batch Consumption Time: 2.42606
Total Iteration Time: 42.58568

Cumulative Model Updates: 9272
Cumulative Timesteps: 77650610

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1251.37990
Policy Entropy: 0.02591
Value Function Loss: 2.21868

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.04830
Value Function Update Magnitude: 0.06263

Collected Steps per Second: 12618.26671
Overall Steps per Second: 2360.30778

Timestep Collection Time: 3.96378
Timestep Consumption Time: 17.22668
PPO Batch Consumption Time: 2.45419
Total Iteration Time: 21.19046

Cumulative Model Updates: 9278
Cumulative Timesteps: 77700626

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.22705
Policy Entropy: 0.02391
Value Function Loss: 2.27876

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.19707
Policy Update Magnitude: 0.04695
Value Function Update Magnitude: 0.07281

Collected Steps per Second: 13257.64562
Overall Steps per Second: 2444.34787

Timestep Collection Time: 3.77382
Timestep Consumption Time: 16.69462
PPO Batch Consumption Time: 2.46702
Total Iteration Time: 20.46845

Cumulative Model Updates: 9284
Cumulative Timesteps: 77750658

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701.97099
Policy Entropy: 0.02605
Value Function Loss: 2.25620

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.19727
Policy Update Magnitude: 0.04190
Value Function Update Magnitude: 0.07304

Collected Steps per Second: 12728.45892
Overall Steps per Second: 2488.93973

Timestep Collection Time: 3.93025
Timestep Consumption Time: 16.16907
PPO Batch Consumption Time: 2.38757
Total Iteration Time: 20.09932

Cumulative Model Updates: 9290
Cumulative Timesteps: 77800684

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 938.11271
Policy Entropy: 0.02192
Value Function Loss: 2.27751

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.17705
Policy Update Magnitude: 0.04234
Value Function Update Magnitude: 0.08166

Collected Steps per Second: 12813.12343
Overall Steps per Second: 2490.08289

Timestep Collection Time: 3.90724
Timestep Consumption Time: 16.19811
PPO Batch Consumption Time: 2.42195
Total Iteration Time: 20.10535

Cumulative Model Updates: 9296
Cumulative Timesteps: 77850748

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728.73127
Policy Entropy: 0.02111
Value Function Loss: 2.23334

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.23429
Policy Update Magnitude: 0.07386
Value Function Update Magnitude: 0.07555

Collected Steps per Second: 12849.34324
Overall Steps per Second: 2435.42265

Timestep Collection Time: 3.89483
Timestep Consumption Time: 16.65438
PPO Batch Consumption Time: 2.45753
Total Iteration Time: 20.54921

Cumulative Model Updates: 9302
Cumulative Timesteps: 77900794

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690.12071
Policy Entropy: 0.02052
Value Function Loss: 2.28665

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.19399
Policy Update Magnitude: 0.05169
Value Function Update Magnitude: 0.07534

Collected Steps per Second: 12426.73701
Overall Steps per Second: 2516.15214

Timestep Collection Time: 4.02922
Timestep Consumption Time: 15.87022
PPO Batch Consumption Time: 2.35728
Total Iteration Time: 19.89943

Cumulative Model Updates: 9308
Cumulative Timesteps: 77950864

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1265.29720
Policy Entropy: 0.01976
Value Function Loss: 2.24059

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.18385
Policy Update Magnitude: 0.04356
Value Function Update Magnitude: 0.07086

Collected Steps per Second: 13326.10777
Overall Steps per Second: 2272.50851

Timestep Collection Time: 3.75519
Timestep Consumption Time: 18.26541
PPO Batch Consumption Time: 2.41074
Total Iteration Time: 22.02060

Cumulative Model Updates: 9314
Cumulative Timesteps: 78000906

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679.56988
Policy Entropy: 0.01829
Value Function Loss: 2.21975

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.18507
Policy Update Magnitude: 0.04217
Value Function Update Magnitude: 0.07116

Collected Steps per Second: 12519.30288
Overall Steps per Second: 2538.98937

Timestep Collection Time: 4.00214
Timestep Consumption Time: 15.73170
PPO Batch Consumption Time: 2.31696
Total Iteration Time: 19.73384

Cumulative Model Updates: 9320
Cumulative Timesteps: 78051010

Timesteps Collected: 50104
--------END ITERATION REPORT--------


Saving checkpoint 78051010...
Checkpoint 78051010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1527.72292
Policy Entropy: 0.01401
Value Function Loss: 2.24249

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.17897
Policy Update Magnitude: 0.04703
Value Function Update Magnitude: 0.06911

Collected Steps per Second: 13497.91041
Overall Steps per Second: 2500.65931

Timestep Collection Time: 3.70872
Timestep Consumption Time: 16.31000
PPO Batch Consumption Time: 2.40670
Total Iteration Time: 20.01872

Cumulative Model Updates: 9326
Cumulative Timesteps: 78101070

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.53632
Policy Entropy: 0.01364
Value Function Loss: 2.27763

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.15888
Policy Update Magnitude: 0.04403
Value Function Update Magnitude: 0.06704

Collected Steps per Second: 13259.87878
Overall Steps per Second: 2504.54396

Timestep Collection Time: 3.77696
Timestep Consumption Time: 16.21950
PPO Batch Consumption Time: 2.39346
Total Iteration Time: 19.99645

Cumulative Model Updates: 9332
Cumulative Timesteps: 78151152

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 887.50855
Policy Entropy: 0.01141
Value Function Loss: 2.29392

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.16503
Policy Update Magnitude: 0.04722
Value Function Update Magnitude: 0.06723

Collected Steps per Second: 13309.55430
Overall Steps per Second: 2603.90278

Timestep Collection Time: 3.75986
Timestep Consumption Time: 15.45822
PPO Batch Consumption Time: 2.30865
Total Iteration Time: 19.21808

Cumulative Model Updates: 9338
Cumulative Timesteps: 78201194

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.87593
Policy Entropy: 0.01171
Value Function Loss: 2.29918

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.15632
Policy Update Magnitude: 0.04699
Value Function Update Magnitude: 0.07101

Collected Steps per Second: 13222.80647
Overall Steps per Second: 2484.61521

Timestep Collection Time: 3.78755
Timestep Consumption Time: 16.36930
PPO Batch Consumption Time: 2.41936
Total Iteration Time: 20.15684

Cumulative Model Updates: 9344
Cumulative Timesteps: 78251276

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.21765
Policy Entropy: 0.01242
Value Function Loss: 2.32050

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.15600
Policy Update Magnitude: 0.04888
Value Function Update Magnitude: 0.07140

Collected Steps per Second: 12563.70724
Overall Steps per Second: 2487.24811

Timestep Collection Time: 3.97972
Timestep Consumption Time: 16.12282
PPO Batch Consumption Time: 2.37520
Total Iteration Time: 20.10254

Cumulative Model Updates: 9350
Cumulative Timesteps: 78301276

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.50347
Policy Entropy: 0.01330
Value Function Loss: 2.32281

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11490
Policy Update Magnitude: 0.04969
Value Function Update Magnitude: 0.06764

Collected Steps per Second: 13459.59674
Overall Steps per Second: 2464.62993

Timestep Collection Time: 3.71794
Timestep Consumption Time: 16.58612
PPO Batch Consumption Time: 2.44915
Total Iteration Time: 20.30406

Cumulative Model Updates: 9356
Cumulative Timesteps: 78351318

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.84012
Policy Entropy: 0.01064
Value Function Loss: 2.28633

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.06507

Collected Steps per Second: 12925.65601
Overall Steps per Second: 907.97343

Timestep Collection Time: 3.86998
Timestep Consumption Time: 51.22194
PPO Batch Consumption Time: 2.34223
Total Iteration Time: 55.09192

Cumulative Model Updates: 9362
Cumulative Timesteps: 78401340

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 806.48020
Policy Entropy: 0.00943
Value Function Loss: 2.25582

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14979
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.06694

Collected Steps per Second: 12519.27481
Overall Steps per Second: 2497.91622

Timestep Collection Time: 3.99752
Timestep Consumption Time: 16.03758
PPO Batch Consumption Time: 2.39915
Total Iteration Time: 20.03510

Cumulative Model Updates: 9368
Cumulative Timesteps: 78451386

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.37482
Policy Entropy: 0.00727
Value Function Loss: 2.19468

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.16028
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.06733

Collected Steps per Second: 12648.35626
Overall Steps per Second: 2445.49774

Timestep Collection Time: 3.95972
Timestep Consumption Time: 16.52036
PPO Batch Consumption Time: 2.43253
Total Iteration Time: 20.48008

Cumulative Model Updates: 9374
Cumulative Timesteps: 78501470

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 854.45981
Policy Entropy: 0.00571
Value Function Loss: 2.20510

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.06024
Value Function Update Magnitude: 0.06642

Collected Steps per Second: 12930.42751
Overall Steps per Second: 2452.72222

Timestep Collection Time: 3.86793
Timestep Consumption Time: 16.52329
PPO Batch Consumption Time: 2.45931
Total Iteration Time: 20.39122

Cumulative Model Updates: 9380
Cumulative Timesteps: 78551484

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 78551484...
Checkpoint 78551484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 866.18619
Policy Entropy: 0.00152
Value Function Loss: 2.15550

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14608
Policy Update Magnitude: 0.06305
Value Function Update Magnitude: 0.06523

Collected Steps per Second: 12895.27739
Overall Steps per Second: 2421.76898

Timestep Collection Time: 3.87971
Timestep Consumption Time: 16.77874
PPO Batch Consumption Time: 2.48219
Total Iteration Time: 20.65845

Cumulative Model Updates: 9386
Cumulative Timesteps: 78601514

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1024.64158
Policy Entropy: -0.00401
Value Function Loss: 2.10103

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.06997
Value Function Update Magnitude: 0.06534

Collected Steps per Second: 12618.02510
Overall Steps per Second: 741.01285

Timestep Collection Time: 3.96401
Timestep Consumption Time: 63.53549
PPO Batch Consumption Time: 2.38702
Total Iteration Time: 67.49950

Cumulative Model Updates: 9392
Cumulative Timesteps: 78651532

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 847.25203
Policy Entropy: -0.00699
Value Function Loss: 2.05198

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.18166
Policy Update Magnitude: 0.06248
Value Function Update Magnitude: 0.06567

Collected Steps per Second: 13098.37200
Overall Steps per Second: 2493.62047

Timestep Collection Time: 3.82139
Timestep Consumption Time: 16.25143
PPO Batch Consumption Time: 2.39358
Total Iteration Time: 20.07282

Cumulative Model Updates: 9398
Cumulative Timesteps: 78701586

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1064.39572
Policy Entropy: -0.00639
Value Function Loss: 2.10954

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.16836
Policy Update Magnitude: 0.04831
Value Function Update Magnitude: 0.06518

Collected Steps per Second: 12747.97957
Overall Steps per Second: 548.55183

Timestep Collection Time: 3.92250
Timestep Consumption Time: 87.23388
PPO Batch Consumption Time: 2.39435
Total Iteration Time: 91.15638

Cumulative Model Updates: 9404
Cumulative Timesteps: 78751590

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1054.89824
Policy Entropy: -0.00807
Value Function Loss: 2.16867

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.16690
Policy Update Magnitude: 0.04370
Value Function Update Magnitude: 0.06533

Collected Steps per Second: 12313.18698
Overall Steps per Second: 2531.06187

Timestep Collection Time: 4.06588
Timestep Consumption Time: 15.71396
PPO Batch Consumption Time: 2.34006
Total Iteration Time: 19.77984

Cumulative Model Updates: 9410
Cumulative Timesteps: 78801654

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 538.42300
Policy Entropy: -0.00711
Value Function Loss: 2.19098

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14178
Policy Update Magnitude: 0.05606
Value Function Update Magnitude: 0.06571

Collected Steps per Second: 12486.91047
Overall Steps per Second: 2434.46015

Timestep Collection Time: 4.00804
Timestep Consumption Time: 16.55011
PPO Batch Consumption Time: 2.44008
Total Iteration Time: 20.55815

Cumulative Model Updates: 9416
Cumulative Timesteps: 78851702

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1004.96260
Policy Entropy: -0.00899
Value Function Loss: 2.20659

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.16044
Policy Update Magnitude: 0.05120
Value Function Update Magnitude: 0.07167

Collected Steps per Second: 12838.31608
Overall Steps per Second: 1396.50077

Timestep Collection Time: 3.89631
Timestep Consumption Time: 31.92322
PPO Batch Consumption Time: 2.36876
Total Iteration Time: 35.81953

Cumulative Model Updates: 9422
Cumulative Timesteps: 78901724

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.07360
Policy Entropy: -0.00847
Value Function Loss: 2.22899

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.05327
Value Function Update Magnitude: 0.06759

Collected Steps per Second: 14921.69823
Overall Steps per Second: 2517.05783

Timestep Collection Time: 3.35565
Timestep Consumption Time: 16.53742
PPO Batch Consumption Time: 2.41241
Total Iteration Time: 19.89307

Cumulative Model Updates: 9428
Cumulative Timesteps: 78951796

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.95509
Policy Entropy: -0.01069
Value Function Loss: 2.20800

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.15482
Policy Update Magnitude: 0.05834
Value Function Update Magnitude: 0.06582

Collected Steps per Second: 13123.48389
Overall Steps per Second: 2458.33293

Timestep Collection Time: 3.81560
Timestep Consumption Time: 16.55349
PPO Batch Consumption Time: 2.41192
Total Iteration Time: 20.36909

Cumulative Model Updates: 9434
Cumulative Timesteps: 79001870

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1077.69444
Policy Entropy: -0.00887
Value Function Loss: 2.15715

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.18436
Policy Update Magnitude: 0.05122
Value Function Update Magnitude: 0.06705

Collected Steps per Second: 12782.65347
Overall Steps per Second: 2460.60215

Timestep Collection Time: 3.91797
Timestep Consumption Time: 16.43559
PPO Batch Consumption Time: 2.46180
Total Iteration Time: 20.35355

Cumulative Model Updates: 9440
Cumulative Timesteps: 79051952

Timesteps Collected: 50082
--------END ITERATION REPORT--------


Saving checkpoint 79051952...
Checkpoint 79051952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.29757
Policy Entropy: -0.00892
Value Function Loss: 2.17325

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.16760
Policy Update Magnitude: 0.04669
Value Function Update Magnitude: 0.07221

Collected Steps per Second: 13324.81922
Overall Steps per Second: 2479.34277

Timestep Collection Time: 3.75855
Timestep Consumption Time: 16.44116
PPO Batch Consumption Time: 2.40042
Total Iteration Time: 20.19971

Cumulative Model Updates: 9446
Cumulative Timesteps: 79102034

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584.40662
Policy Entropy: -0.01018
Value Function Loss: 2.25636

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.15358
Policy Update Magnitude: 0.05113
Value Function Update Magnitude: 0.06872

Collected Steps per Second: 14284.10618
Overall Steps per Second: 2523.44706

Timestep Collection Time: 3.50277
Timestep Consumption Time: 16.32487
PPO Batch Consumption Time: 2.39753
Total Iteration Time: 19.82764

Cumulative Model Updates: 9452
Cumulative Timesteps: 79152068

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.29339
Policy Entropy: -0.01293
Value Function Loss: 2.28869

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.15340
Policy Update Magnitude: 0.05506
Value Function Update Magnitude: 0.06500

Collected Steps per Second: 13354.85445
Overall Steps per Second: 2573.54842

Timestep Collection Time: 3.75115
Timestep Consumption Time: 15.71459
PPO Batch Consumption Time: 2.30441
Total Iteration Time: 19.46573

Cumulative Model Updates: 9458
Cumulative Timesteps: 79202164

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 812.69786
Policy Entropy: -0.01711
Value Function Loss: 2.22628

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.14583
Policy Update Magnitude: 0.05313
Value Function Update Magnitude: 0.06598

Collected Steps per Second: 12773.91157
Overall Steps per Second: 2534.05558

Timestep Collection Time: 3.91501
Timestep Consumption Time: 15.82015
PPO Batch Consumption Time: 2.34776
Total Iteration Time: 19.73516

Cumulative Model Updates: 9464
Cumulative Timesteps: 79252174

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.95856
Policy Entropy: -0.01782
Value Function Loss: 2.17410

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.04776
Value Function Update Magnitude: 0.06510

Collected Steps per Second: 13153.32864
Overall Steps per Second: 2550.57501

Timestep Collection Time: 3.80345
Timestep Consumption Time: 15.81095
PPO Batch Consumption Time: 2.31859
Total Iteration Time: 19.61440

Cumulative Model Updates: 9470
Cumulative Timesteps: 79302202

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1262.46625
Policy Entropy: -0.01926
Value Function Loss: 2.17169

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.04743
Value Function Update Magnitude: 0.06492

Collected Steps per Second: 14918.68181
Overall Steps per Second: 2622.37765

Timestep Collection Time: 3.35365
Timestep Consumption Time: 15.72522
PPO Batch Consumption Time: 2.30095
Total Iteration Time: 19.07887

Cumulative Model Updates: 9476
Cumulative Timesteps: 79352234

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.26538
Policy Entropy: -0.02048
Value Function Loss: 2.15519

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.15503
Policy Update Magnitude: 0.04861
Value Function Update Magnitude: 0.06605

Collected Steps per Second: 13666.72136
Overall Steps per Second: 2523.89294

Timestep Collection Time: 3.65867
Timestep Consumption Time: 16.15279
PPO Batch Consumption Time: 2.38834
Total Iteration Time: 19.81146

Cumulative Model Updates: 9482
Cumulative Timesteps: 79402236

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1029.26290
Policy Entropy: -0.02427
Value Function Loss: 2.12458

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.16380
Policy Update Magnitude: 0.04499
Value Function Update Magnitude: 0.06990

Collected Steps per Second: 13168.49861
Overall Steps per Second: 2453.51908

Timestep Collection Time: 3.79998
Timestep Consumption Time: 16.59522
PPO Batch Consumption Time: 2.43857
Total Iteration Time: 20.39519

Cumulative Model Updates: 9488
Cumulative Timesteps: 79452276

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1248.35332
Policy Entropy: -0.02411
Value Function Loss: 2.10190

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.16756
Policy Update Magnitude: 0.04438
Value Function Update Magnitude: 0.07423

Collected Steps per Second: 13012.98397
Overall Steps per Second: 2522.63124

Timestep Collection Time: 3.84708
Timestep Consumption Time: 15.99807
PPO Batch Consumption Time: 2.39415
Total Iteration Time: 19.84515

Cumulative Model Updates: 9494
Cumulative Timesteps: 79502338

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1088.74070
Policy Entropy: -0.02876
Value Function Loss: 2.10746

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15456
Policy Update Magnitude: 0.04495
Value Function Update Magnitude: 0.07137

Collected Steps per Second: 13679.78689
Overall Steps per Second: 2516.55032

Timestep Collection Time: 3.65547
Timestep Consumption Time: 16.21539
PPO Batch Consumption Time: 2.37878
Total Iteration Time: 19.87085

Cumulative Model Updates: 9500
Cumulative Timesteps: 79552344

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 79552344...
Checkpoint 79552344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1195.35318
Policy Entropy: -0.02832
Value Function Loss: 2.11224

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.14133
Policy Update Magnitude: 0.04619
Value Function Update Magnitude: 0.07263

Collected Steps per Second: 12277.85874
Overall Steps per Second: 2508.99102

Timestep Collection Time: 4.07677
Timestep Consumption Time: 15.87308
PPO Batch Consumption Time: 2.36531
Total Iteration Time: 19.94985

Cumulative Model Updates: 9506
Cumulative Timesteps: 79602398

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836.78845
Policy Entropy: -0.03116
Value Function Loss: 2.10717

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14068
Policy Update Magnitude: 0.04479
Value Function Update Magnitude: 0.07365

Collected Steps per Second: 12721.98738
Overall Steps per Second: 2530.80091

Timestep Collection Time: 3.93272
Timestep Consumption Time: 15.83652
PPO Batch Consumption Time: 2.33683
Total Iteration Time: 19.76924

Cumulative Model Updates: 9512
Cumulative Timesteps: 79652430

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1329.54665
Policy Entropy: -0.03209
Value Function Loss: 2.09946

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.14519
Policy Update Magnitude: 0.05059
Value Function Update Magnitude: 0.07299

Collected Steps per Second: 12447.32861
Overall Steps per Second: 2470.96826

Timestep Collection Time: 4.01918
Timestep Consumption Time: 16.22714
PPO Batch Consumption Time: 2.38669
Total Iteration Time: 20.24631

Cumulative Model Updates: 9518
Cumulative Timesteps: 79702458

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1328.16783
Policy Entropy: -0.03448
Value Function Loss: 2.09252

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.15167
Policy Update Magnitude: 0.05402
Value Function Update Magnitude: 0.06974

Collected Steps per Second: 16909.09641
Overall Steps per Second: 2596.74514

Timestep Collection Time: 2.95699
Timestep Consumption Time: 16.29789
PPO Batch Consumption Time: 2.40502
Total Iteration Time: 19.25487

Cumulative Model Updates: 9524
Cumulative Timesteps: 79752458

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 882.95922
Policy Entropy: -0.03495
Value Function Loss: 2.09401

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.16274
Policy Update Magnitude: 0.05090
Value Function Update Magnitude: 0.06694

Collected Steps per Second: 15318.17137
Overall Steps per Second: 2467.10921

Timestep Collection Time: 3.26814
Timestep Consumption Time: 17.02362
PPO Batch Consumption Time: 2.52377
Total Iteration Time: 20.29176

Cumulative Model Updates: 9530
Cumulative Timesteps: 79802520

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1334.51057
Policy Entropy: -0.03733
Value Function Loss: 2.14732

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.16491
Policy Update Magnitude: 0.04715
Value Function Update Magnitude: 0.06292

Collected Steps per Second: 16864.94281
Overall Steps per Second: 2489.85821

Timestep Collection Time: 2.96698
Timestep Consumption Time: 17.12974
PPO Batch Consumption Time: 2.54382
Total Iteration Time: 20.09673

Cumulative Model Updates: 9536
Cumulative Timesteps: 79852558

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1063.77829
Policy Entropy: -0.03779
Value Function Loss: 2.19593

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15678
Policy Update Magnitude: 0.05208
Value Function Update Magnitude: 0.06269

Collected Steps per Second: 15107.68611
Overall Steps per Second: 2592.01376

Timestep Collection Time: 3.31129
Timestep Consumption Time: 15.98876
PPO Batch Consumption Time: 2.36252
Total Iteration Time: 19.30005

Cumulative Model Updates: 9542
Cumulative Timesteps: 79902584

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 889.32437
Policy Entropy: -0.04184
Value Function Loss: 2.14880

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.15278
Policy Update Magnitude: 0.05627
Value Function Update Magnitude: 0.06955

Collected Steps per Second: 13755.46214
Overall Steps per Second: 2553.66688

Timestep Collection Time: 3.63710
Timestep Consumption Time: 15.95433
PPO Batch Consumption Time: 2.35958
Total Iteration Time: 19.59144

Cumulative Model Updates: 9548
Cumulative Timesteps: 79952614

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1375.55944
Policy Entropy: -0.04187
Value Function Loss: 2.15215

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.15806
Policy Update Magnitude: 0.05681
Value Function Update Magnitude: 0.07058

Collected Steps per Second: 15806.46083
Overall Steps per Second: 2569.15970

Timestep Collection Time: 3.16706
Timestep Consumption Time: 16.31791
PPO Batch Consumption Time: 2.39865
Total Iteration Time: 19.48497

Cumulative Model Updates: 9554
Cumulative Timesteps: 80002674

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1310.70830
Policy Entropy: -0.04498
Value Function Loss: 2.14555

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.16780
Policy Update Magnitude: 0.05614
Value Function Update Magnitude: 0.07472

Collected Steps per Second: 15960.25996
Overall Steps per Second: 2566.29641

Timestep Collection Time: 3.13278
Timestep Consumption Time: 16.35055
PPO Batch Consumption Time: 2.39242
Total Iteration Time: 19.48333

Cumulative Model Updates: 9560
Cumulative Timesteps: 80052674

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 80052674...
Checkpoint 80052674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1170.80054
Policy Entropy: -0.04507
Value Function Loss: 2.18355

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.15700
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.07296

Collected Steps per Second: 12770.87057
Overall Steps per Second: 2471.83480

Timestep Collection Time: 3.91516
Timestep Consumption Time: 16.31273
PPO Batch Consumption Time: 2.38829
Total Iteration Time: 20.22789

Cumulative Model Updates: 9566
Cumulative Timesteps: 80102674

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1265.97937
Policy Entropy: -0.04826
Value Function Loss: 2.25808

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.14306
Policy Update Magnitude: 0.06261
Value Function Update Magnitude: 0.07095

Collected Steps per Second: 13609.96290
Overall Steps per Second: 2512.23422

Timestep Collection Time: 3.67789
Timestep Consumption Time: 16.24700
PPO Batch Consumption Time: 2.40418
Total Iteration Time: 19.92489

Cumulative Model Updates: 9572
Cumulative Timesteps: 80152730

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.81887
Policy Entropy: -0.04773
Value Function Loss: 2.19514

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14297
Policy Update Magnitude: 0.05862
Value Function Update Magnitude: 0.07083

Collected Steps per Second: 13080.54622
Overall Steps per Second: 2538.09616

Timestep Collection Time: 3.82553
Timestep Consumption Time: 15.89004
PPO Batch Consumption Time: 2.34837
Total Iteration Time: 19.71557

Cumulative Model Updates: 9578
Cumulative Timesteps: 80202770

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1296.97296
Policy Entropy: -0.04895
Value Function Loss: 2.26859

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.14276
Policy Update Magnitude: 0.05521
Value Function Update Magnitude: 0.07060

Collected Steps per Second: 12433.75331
Overall Steps per Second: 2597.93414

Timestep Collection Time: 4.02759
Timestep Consumption Time: 15.24850
PPO Batch Consumption Time: 2.25659
Total Iteration Time: 19.27609

Cumulative Model Updates: 9584
Cumulative Timesteps: 80252848

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 896.64320
Policy Entropy: -0.05003
Value Function Loss: 2.20126

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.05350
Value Function Update Magnitude: 0.06937

Collected Steps per Second: 13375.12602
Overall Steps per Second: 2585.07653

Timestep Collection Time: 3.74157
Timestep Consumption Time: 15.61724
PPO Batch Consumption Time: 2.28999
Total Iteration Time: 19.35881

Cumulative Model Updates: 9590
Cumulative Timesteps: 80302892

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.34364
Policy Entropy: -0.05177
Value Function Loss: 2.24633

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.15804
Policy Update Magnitude: 0.06000
Value Function Update Magnitude: 0.06945

Collected Steps per Second: 12568.29102
Overall Steps per Second: 2486.57560

Timestep Collection Time: 3.97970
Timestep Consumption Time: 16.13552
PPO Batch Consumption Time: 2.39511
Total Iteration Time: 20.11521

Cumulative Model Updates: 9596
Cumulative Timesteps: 80352910

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1505.62649
Policy Entropy: -0.05303
Value Function Loss: 2.18988

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.16174
Policy Update Magnitude: 0.06433
Value Function Update Magnitude: 0.07678

Collected Steps per Second: 17816.15607
Overall Steps per Second: 2598.50022

Timestep Collection Time: 2.81015
Timestep Consumption Time: 16.45712
PPO Batch Consumption Time: 2.42337
Total Iteration Time: 19.26727

Cumulative Model Updates: 9602
Cumulative Timesteps: 80402976

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.63896
Policy Entropy: -0.05686
Value Function Loss: 2.12112

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.06581
Value Function Update Magnitude: 0.07267

Collected Steps per Second: 13105.19866
Overall Steps per Second: 2460.75783

Timestep Collection Time: 3.81971
Timestep Consumption Time: 16.52281
PPO Batch Consumption Time: 2.42667
Total Iteration Time: 20.34251

Cumulative Model Updates: 9608
Cumulative Timesteps: 80453034

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.74080
Policy Entropy: -0.05736
Value Function Loss: 2.13333

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.14494
Policy Update Magnitude: 0.05728
Value Function Update Magnitude: 0.06943

Collected Steps per Second: 14485.89957
Overall Steps per Second: 2534.06564

Timestep Collection Time: 3.45246
Timestep Consumption Time: 16.28341
PPO Batch Consumption Time: 2.43726
Total Iteration Time: 19.73587

Cumulative Model Updates: 9614
Cumulative Timesteps: 80503046

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1122.24339
Policy Entropy: -0.06014
Value Function Loss: 2.10682

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14681
Policy Update Magnitude: 0.05701
Value Function Update Magnitude: 0.07160

Collected Steps per Second: 15503.15912
Overall Steps per Second: 2575.75232

Timestep Collection Time: 3.22863
Timestep Consumption Time: 16.20414
PPO Batch Consumption Time: 2.37922
Total Iteration Time: 19.43277

Cumulative Model Updates: 9620
Cumulative Timesteps: 80553100

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 80553100...
Checkpoint 80553100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1368.92038
Policy Entropy: -0.05953
Value Function Loss: 2.13597

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.16241
Policy Update Magnitude: 0.05811
Value Function Update Magnitude: 0.06913

Collected Steps per Second: 12590.95438
Overall Steps per Second: 2513.25945

Timestep Collection Time: 3.97412
Timestep Consumption Time: 15.93548
PPO Batch Consumption Time: 2.37869
Total Iteration Time: 19.90960

Cumulative Model Updates: 9626
Cumulative Timesteps: 80603138

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.12422
Policy Entropy: -0.05925
Value Function Loss: 2.08950

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.15951
Policy Update Magnitude: 0.05872
Value Function Update Magnitude: 0.07189

Collected Steps per Second: 12722.69629
Overall Steps per Second: 2616.40845

Timestep Collection Time: 3.93376
Timestep Consumption Time: 15.19475
PPO Batch Consumption Time: 2.23707
Total Iteration Time: 19.12851

Cumulative Model Updates: 9632
Cumulative Timesteps: 80653186

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1404.65767
Policy Entropy: -0.05810
Value Function Loss: 2.05650

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.15673
Policy Update Magnitude: 0.05908
Value Function Update Magnitude: 0.07516

Collected Steps per Second: 12628.22940
Overall Steps per Second: 2542.67815

Timestep Collection Time: 3.96619
Timestep Consumption Time: 15.73193
PPO Batch Consumption Time: 2.31324
Total Iteration Time: 19.69813

Cumulative Model Updates: 9638
Cumulative Timesteps: 80703272

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 993.25618
Policy Entropy: -0.05998
Value Function Loss: 2.09524

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.15259
Policy Update Magnitude: 0.05533
Value Function Update Magnitude: 0.07826

Collected Steps per Second: 13366.77094
Overall Steps per Second: 2589.46889

Timestep Collection Time: 3.74212
Timestep Consumption Time: 15.57459
PPO Batch Consumption Time: 2.29953
Total Iteration Time: 19.31670

Cumulative Model Updates: 9644
Cumulative Timesteps: 80753292

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1336.03656
Policy Entropy: -0.05964
Value Function Loss: 2.12411

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14842
Policy Update Magnitude: 0.05437
Value Function Update Magnitude: 0.07313

Collected Steps per Second: 16311.74615
Overall Steps per Second: 2582.62248

Timestep Collection Time: 3.06773
Timestep Consumption Time: 16.30793
PPO Batch Consumption Time: 2.41403
Total Iteration Time: 19.37565

Cumulative Model Updates: 9650
Cumulative Timesteps: 80803332

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 739.80748
Policy Entropy: -0.06371
Value Function Loss: 2.12247

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.15543
Policy Update Magnitude: 0.05705
Value Function Update Magnitude: 0.06745

Collected Steps per Second: 14600.82909
Overall Steps per Second: 2529.07838

Timestep Collection Time: 3.42652
Timestep Consumption Time: 16.35539
PPO Batch Consumption Time: 2.39887
Total Iteration Time: 19.78191

Cumulative Model Updates: 9656
Cumulative Timesteps: 80853362

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.10109
Policy Entropy: -0.06422
Value Function Loss: 2.12954

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15704
Policy Update Magnitude: 0.05407
Value Function Update Magnitude: 0.06524

Collected Steps per Second: 14384.08581
Overall Steps per Second: 2492.91148

Timestep Collection Time: 3.47745
Timestep Consumption Time: 16.58744
PPO Batch Consumption Time: 2.40370
Total Iteration Time: 20.06489

Cumulative Model Updates: 9662
Cumulative Timesteps: 80903382

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1109.53338
Policy Entropy: -0.06609
Value Function Loss: 2.09119

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.16694
Policy Update Magnitude: 0.05431
Value Function Update Magnitude: 0.06612

Collected Steps per Second: 14295.22014
Overall Steps per Second: 2572.75040

Timestep Collection Time: 3.49823
Timestep Consumption Time: 15.93933
PPO Batch Consumption Time: 2.36375
Total Iteration Time: 19.43756

Cumulative Model Updates: 9668
Cumulative Timesteps: 80953390

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1325.50219
Policy Entropy: -0.06308
Value Function Loss: 2.10275

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.15673
Policy Update Magnitude: 0.05490
Value Function Update Magnitude: 0.06454

Collected Steps per Second: 13537.30641
Overall Steps per Second: 2535.63847

Timestep Collection Time: 3.69409
Timestep Consumption Time: 16.02797
PPO Batch Consumption Time: 2.35474
Total Iteration Time: 19.72205

Cumulative Model Updates: 9674
Cumulative Timesteps: 81003398

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.57813
Policy Entropy: -0.06420
Value Function Loss: 2.15905

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15109
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.07088

Collected Steps per Second: 12598.27081
Overall Steps per Second: 2644.27058

Timestep Collection Time: 3.97324
Timestep Consumption Time: 14.95674
PPO Batch Consumption Time: 2.23978
Total Iteration Time: 18.92998

Cumulative Model Updates: 9680
Cumulative Timesteps: 81053454

Timesteps Collected: 50056
--------END ITERATION REPORT--------


Saving checkpoint 81053454...
Checkpoint 81053454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1092.95888
Policy Entropy: -0.06472
Value Function Loss: 2.13208

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.15456
Policy Update Magnitude: 0.05551
Value Function Update Magnitude: 0.07243

Collected Steps per Second: 12892.86012
Overall Steps per Second: 2555.07550

Timestep Collection Time: 3.87936
Timestep Consumption Time: 15.69580
PPO Batch Consumption Time: 2.30061
Total Iteration Time: 19.57516

Cumulative Model Updates: 9686
Cumulative Timesteps: 81103470

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1215.27604
Policy Entropy: -0.06907
Value Function Loss: 2.12410

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14596
Policy Update Magnitude: 0.05624
Value Function Update Magnitude: 0.07112

Collected Steps per Second: 12292.05581
Overall Steps per Second: 2566.16883

Timestep Collection Time: 4.07353
Timestep Consumption Time: 15.43883
PPO Batch Consumption Time: 2.27637
Total Iteration Time: 19.51236

Cumulative Model Updates: 9692
Cumulative Timesteps: 81153542

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.86020
Policy Entropy: -0.06912
Value Function Loss: 2.10472

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.14815
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.06993

Collected Steps per Second: 18348.61087
Overall Steps per Second: 2713.36624

Timestep Collection Time: 2.72642
Timestep Consumption Time: 15.71046
PPO Batch Consumption Time: 2.30746
Total Iteration Time: 18.43688

Cumulative Model Updates: 9698
Cumulative Timesteps: 81203568

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.87683
Policy Entropy: -0.07063
Value Function Loss: 2.15750

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.05632
Value Function Update Magnitude: 0.06744

Collected Steps per Second: 14043.93772
Overall Steps per Second: 2516.23319

Timestep Collection Time: 3.56624
Timestep Consumption Time: 16.33812
PPO Batch Consumption Time: 2.39380
Total Iteration Time: 19.90436

Cumulative Model Updates: 9704
Cumulative Timesteps: 81253652

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757.52416
Policy Entropy: -0.06806
Value Function Loss: 2.17324

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.14825
Policy Update Magnitude: 0.05449
Value Function Update Magnitude: 0.06758

Collected Steps per Second: 13337.90109
Overall Steps per Second: 2522.03558

Timestep Collection Time: 3.75216
Timestep Consumption Time: 16.09133
PPO Batch Consumption Time: 2.39655
Total Iteration Time: 19.84349

Cumulative Model Updates: 9710
Cumulative Timesteps: 81303698

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1781.48762
Policy Entropy: -0.07026
Value Function Loss: 2.08385

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.15386
Policy Update Magnitude: 0.05483
Value Function Update Magnitude: 0.06839

Collected Steps per Second: 13809.04084
Overall Steps per Second: 2496.85830

Timestep Collection Time: 3.62241
Timestep Consumption Time: 16.41157
PPO Batch Consumption Time: 2.39099
Total Iteration Time: 20.03398

Cumulative Model Updates: 9716
Cumulative Timesteps: 81353720

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.92393
Policy Entropy: -0.07038
Value Function Loss: 2.09146

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.14983
Policy Update Magnitude: 0.05520
Value Function Update Magnitude: 0.06365

Collected Steps per Second: 12552.66306
Overall Steps per Second: 2486.84493

Timestep Collection Time: 3.98784
Timestep Consumption Time: 16.14128
PPO Batch Consumption Time: 2.40655
Total Iteration Time: 20.12912

Cumulative Model Updates: 9722
Cumulative Timesteps: 81403778

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1336.37458
Policy Entropy: -0.07205
Value Function Loss: 2.06359

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.15922
Policy Update Magnitude: 0.05781
Value Function Update Magnitude: 0.06351

Collected Steps per Second: 12774.63875
Overall Steps per Second: 2477.75119

Timestep Collection Time: 3.91823
Timestep Consumption Time: 16.28315
PPO Batch Consumption Time: 2.38819
Total Iteration Time: 20.20138

Cumulative Model Updates: 9728
Cumulative Timesteps: 81453832

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1058.20497
Policy Entropy: -0.07389
Value Function Loss: 2.12696

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15375
Policy Update Magnitude: 0.06156
Value Function Update Magnitude: 0.06702

Collected Steps per Second: 12503.35374
Overall Steps per Second: 2482.93053

Timestep Collection Time: 4.00501
Timestep Consumption Time: 16.16310
PPO Batch Consumption Time: 2.37932
Total Iteration Time: 20.16810

Cumulative Model Updates: 9734
Cumulative Timesteps: 81503908

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 972.00153
Policy Entropy: -0.07542
Value Function Loss: 2.12668

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.15827
Policy Update Magnitude: 0.06123
Value Function Update Magnitude: 0.06568

Collected Steps per Second: 14906.52900
Overall Steps per Second: 2536.21563

Timestep Collection Time: 3.35839
Timestep Consumption Time: 16.38046
PPO Batch Consumption Time: 2.36411
Total Iteration Time: 19.73886

Cumulative Model Updates: 9740
Cumulative Timesteps: 81553970

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 81553970...
Checkpoint 81553970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 748.28325
Policy Entropy: -0.07542
Value Function Loss: 2.12869

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.16948
Policy Update Magnitude: 0.05615
Value Function Update Magnitude: 0.07206

Collected Steps per Second: 13173.17830
Overall Steps per Second: 2476.91217

Timestep Collection Time: 3.80349
Timestep Consumption Time: 16.42493
PPO Batch Consumption Time: 2.42622
Total Iteration Time: 20.22841

Cumulative Model Updates: 9746
Cumulative Timesteps: 81604074

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1212.19013
Policy Entropy: -0.07646
Value Function Loss: 2.11951

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.18414
Policy Update Magnitude: 0.05310
Value Function Update Magnitude: 0.06767

Collected Steps per Second: 12690.57895
Overall Steps per Second: 2502.28545

Timestep Collection Time: 3.94182
Timestep Consumption Time: 16.04950
PPO Batch Consumption Time: 2.40190
Total Iteration Time: 19.99132

Cumulative Model Updates: 9752
Cumulative Timesteps: 81654098

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 907.92447
Policy Entropy: -0.07663
Value Function Loss: 2.10459

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.19499
Policy Update Magnitude: 0.04973
Value Function Update Magnitude: 0.06543

Collected Steps per Second: 13449.56162
Overall Steps per Second: 2482.63433

Timestep Collection Time: 3.72086
Timestep Consumption Time: 16.43676
PPO Batch Consumption Time: 2.39727
Total Iteration Time: 20.15762

Cumulative Model Updates: 9758
Cumulative Timesteps: 81704142

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1915.52736
Policy Entropy: -0.07550
Value Function Loss: 2.06257

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.18611
Policy Update Magnitude: 0.04884
Value Function Update Magnitude: 0.06699

Collected Steps per Second: 15882.56858
Overall Steps per Second: 2575.65700

Timestep Collection Time: 3.14949
Timestep Consumption Time: 16.27157
PPO Batch Consumption Time: 2.39346
Total Iteration Time: 19.42106

Cumulative Model Updates: 9764
Cumulative Timesteps: 81754164

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1402.76507
Policy Entropy: -0.07642
Value Function Loss: 2.00676

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.15597
Policy Update Magnitude: 0.05628
Value Function Update Magnitude: 0.07020

Collected Steps per Second: 13314.63754
Overall Steps per Second: 1475.27428

Timestep Collection Time: 3.76037
Timestep Consumption Time: 30.17772
PPO Batch Consumption Time: 2.39787
Total Iteration Time: 33.93810

Cumulative Model Updates: 9770
Cumulative Timesteps: 81804232

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.80029
Policy Entropy: -0.07485
Value Function Loss: 2.02499

Mean KL Divergence: 0.02721
SB3 Clip Fraction: 0.30081
Policy Update Magnitude: 0.06930
Value Function Update Magnitude: 0.07088

Collected Steps per Second: 12560.14055
Overall Steps per Second: 1317.35743

Timestep Collection Time: 3.98419
Timestep Consumption Time: 34.00246
PPO Batch Consumption Time: 2.39457
Total Iteration Time: 37.98665

Cumulative Model Updates: 9776
Cumulative Timesteps: 81854274

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 889.58677
Policy Entropy: -0.07630
Value Function Loss: 2.08548

Mean KL Divergence: 0.02242
SB3 Clip Fraction: 0.27459
Policy Update Magnitude: 0.04754
Value Function Update Magnitude: 0.07131

Collected Steps per Second: 13525.77292
Overall Steps per Second: 2508.29137

Timestep Collection Time: 3.69739
Timestep Consumption Time: 16.24049
PPO Batch Consumption Time: 2.39006
Total Iteration Time: 19.93788

Cumulative Model Updates: 9782
Cumulative Timesteps: 81904284

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1157.75785
Policy Entropy: -0.07618
Value Function Loss: 2.08921

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.15544
Policy Update Magnitude: 0.05024
Value Function Update Magnitude: 0.07127

Collected Steps per Second: 12515.65655
Overall Steps per Second: 398.25169

Timestep Collection Time: 4.00075
Timestep Consumption Time: 121.72879
PPO Batch Consumption Time: 2.36871
Total Iteration Time: 125.72954

Cumulative Model Updates: 9788
Cumulative Timesteps: 81954356

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1587.53377
Policy Entropy: -0.07678
Value Function Loss: 2.04221

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.06124
Value Function Update Magnitude: 0.06994

Collected Steps per Second: 12541.19375
Overall Steps per Second: 2488.11569

Timestep Collection Time: 3.98893
Timestep Consumption Time: 16.11704
PPO Batch Consumption Time: 2.39858
Total Iteration Time: 20.10598

Cumulative Model Updates: 9794
Cumulative Timesteps: 82004382

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 691.74152
Policy Entropy: -0.07886
Value Function Loss: 1.98173

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14355
Policy Update Magnitude: 0.05923
Value Function Update Magnitude: 0.07015

Collected Steps per Second: 12658.07027
Overall Steps per Second: 1952.38052

Timestep Collection Time: 3.95305
Timestep Consumption Time: 21.67617
PPO Batch Consumption Time: 2.41512
Total Iteration Time: 25.62923

Cumulative Model Updates: 9800
Cumulative Timesteps: 82054420

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 82054420...
Checkpoint 82054420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1485.19063
Policy Entropy: -0.07895
Value Function Loss: 1.96928

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14921
Policy Update Magnitude: 0.06325
Value Function Update Magnitude: 0.06811

Collected Steps per Second: 12526.29511
Overall Steps per Second: 2466.45250

Timestep Collection Time: 3.99160
Timestep Consumption Time: 16.28043
PPO Batch Consumption Time: 2.44176
Total Iteration Time: 20.27203

Cumulative Model Updates: 9806
Cumulative Timesteps: 82104420

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 987.97550
Policy Entropy: -0.08139
Value Function Loss: 1.95744

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.19233
Policy Update Magnitude: 0.06439
Value Function Update Magnitude: 0.07337

Collected Steps per Second: 12698.04889
Overall Steps per Second: 2079.80662

Timestep Collection Time: 3.94108
Timestep Consumption Time: 20.12077
PPO Batch Consumption Time: 2.36988
Total Iteration Time: 24.06185

Cumulative Model Updates: 9812
Cumulative Timesteps: 82154464

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1546.15226
Policy Entropy: -0.08296
Value Function Loss: 1.95304

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.19923
Policy Update Magnitude: 0.06293
Value Function Update Magnitude: 0.07293

Collected Steps per Second: 12539.56120
Overall Steps per Second: 969.18426

Timestep Collection Time: 3.99009
Timestep Consumption Time: 47.63477
PPO Batch Consumption Time: 2.35807
Total Iteration Time: 51.62486

Cumulative Model Updates: 9818
Cumulative Timesteps: 82204498

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1388.02633
Policy Entropy: -0.08346
Value Function Loss: 1.97738

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.19560
Policy Update Magnitude: 0.05726
Value Function Update Magnitude: 0.07019

Collected Steps per Second: 13384.40886
Overall Steps per Second: 2533.68623

Timestep Collection Time: 3.73913
Timestep Consumption Time: 16.01312
PPO Batch Consumption Time: 2.34118
Total Iteration Time: 19.75225

Cumulative Model Updates: 9824
Cumulative Timesteps: 82254544

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.65047
Policy Entropy: -0.08476
Value Function Loss: 1.99176

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.16004
Policy Update Magnitude: 0.05616
Value Function Update Magnitude: 0.06500

Collected Steps per Second: 12445.15189
Overall Steps per Second: 1809.70854

Timestep Collection Time: 4.01859
Timestep Consumption Time: 23.61680
PPO Batch Consumption Time: 2.40352
Total Iteration Time: 27.63539

Cumulative Model Updates: 9830
Cumulative Timesteps: 82304556

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1420.82442
Policy Entropy: -0.08239
Value Function Loss: 1.98540

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14597
Policy Update Magnitude: 0.05902
Value Function Update Magnitude: 0.06707

Collected Steps per Second: 12486.05780
Overall Steps per Second: 828.37957

Timestep Collection Time: 4.00703
Timestep Consumption Time: 56.39040
PPO Batch Consumption Time: 2.34789
Total Iteration Time: 60.39743

Cumulative Model Updates: 9836
Cumulative Timesteps: 82354588

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1913.89028
Policy Entropy: -0.08207
Value Function Loss: 1.95840

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.15608
Policy Update Magnitude: 0.05714
Value Function Update Magnitude: 0.07352

Collected Steps per Second: 12868.14879
Overall Steps per Second: 2488.24438

Timestep Collection Time: 3.88852
Timestep Consumption Time: 16.22125
PPO Batch Consumption Time: 2.38483
Total Iteration Time: 20.10976

Cumulative Model Updates: 9842
Cumulative Timesteps: 82404626

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1882.52881
Policy Entropy: -0.08021
Value Function Loss: 1.99061

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13776
Policy Update Magnitude: 0.07063
Value Function Update Magnitude: 0.07550

Collected Steps per Second: 12688.40634
Overall Steps per Second: 927.02101

Timestep Collection Time: 3.94297
Timestep Consumption Time: 50.02560
PPO Batch Consumption Time: 2.32183
Total Iteration Time: 53.96857

Cumulative Model Updates: 9848
Cumulative Timesteps: 82454656

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1034.88252
Policy Entropy: -0.07874
Value Function Loss: 2.03420

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.18579
Policy Update Magnitude: 0.06314
Value Function Update Magnitude: 0.07062

Collected Steps per Second: 12497.98717
Overall Steps per Second: 2504.38487

Timestep Collection Time: 4.00320
Timestep Consumption Time: 15.97456
PPO Batch Consumption Time: 2.34711
Total Iteration Time: 19.97776

Cumulative Model Updates: 9854
Cumulative Timesteps: 82504688

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 826.27143
Policy Entropy: -0.08025
Value Function Loss: 2.08471

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.17958
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.07645

Collected Steps per Second: 12796.53674
Overall Steps per Second: 1181.19764

Timestep Collection Time: 3.90840
Timestep Consumption Time: 38.43337
PPO Batch Consumption Time: 2.38075
Total Iteration Time: 42.34177

Cumulative Model Updates: 9860
Cumulative Timesteps: 82554702

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 82554702...
Checkpoint 82554702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1102.62074
Policy Entropy: -0.08070
Value Function Loss: 2.01746

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.15650
Policy Update Magnitude: 0.05337
Value Function Update Magnitude: 0.07574

Collected Steps per Second: 13098.00341
Overall Steps per Second: 2488.48288

Timestep Collection Time: 3.81753
Timestep Consumption Time: 16.27584
PPO Batch Consumption Time: 2.40173
Total Iteration Time: 20.09337

Cumulative Model Updates: 9866
Cumulative Timesteps: 82604704

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.23385
Policy Entropy: -0.08363
Value Function Loss: 2.02623

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15408
Policy Update Magnitude: 0.06123
Value Function Update Magnitude: 0.07146

Collected Steps per Second: 12454.23911
Overall Steps per Second: 2417.51317

Timestep Collection Time: 4.01534
Timestep Consumption Time: 16.67038
PPO Batch Consumption Time: 2.44846
Total Iteration Time: 20.68572

Cumulative Model Updates: 9872
Cumulative Timesteps: 82654712

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1563.92641
Policy Entropy: -0.08578
Value Function Loss: 2.01347

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.16626
Policy Update Magnitude: 0.06026
Value Function Update Magnitude: 0.06998

Collected Steps per Second: 12727.67211
Overall Steps per Second: 2513.79779

Timestep Collection Time: 3.93253
Timestep Consumption Time: 15.97838
PPO Batch Consumption Time: 2.39157
Total Iteration Time: 19.91091

Cumulative Model Updates: 9878
Cumulative Timesteps: 82704764

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1320.10017
Policy Entropy: -0.08499
Value Function Loss: 2.08076

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.15791
Policy Update Magnitude: 0.05959
Value Function Update Magnitude: 0.06679

Collected Steps per Second: 12930.44181
Overall Steps per Second: 2521.04458

Timestep Collection Time: 3.87257
Timestep Consumption Time: 15.98983
PPO Batch Consumption Time: 2.35126
Total Iteration Time: 19.86240

Cumulative Model Updates: 9884
Cumulative Timesteps: 82754838

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.38151
Policy Entropy: -0.08623
Value Function Loss: 2.07755

Mean KL Divergence: 0.02492
SB3 Clip Fraction: 0.27863
Policy Update Magnitude: 0.06109
Value Function Update Magnitude: 0.06808

Collected Steps per Second: 12564.61841
Overall Steps per Second: 2521.33305

Timestep Collection Time: 3.98341
Timestep Consumption Time: 15.86720
PPO Batch Consumption Time: 2.36561
Total Iteration Time: 19.85061

Cumulative Model Updates: 9890
Cumulative Timesteps: 82804888

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 866.06714
Policy Entropy: -0.08502
Value Function Loss: 2.03362

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.20888
Policy Update Magnitude: 0.05043
Value Function Update Magnitude: 0.07148

Collected Steps per Second: 12632.58392
Overall Steps per Second: 1683.39939

Timestep Collection Time: 3.96324
Timestep Consumption Time: 25.77777
PPO Batch Consumption Time: 2.36873
Total Iteration Time: 29.74101

Cumulative Model Updates: 9896
Cumulative Timesteps: 82854954

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1806.28074
Policy Entropy: -0.08806
Value Function Loss: 1.98321

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.18670
Policy Update Magnitude: 0.05711
Value Function Update Magnitude: 0.06923

Collected Steps per Second: 12755.52266
Overall Steps per Second: 2561.65780

Timestep Collection Time: 3.92661
Timestep Consumption Time: 15.62557
PPO Batch Consumption Time: 2.32653
Total Iteration Time: 19.55218

Cumulative Model Updates: 9902
Cumulative Timesteps: 82905040

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1372.96515
Policy Entropy: -0.08665
Value Function Loss: 1.98518

Mean KL Divergence: 0.02524
SB3 Clip Fraction: 0.29401
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.06652

Collected Steps per Second: 12821.26707
Overall Steps per Second: 704.86643

Timestep Collection Time: 3.90024
Timestep Consumption Time: 67.04370
PPO Batch Consumption Time: 2.42730
Total Iteration Time: 70.94394

Cumulative Model Updates: 9908
Cumulative Timesteps: 82955046

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1723.68105
Policy Entropy: -0.08744
Value Function Loss: 2.02492

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.21322
Policy Update Magnitude: 0.04535
Value Function Update Magnitude: 0.07014

Collected Steps per Second: 12614.50582
Overall Steps per Second: 2541.03422

Timestep Collection Time: 3.96861
Timestep Consumption Time: 15.73282
PPO Batch Consumption Time: 2.31227
Total Iteration Time: 19.70143

Cumulative Model Updates: 9914
Cumulative Timesteps: 83005108

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1023.22619
Policy Entropy: -0.08868
Value Function Loss: 2.04340

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.16186
Policy Update Magnitude: 0.05406
Value Function Update Magnitude: 0.07603

Collected Steps per Second: 13513.27296
Overall Steps per Second: 1157.44814

Timestep Collection Time: 3.70214
Timestep Consumption Time: 39.52053
PPO Batch Consumption Time: 2.39733
Total Iteration Time: 43.22267

Cumulative Model Updates: 9920
Cumulative Timesteps: 83055136

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 83055136...
Checkpoint 83055136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.39862
Policy Entropy: -0.09160
Value Function Loss: 2.11922

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.15582
Policy Update Magnitude: 0.05663
Value Function Update Magnitude: 0.07265

Collected Steps per Second: 12595.68190
Overall Steps per Second: 2482.87007

Timestep Collection Time: 3.97041
Timestep Consumption Time: 16.17160
PPO Batch Consumption Time: 2.37719
Total Iteration Time: 20.14201

Cumulative Model Updates: 9926
Cumulative Timesteps: 83105146

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.91061
Policy Entropy: -0.09249
Value Function Loss: 2.09617

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.15527
Policy Update Magnitude: 0.05776
Value Function Update Magnitude: 0.07221

Collected Steps per Second: 12466.88116
Overall Steps per Second: 2489.78248

Timestep Collection Time: 4.01736
Timestep Consumption Time: 16.09845
PPO Batch Consumption Time: 2.40515
Total Iteration Time: 20.11581

Cumulative Model Updates: 9932
Cumulative Timesteps: 83155230

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1638.59140
Policy Entropy: -0.09451
Value Function Loss: 2.11571

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.15296
Policy Update Magnitude: 0.05763
Value Function Update Magnitude: 0.07709

Collected Steps per Second: 12810.56294
Overall Steps per Second: 2481.86136

Timestep Collection Time: 3.90412
Timestep Consumption Time: 16.24769
PPO Batch Consumption Time: 2.39181
Total Iteration Time: 20.15181

Cumulative Model Updates: 9938
Cumulative Timesteps: 83205244

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1011.22864
Policy Entropy: -0.09472
Value Function Loss: 2.07656

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.16347
Policy Update Magnitude: 0.06661
Value Function Update Magnitude: 0.08120

Collected Steps per Second: 12731.43462
Overall Steps per Second: 2493.38955

Timestep Collection Time: 3.93011
Timestep Consumption Time: 16.13735
PPO Batch Consumption Time: 2.39520
Total Iteration Time: 20.06746

Cumulative Model Updates: 9944
Cumulative Timesteps: 83255280

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1702.03503
Policy Entropy: -0.09575
Value Function Loss: 2.09818

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14008
Policy Update Magnitude: 0.06719
Value Function Update Magnitude: 0.08037

Collected Steps per Second: 13492.21506
Overall Steps per Second: 2542.43679

Timestep Collection Time: 3.70910
Timestep Consumption Time: 15.97438
PPO Batch Consumption Time: 2.34561
Total Iteration Time: 19.68348

Cumulative Model Updates: 9950
Cumulative Timesteps: 83305324

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1203.43064
Policy Entropy: -0.09640
Value Function Loss: 2.09360

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.06703
Value Function Update Magnitude: 0.08028

Collected Steps per Second: 12380.31470
Overall Steps per Second: 2536.59688

Timestep Collection Time: 4.04319
Timestep Consumption Time: 15.69033
PPO Batch Consumption Time: 2.30393
Total Iteration Time: 19.73353

Cumulative Model Updates: 9956
Cumulative Timesteps: 83355380

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.98618
Policy Entropy: -0.09720
Value Function Loss: 2.08461

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14944
Policy Update Magnitude: 0.06159
Value Function Update Magnitude: 0.08243

Collected Steps per Second: 13267.39846
Overall Steps per Second: 2177.61203

Timestep Collection Time: 3.77150
Timestep Consumption Time: 19.20688
PPO Batch Consumption Time: 2.26400
Total Iteration Time: 22.97838

Cumulative Model Updates: 9962
Cumulative Timesteps: 83405418

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1132.76839
Policy Entropy: -0.09994
Value Function Loss: 2.05628

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13693
Policy Update Magnitude: 0.05486
Value Function Update Magnitude: 0.07826

Collected Steps per Second: 12839.30398
Overall Steps per Second: 2565.53547

Timestep Collection Time: 3.89492
Timestep Consumption Time: 15.59731
PPO Batch Consumption Time: 2.29239
Total Iteration Time: 19.49223

Cumulative Model Updates: 9968
Cumulative Timesteps: 83455426

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 798.73836
Policy Entropy: -0.10136
Value Function Loss: 2.07291

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.17668
Policy Update Magnitude: 0.05240
Value Function Update Magnitude: 0.07842

Collected Steps per Second: 12558.94401
Overall Steps per Second: 2514.37547

Timestep Collection Time: 3.98330
Timestep Consumption Time: 15.91270
PPO Batch Consumption Time: 2.37479
Total Iteration Time: 19.89599

Cumulative Model Updates: 9974
Cumulative Timesteps: 83505452

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1058.34587
Policy Entropy: -0.10199
Value Function Loss: 2.09150

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.15097
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.07161

Collected Steps per Second: 12654.44127
Overall Steps per Second: 2493.10452

Timestep Collection Time: 3.95418
Timestep Consumption Time: 16.11637
PPO Batch Consumption Time: 2.35895
Total Iteration Time: 20.07056

Cumulative Model Updates: 9980
Cumulative Timesteps: 83555490

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 83555490...
Checkpoint 83555490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 796.50060
Policy Entropy: -0.10095
Value Function Loss: 2.12689

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.19953
Policy Update Magnitude: 0.05589
Value Function Update Magnitude: 0.07363

Collected Steps per Second: 12585.80584
Overall Steps per Second: 2162.21348

Timestep Collection Time: 3.97781
Timestep Consumption Time: 19.17624
PPO Batch Consumption Time: 2.35723
Total Iteration Time: 23.15405

Cumulative Model Updates: 9986
Cumulative Timesteps: 83605554

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1797.04141
Policy Entropy: -0.10222
Value Function Loss: 2.08873

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14325
Policy Update Magnitude: 0.06322
Value Function Update Magnitude: 0.07143

Collected Steps per Second: 12838.64592
Overall Steps per Second: 2490.65294

Timestep Collection Time: 3.89979
Timestep Consumption Time: 16.20257
PPO Batch Consumption Time: 2.38316
Total Iteration Time: 20.10236

Cumulative Model Updates: 9992
Cumulative Timesteps: 83655622

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1141.72856
Policy Entropy: -0.10666
Value Function Loss: 2.06205

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.07572
Value Function Update Magnitude: 0.06883

Collected Steps per Second: 12681.76998
Overall Steps per Second: 2503.66284

Timestep Collection Time: 3.94724
Timestep Consumption Time: 16.04667
PPO Batch Consumption Time: 2.36352
Total Iteration Time: 19.99391

Cumulative Model Updates: 9998
Cumulative Timesteps: 83705680

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1727.59136
Policy Entropy: -0.10797
Value Function Loss: 2.01226

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11787
Policy Update Magnitude: 0.08878
Value Function Update Magnitude: 0.07172

Collected Steps per Second: 14404.13217
Overall Steps per Second: 1401.00047

Timestep Collection Time: 3.47525
Timestep Consumption Time: 32.25493
PPO Batch Consumption Time: 2.36321
Total Iteration Time: 35.73018

Cumulative Model Updates: 10004
Cumulative Timesteps: 83755738

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1139.78897
Policy Entropy: -0.10690
Value Function Loss: 2.02116

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12222
Policy Update Magnitude: 0.07887
Value Function Update Magnitude: 0.07078

Collected Steps per Second: 12682.45036
Overall Steps per Second: 2442.96912

Timestep Collection Time: 3.94435
Timestep Consumption Time: 16.53237
PPO Batch Consumption Time: 2.43710
Total Iteration Time: 20.47672

Cumulative Model Updates: 10010
Cumulative Timesteps: 83805762

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1365.66458
Policy Entropy: -0.10668
Value Function Loss: 2.03272

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14074
Policy Update Magnitude: 0.06758
Value Function Update Magnitude: 0.07335

Collected Steps per Second: 12678.32199
Overall Steps per Second: 2547.16514

Timestep Collection Time: 3.94863
Timestep Consumption Time: 15.70538
PPO Batch Consumption Time: 2.33974
Total Iteration Time: 19.65401

Cumulative Model Updates: 10016
Cumulative Timesteps: 83855824

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1251.47308
Policy Entropy: -0.10510
Value Function Loss: 2.01576

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13797
Policy Update Magnitude: 0.06487
Value Function Update Magnitude: 0.07422

Collected Steps per Second: 12571.86010
Overall Steps per Second: 2040.11816

Timestep Collection Time: 3.98143
Timestep Consumption Time: 20.55342
PPO Batch Consumption Time: 2.41274
Total Iteration Time: 24.53485

Cumulative Model Updates: 10022
Cumulative Timesteps: 83905878

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2080.50203
Policy Entropy: -0.10422
Value Function Loss: 2.05194

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.17306
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.07276

Collected Steps per Second: 12405.29892
Overall Steps per Second: 2471.45161

Timestep Collection Time: 4.03247
Timestep Consumption Time: 16.20827
PPO Batch Consumption Time: 2.38628
Total Iteration Time: 20.24074

Cumulative Model Updates: 10028
Cumulative Timesteps: 83955902

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1508.84019
Policy Entropy: -0.10777
Value Function Loss: 2.03853

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.16087
Policy Update Magnitude: 0.05100
Value Function Update Magnitude: 0.07655

Collected Steps per Second: 13282.68242
Overall Steps per Second: 442.52119

Timestep Collection Time: 3.76626
Timestep Consumption Time: 109.28144
PPO Batch Consumption Time: 2.38015
Total Iteration Time: 113.04769

Cumulative Model Updates: 10034
Cumulative Timesteps: 84005928

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1074.76650
Policy Entropy: -0.10680
Value Function Loss: 2.05090

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.15807
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.07475

Collected Steps per Second: 12325.67578
Overall Steps per Second: 2450.37956

Timestep Collection Time: 4.05722
Timestep Consumption Time: 16.35105
PPO Batch Consumption Time: 2.41442
Total Iteration Time: 20.40827

Cumulative Model Updates: 10040
Cumulative Timesteps: 84055936

Timesteps Collected: 50008
--------END ITERATION REPORT--------


Saving checkpoint 84055936...
Checkpoint 84055936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 970.10200
Policy Entropy: -0.10909
Value Function Loss: 1.95174

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.15079
Policy Update Magnitude: 0.05667
Value Function Update Magnitude: 0.07364

Collected Steps per Second: 13349.47706
Overall Steps per Second: 2495.37358

Timestep Collection Time: 3.74636
Timestep Consumption Time: 16.29552
PPO Batch Consumption Time: 2.40193
Total Iteration Time: 20.04189

Cumulative Model Updates: 10046
Cumulative Timesteps: 84105948

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1656.47929
Policy Entropy: -0.11014
Value Function Loss: 1.92284

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.06050
Value Function Update Magnitude: 0.06880

Collected Steps per Second: 12878.10113
Overall Steps per Second: 2521.00016

Timestep Collection Time: 3.88768
Timestep Consumption Time: 15.97189
PPO Batch Consumption Time: 2.35434
Total Iteration Time: 19.85958

Cumulative Model Updates: 10052
Cumulative Timesteps: 84156014

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1340.64775
Policy Entropy: -0.11320
Value Function Loss: 2.04804

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.15529
Policy Update Magnitude: 0.06169
Value Function Update Magnitude: 0.07173

Collected Steps per Second: 12698.31167
Overall Steps per Second: 2528.81356

Timestep Collection Time: 3.93863
Timestep Consumption Time: 15.83902
PPO Batch Consumption Time: 2.36834
Total Iteration Time: 19.77765

Cumulative Model Updates: 10058
Cumulative Timesteps: 84206028

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1089.49914
Policy Entropy: -0.11422
Value Function Loss: 2.13820

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.20942
Policy Update Magnitude: 0.07444
Value Function Update Magnitude: 0.07679

Collected Steps per Second: 12766.87263
Overall Steps per Second: 2503.88031

Timestep Collection Time: 3.91639
Timestep Consumption Time: 16.05262
PPO Batch Consumption Time: 2.37158
Total Iteration Time: 19.96901

Cumulative Model Updates: 10064
Cumulative Timesteps: 84256028

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2233.71581
Policy Entropy: -0.11754
Value Function Loss: 2.11892

Mean KL Divergence: 0.01808
SB3 Clip Fraction: 0.24282
Policy Update Magnitude: 0.06107
Value Function Update Magnitude: 0.07522

Collected Steps per Second: 12580.57608
Overall Steps per Second: 2488.98695

Timestep Collection Time: 3.97533
Timestep Consumption Time: 16.11798
PPO Batch Consumption Time: 2.40312
Total Iteration Time: 20.09332

Cumulative Model Updates: 10070
Cumulative Timesteps: 84306040

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1302.99247
Policy Entropy: -0.11791
Value Function Loss: 2.02106

Mean KL Divergence: 0.02099
SB3 Clip Fraction: 0.26238
Policy Update Magnitude: 0.06162
Value Function Update Magnitude: 0.07593

Collected Steps per Second: 12485.36542
Overall Steps per Second: 2472.55054

Timestep Collection Time: 4.00853
Timestep Consumption Time: 16.23291
PPO Batch Consumption Time: 2.37574
Total Iteration Time: 20.24145

Cumulative Model Updates: 10076
Cumulative Timesteps: 84356088

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1434.70778
Policy Entropy: -0.11819
Value Function Loss: 1.99860

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.20027
Policy Update Magnitude: 0.05334
Value Function Update Magnitude: 0.07584

Collected Steps per Second: 13042.09794
Overall Steps per Second: 2555.21888

Timestep Collection Time: 3.83543
Timestep Consumption Time: 15.74098
PPO Batch Consumption Time: 2.34921
Total Iteration Time: 19.57641

Cumulative Model Updates: 10082
Cumulative Timesteps: 84406110

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.58299
Policy Entropy: -0.11727
Value Function Loss: 2.05601

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.17239
Policy Update Magnitude: 0.05775
Value Function Update Magnitude: 0.07757

Collected Steps per Second: 13196.40036
Overall Steps per Second: 2544.82863

Timestep Collection Time: 3.79119
Timestep Consumption Time: 15.86829
PPO Batch Consumption Time: 2.33379
Total Iteration Time: 19.65948

Cumulative Model Updates: 10088
Cumulative Timesteps: 84456140

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1339.17464
Policy Entropy: -0.11973
Value Function Loss: 2.00691

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15857
Policy Update Magnitude: 0.06447
Value Function Update Magnitude: 0.08240

Collected Steps per Second: 12833.57431
Overall Steps per Second: 2536.79764

Timestep Collection Time: 3.89712
Timestep Consumption Time: 15.81829
PPO Batch Consumption Time: 2.33155
Total Iteration Time: 19.71541

Cumulative Model Updates: 10094
Cumulative Timesteps: 84506154

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1087.51060
Policy Entropy: -0.12093
Value Function Loss: 1.98820

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.18455
Policy Update Magnitude: 0.06422
Value Function Update Magnitude: 0.07667

Collected Steps per Second: 13286.48862
Overall Steps per Second: 2576.45855

Timestep Collection Time: 3.77045
Timestep Consumption Time: 15.67330
PPO Batch Consumption Time: 2.29501
Total Iteration Time: 19.44374

Cumulative Model Updates: 10100
Cumulative Timesteps: 84556250

Timesteps Collected: 50096
--------END ITERATION REPORT--------


Saving checkpoint 84556250...
Checkpoint 84556250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 984.99104
Policy Entropy: -0.12049
Value Function Loss: 1.98213

Mean KL Divergence: 0.03725
SB3 Clip Fraction: 0.35667
Policy Update Magnitude: 0.06777
Value Function Update Magnitude: 0.07075

Collected Steps per Second: 12911.19709
Overall Steps per Second: 2461.60366

Timestep Collection Time: 3.87447
Timestep Consumption Time: 16.44725
PPO Batch Consumption Time: 2.39817
Total Iteration Time: 20.32171

Cumulative Model Updates: 10106
Cumulative Timesteps: 84606274

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1386.92390
Policy Entropy: -0.12178
Value Function Loss: 2.14922

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.22667
Policy Update Magnitude: 0.05018
Value Function Update Magnitude: 0.07506

Collected Steps per Second: 13747.34792
Overall Steps per Second: 2485.92205

Timestep Collection Time: 3.64288
Timestep Consumption Time: 16.50256
PPO Batch Consumption Time: 2.46514
Total Iteration Time: 20.14544

Cumulative Model Updates: 10112
Cumulative Timesteps: 84656354

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 994.84242
Policy Entropy: -0.12105
Value Function Loss: 2.13953

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.17763
Policy Update Magnitude: 0.05465
Value Function Update Magnitude: 0.07844

Collected Steps per Second: 13383.71926
Overall Steps per Second: 726.90688

Timestep Collection Time: 3.74081
Timestep Consumption Time: 65.13458
PPO Batch Consumption Time: 2.37879
Total Iteration Time: 68.87540

Cumulative Model Updates: 10118
Cumulative Timesteps: 84706420

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1301.75067
Policy Entropy: -0.12136
Value Function Loss: 2.11535

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.23066
Policy Update Magnitude: 0.06216
Value Function Update Magnitude: 0.07740

Collected Steps per Second: 13510.68490
Overall Steps per Second: 2600.02416

Timestep Collection Time: 3.70196
Timestep Consumption Time: 15.53479
PPO Batch Consumption Time: 2.32385
Total Iteration Time: 19.23674

Cumulative Model Updates: 10124
Cumulative Timesteps: 84756436

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1114.64501
Policy Entropy: -0.12428
Value Function Loss: 2.04777

Mean KL Divergence: 0.02366
SB3 Clip Fraction: 0.25512
Policy Update Magnitude: 0.04738
Value Function Update Magnitude: 0.07274

Collected Steps per Second: 13393.80088
Overall Steps per Second: 2525.25217

Timestep Collection Time: 3.73680
Timestep Consumption Time: 16.08300
PPO Batch Consumption Time: 2.36757
Total Iteration Time: 19.81980

Cumulative Model Updates: 10130
Cumulative Timesteps: 84806486

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1100.94703
Policy Entropy: -0.12581
Value Function Loss: 2.02972

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.18584
Policy Update Magnitude: 0.04828
Value Function Update Magnitude: 0.07617

Collected Steps per Second: 13736.26642
Overall Steps per Second: 2253.59416

Timestep Collection Time: 3.64422
Timestep Consumption Time: 18.56830
PPO Batch Consumption Time: 2.45538
Total Iteration Time: 22.21252

Cumulative Model Updates: 10136
Cumulative Timesteps: 84856544

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 912.98628
Policy Entropy: -0.12883
Value Function Loss: 2.01260

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.06153
Value Function Update Magnitude: 0.07528

Collected Steps per Second: 13440.52199
Overall Steps per Second: 2563.93927

Timestep Collection Time: 3.72738
Timestep Consumption Time: 15.81208
PPO Batch Consumption Time: 2.36821
Total Iteration Time: 19.53946

Cumulative Model Updates: 10142
Cumulative Timesteps: 84906642

Timesteps Collected: 50098
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1211.50202
Policy Entropy: -0.12915
Value Function Loss: 1.95006

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.15164
Policy Update Magnitude: 0.06144
Value Function Update Magnitude: 0.07521

Collected Steps per Second: 13220.56389
Overall Steps per Second: 2469.27802

Timestep Collection Time: 3.78925
Timestep Consumption Time: 16.49846
PPO Batch Consumption Time: 2.43164
Total Iteration Time: 20.28771

Cumulative Model Updates: 10148
Cumulative Timesteps: 84956738

Timesteps Collected: 50096
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1218.88073
Policy Entropy: -0.12669
Value Function Loss: 1.92530

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.15666
Policy Update Magnitude: 0.05582
Value Function Update Magnitude: 0.07486

Collected Steps per Second: 13012.41451
Overall Steps per Second: 2564.39913

Timestep Collection Time: 3.84510
Timestep Consumption Time: 15.66591
PPO Batch Consumption Time: 2.34323
Total Iteration Time: 19.51100

Cumulative Model Updates: 10154
Cumulative Timesteps: 85006772

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1398.14657
Policy Entropy: -0.12948
Value Function Loss: 1.88769

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.16804
Policy Update Magnitude: 0.05578
Value Function Update Magnitude: 0.07416

Collected Steps per Second: 12814.31546
Overall Steps per Second: 2493.22653

Timestep Collection Time: 3.90298
Timestep Consumption Time: 16.15697
PPO Batch Consumption Time: 2.37237
Total Iteration Time: 20.05995

Cumulative Model Updates: 10160
Cumulative Timesteps: 85056786

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 85056786...
Checkpoint 85056786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 816.14309
Policy Entropy: -0.12985
Value Function Loss: 1.94938

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.15836
Policy Update Magnitude: 0.05535
Value Function Update Magnitude: 0.07320

Collected Steps per Second: 13528.37931
Overall Steps per Second: 2086.19409

Timestep Collection Time: 3.70007
Timestep Consumption Time: 20.29386
PPO Batch Consumption Time: 2.40511
Total Iteration Time: 23.99393

Cumulative Model Updates: 10166
Cumulative Timesteps: 85106842

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1064.79075
Policy Entropy: -0.13184
Value Function Loss: 1.98629

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.16028
Policy Update Magnitude: 0.05242
Value Function Update Magnitude: 0.07754

Collected Steps per Second: 14377.87258
Overall Steps per Second: 2540.04588

Timestep Collection Time: 3.48369
Timestep Consumption Time: 16.23564
PPO Batch Consumption Time: 2.39465
Total Iteration Time: 19.71933

Cumulative Model Updates: 10172
Cumulative Timesteps: 85156930

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.86515
Policy Entropy: -0.13296
Value Function Loss: 2.04945

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.15848
Policy Update Magnitude: 0.05534
Value Function Update Magnitude: 0.08129

Collected Steps per Second: 13829.35878
Overall Steps per Second: 2532.44101

Timestep Collection Time: 3.61608
Timestep Consumption Time: 16.13088
PPO Batch Consumption Time: 2.35822
Total Iteration Time: 19.74696

Cumulative Model Updates: 10178
Cumulative Timesteps: 85206938

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717.67528
Policy Entropy: -0.13499
Value Function Loss: 2.01539

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.15391
Policy Update Magnitude: 0.05464
Value Function Update Magnitude: 0.07606

Collected Steps per Second: 13670.69022
Overall Steps per Second: 1506.91565

Timestep Collection Time: 3.66024
Timestep Consumption Time: 29.54534
PPO Batch Consumption Time: 2.38219
Total Iteration Time: 33.20557

Cumulative Model Updates: 10184
Cumulative Timesteps: 85256976

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.14506
Policy Entropy: -0.13699
Value Function Loss: 2.04147

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.15293
Policy Update Magnitude: 0.05458
Value Function Update Magnitude: 0.07078

Collected Steps per Second: 13808.80220
Overall Steps per Second: 2556.78600

Timestep Collection Time: 3.62421
Timestep Consumption Time: 15.94958
PPO Batch Consumption Time: 2.35166
Total Iteration Time: 19.57379

Cumulative Model Updates: 10190
Cumulative Timesteps: 85307022

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1010.55844
Policy Entropy: -0.13804
Value Function Loss: 1.99370

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15287
Policy Update Magnitude: 0.05274
Value Function Update Magnitude: 0.07132

Collected Steps per Second: 13265.25472
Overall Steps per Second: 1557.44021

Timestep Collection Time: 3.77633
Timestep Consumption Time: 28.38798
PPO Batch Consumption Time: 2.34149
Total Iteration Time: 32.16432

Cumulative Model Updates: 10196
Cumulative Timesteps: 85357116

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1646.86057
Policy Entropy: -0.13674
Value Function Loss: 2.01938

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.14932
Policy Update Magnitude: 0.05940
Value Function Update Magnitude: 0.07080

Collected Steps per Second: 14421.94037
Overall Steps per Second: 2508.23524

Timestep Collection Time: 3.46860
Timestep Consumption Time: 16.47530
PPO Batch Consumption Time: 2.43464
Total Iteration Time: 19.94390

Cumulative Model Updates: 10202
Cumulative Timesteps: 85407140

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1542.79190
Policy Entropy: -0.14046
Value Function Loss: 2.00539

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11860
Policy Update Magnitude: 0.08579
Value Function Update Magnitude: 0.07247

Collected Steps per Second: 14017.84881
Overall Steps per Second: 2518.36248

Timestep Collection Time: 3.56902
Timestep Consumption Time: 16.29706
PPO Batch Consumption Time: 2.41204
Total Iteration Time: 19.86608

Cumulative Model Updates: 10208
Cumulative Timesteps: 85457170

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1425.37100
Policy Entropy: -0.14305
Value Function Loss: 2.04362

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.19330
Policy Update Magnitude: 0.08637
Value Function Update Magnitude: 0.07241

Collected Steps per Second: 13364.64448
Overall Steps per Second: 2526.53238

Timestep Collection Time: 3.74540
Timestep Consumption Time: 16.06673
PPO Batch Consumption Time: 2.40418
Total Iteration Time: 19.81213

Cumulative Model Updates: 10214
Cumulative Timesteps: 85507226

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 919.56926
Policy Entropy: -0.14536
Value Function Loss: 1.96380

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.15421
Policy Update Magnitude: 0.06585
Value Function Update Magnitude: 0.07738

Collected Steps per Second: 12975.18166
Overall Steps per Second: 617.65232

Timestep Collection Time: 3.85567
Timestep Consumption Time: 77.14136
PPO Batch Consumption Time: 5.74817
Total Iteration Time: 80.99702

Cumulative Model Updates: 10220
Cumulative Timesteps: 85557254

Timesteps Collected: 50028
--------END ITERATION REPORT--------


Saving checkpoint 85557254...
Checkpoint 85557254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735.31420
Policy Entropy: -0.14848
Value Function Loss: 1.91501

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12120
Policy Update Magnitude: 0.07652
Value Function Update Magnitude: 0.07370

Collected Steps per Second: 13998.74326
Overall Steps per Second: 2530.92145

Timestep Collection Time: 3.57775
Timestep Consumption Time: 16.21109
PPO Batch Consumption Time: 2.39168
Total Iteration Time: 19.78884

Cumulative Model Updates: 10226
Cumulative Timesteps: 85607338

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1005.80036
Policy Entropy: -0.15248
Value Function Loss: 1.89245

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14614
Policy Update Magnitude: 0.07971
Value Function Update Magnitude: 0.07042

Collected Steps per Second: 13671.54824
Overall Steps per Second: 2478.25774

Timestep Collection Time: 3.66381
Timestep Consumption Time: 16.54797
PPO Batch Consumption Time: 2.43819
Total Iteration Time: 20.21178

Cumulative Model Updates: 10232
Cumulative Timesteps: 85657428

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1745.42782
Policy Entropy: -0.15710
Value Function Loss: 1.90703

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.16614
Policy Update Magnitude: 0.07103
Value Function Update Magnitude: 0.07054

Collected Steps per Second: 12793.20370
Overall Steps per Second: 930.72166

Timestep Collection Time: 3.91333
Timestep Consumption Time: 49.87719
PPO Batch Consumption Time: 2.39180
Total Iteration Time: 53.79052

Cumulative Model Updates: 10238
Cumulative Timesteps: 85707492

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1267.11981
Policy Entropy: -0.16001
Value Function Loss: 1.95070

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.18337
Policy Update Magnitude: 0.06949
Value Function Update Magnitude: 0.07209

Collected Steps per Second: 13225.13171
Overall Steps per Second: 2541.38599

Timestep Collection Time: 3.78779
Timestep Consumption Time: 15.92350
PPO Batch Consumption Time: 2.37441
Total Iteration Time: 19.71129

Cumulative Model Updates: 10244
Cumulative Timesteps: 85757586

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2051.76629
Policy Entropy: -0.16701
Value Function Loss: 1.90956

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.17243
Policy Update Magnitude: 0.06396
Value Function Update Magnitude: 0.07575

Collected Steps per Second: 13815.94825
Overall Steps per Second: 2247.78304

Timestep Collection Time: 3.62031
Timestep Consumption Time: 18.63184
PPO Batch Consumption Time: 2.37367
Total Iteration Time: 22.25215

Cumulative Model Updates: 10250
Cumulative Timesteps: 85807604

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1280.26981
Policy Entropy: -0.17014
Value Function Loss: 1.97400

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.18380
Policy Update Magnitude: 0.05888
Value Function Update Magnitude: 0.07542

Collected Steps per Second: 13596.12534
Overall Steps per Second: 2555.46667

Timestep Collection Time: 3.68517
Timestep Consumption Time: 15.92143
PPO Batch Consumption Time: 2.34794
Total Iteration Time: 19.60660

Cumulative Model Updates: 10256
Cumulative Timesteps: 85857708

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1418.48299
Policy Entropy: -0.17603
Value Function Loss: 1.96634

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.18172
Policy Update Magnitude: 0.05789
Value Function Update Magnitude: 0.07572

Collected Steps per Second: 14380.89900
Overall Steps per Second: 853.17716

Timestep Collection Time: 3.47975
Timestep Consumption Time: 55.17395
PPO Batch Consumption Time: 2.37651
Total Iteration Time: 58.65370

Cumulative Model Updates: 10262
Cumulative Timesteps: 85907750

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1165.67275
Policy Entropy: -0.17999
Value Function Loss: 1.96919

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.18146
Policy Update Magnitude: 0.06201
Value Function Update Magnitude: 0.07184

Collected Steps per Second: 13345.20606
Overall Steps per Second: 2501.29066

Timestep Collection Time: 3.75251
Timestep Consumption Time: 16.26836
PPO Batch Consumption Time: 2.39428
Total Iteration Time: 20.02086

Cumulative Model Updates: 10268
Cumulative Timesteps: 85957828

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 630.95432
Policy Entropy: -0.18587
Value Function Loss: 1.96533

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13600
Policy Update Magnitude: 0.07439
Value Function Update Magnitude: 0.07294

Collected Steps per Second: 14611.50650
Overall Steps per Second: 2501.61244

Timestep Collection Time: 3.42771
Timestep Consumption Time: 16.59298
PPO Batch Consumption Time: 2.48879
Total Iteration Time: 20.02069

Cumulative Model Updates: 10274
Cumulative Timesteps: 86007912

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1884.10918
Policy Entropy: -0.19126
Value Function Loss: 1.93474

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13982
Policy Update Magnitude: 0.08915
Value Function Update Magnitude: 0.06899

Collected Steps per Second: 12964.98907
Overall Steps per Second: 2460.32836

Timestep Collection Time: 3.85654
Timestep Consumption Time: 16.46595
PPO Batch Consumption Time: 2.41555
Total Iteration Time: 20.32249

Cumulative Model Updates: 10280
Cumulative Timesteps: 86057912

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 86057912...
Checkpoint 86057912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1708.77168
Policy Entropy: -0.19602
Value Function Loss: 2.06437

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.20146
Policy Update Magnitude: 0.08418
Value Function Update Magnitude: 0.06565

Collected Steps per Second: 12670.13437
Overall Steps per Second: 1642.16334

Timestep Collection Time: 3.95229
Timestep Consumption Time: 26.54164
PPO Batch Consumption Time: 2.33425
Total Iteration Time: 30.49392

Cumulative Model Updates: 10286
Cumulative Timesteps: 86107988

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1717.57905
Policy Entropy: -0.20253
Value Function Loss: 1.98689

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.21998
Policy Update Magnitude: 0.06383
Value Function Update Magnitude: 0.07714

Collected Steps per Second: 13311.64696
Overall Steps per Second: 1905.57552

Timestep Collection Time: 3.75641
Timestep Consumption Time: 22.48448
PPO Batch Consumption Time: 2.35800
Total Iteration Time: 26.24089

Cumulative Model Updates: 10292
Cumulative Timesteps: 86157992

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1707.97494
Policy Entropy: -0.21047
Value Function Loss: 2.00576

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.20278
Policy Update Magnitude: 0.05451
Value Function Update Magnitude: 0.07762

Collected Steps per Second: 12497.47993
Overall Steps per Second: 2485.72721

Timestep Collection Time: 4.00401
Timestep Consumption Time: 16.12692
PPO Batch Consumption Time: 2.38061
Total Iteration Time: 20.13093

Cumulative Model Updates: 10298
Cumulative Timesteps: 86208032

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.46404
Policy Entropy: -0.21650
Value Function Loss: 1.92839

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.18056
Policy Update Magnitude: 0.05522
Value Function Update Magnitude: 0.07031

Collected Steps per Second: 13260.26288
Overall Steps per Second: 2486.54064

Timestep Collection Time: 3.77082
Timestep Consumption Time: 16.33825
PPO Batch Consumption Time: 2.40602
Total Iteration Time: 20.10906

Cumulative Model Updates: 10304
Cumulative Timesteps: 86258034

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1834.19145
Policy Entropy: -0.22273
Value Function Loss: 1.96441

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.17052
Policy Update Magnitude: 0.07437
Value Function Update Magnitude: 0.06680

Collected Steps per Second: 12630.11659
Overall Steps per Second: 1321.02082

Timestep Collection Time: 3.95958
Timestep Consumption Time: 33.89750
PPO Batch Consumption Time: 2.38597
Total Iteration Time: 37.85709

Cumulative Model Updates: 10310
Cumulative Timesteps: 86308044

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2474.09463
Policy Entropy: -0.22517
Value Function Loss: 1.98137

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.19501
Policy Update Magnitude: 0.07443
Value Function Update Magnitude: 0.07318

Collected Steps per Second: 12639.24694
Overall Steps per Second: 1774.77903

Timestep Collection Time: 3.96100
Timestep Consumption Time: 24.24759
PPO Batch Consumption Time: 2.42580
Total Iteration Time: 28.20858

Cumulative Model Updates: 10316
Cumulative Timesteps: 86358108

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1974.05486
Policy Entropy: -0.23360
Value Function Loss: 1.97185

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.21246
Policy Update Magnitude: 0.06429
Value Function Update Magnitude: 0.07597

Collected Steps per Second: 12556.18153
Overall Steps per Second: 2442.32356

Timestep Collection Time: 3.98800
Timestep Consumption Time: 16.51461
PPO Batch Consumption Time: 2.44030
Total Iteration Time: 20.50261

Cumulative Model Updates: 10322
Cumulative Timesteps: 86408182

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2667.55530
Policy Entropy: -0.24085
Value Function Loss: 1.97756

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.21711
Policy Update Magnitude: 0.07733
Value Function Update Magnitude: 0.07114

Collected Steps per Second: 12581.15894
Overall Steps per Second: 2511.05875

Timestep Collection Time: 3.97674
Timestep Consumption Time: 15.94792
PPO Batch Consumption Time: 2.38211
Total Iteration Time: 19.92466

Cumulative Model Updates: 10328
Cumulative Timesteps: 86458214

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.94132
Policy Entropy: -0.24787
Value Function Loss: 1.92935

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.18264
Policy Update Magnitude: 0.07338
Value Function Update Magnitude: 0.07656

Collected Steps per Second: 12859.98427
Overall Steps per Second: 2454.77933

Timestep Collection Time: 3.89114
Timestep Consumption Time: 16.49358
PPO Batch Consumption Time: 2.43162
Total Iteration Time: 20.38472

Cumulative Model Updates: 10334
Cumulative Timesteps: 86508254

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2387.40940
Policy Entropy: -0.25290
Value Function Loss: 1.97298

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.17866
Policy Update Magnitude: 0.06889
Value Function Update Magnitude: 0.07850

Collected Steps per Second: 12311.52026
Overall Steps per Second: 2537.99198

Timestep Collection Time: 4.06773
Timestep Consumption Time: 15.66440
PPO Batch Consumption Time: 2.33324
Total Iteration Time: 19.73213

Cumulative Model Updates: 10340
Cumulative Timesteps: 86558334

Timesteps Collected: 50080
--------END ITERATION REPORT--------


Saving checkpoint 86558334...
Checkpoint 86558334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1774.20397
Policy Entropy: -0.25809
Value Function Loss: 1.96420

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.18672
Policy Update Magnitude: 0.05908
Value Function Update Magnitude: 0.08416

Collected Steps per Second: 12829.62007
Overall Steps per Second: 2486.08676

Timestep Collection Time: 3.90051
Timestep Consumption Time: 16.22832
PPO Batch Consumption Time: 2.38601
Total Iteration Time: 20.12882

Cumulative Model Updates: 10346
Cumulative Timesteps: 86608376

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1180.87329
Policy Entropy: -0.26061
Value Function Loss: 2.02915

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.18550
Policy Update Magnitude: 0.05643
Value Function Update Magnitude: 0.07758

Collected Steps per Second: 12545.64403
Overall Steps per Second: 612.36442

Timestep Collection Time: 3.98864
Timestep Consumption Time: 77.72741
PPO Batch Consumption Time: 2.34636
Total Iteration Time: 81.71605

Cumulative Model Updates: 10352
Cumulative Timesteps: 86658416

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 976.49103
Policy Entropy: -0.26614
Value Function Loss: 2.05248

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.18170
Policy Update Magnitude: 0.05987
Value Function Update Magnitude: 0.07227

Collected Steps per Second: 13673.89103
Overall Steps per Second: 2493.83738

Timestep Collection Time: 3.66348
Timestep Consumption Time: 16.42364
PPO Batch Consumption Time: 2.41939
Total Iteration Time: 20.08712

Cumulative Model Updates: 10358
Cumulative Timesteps: 86708510

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1767.03742
Policy Entropy: -0.26941
Value Function Loss: 2.06063

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.18468
Policy Update Magnitude: 0.06052
Value Function Update Magnitude: 0.07600

Collected Steps per Second: 13818.63985
Overall Steps per Second: 2563.36091

Timestep Collection Time: 3.61975
Timestep Consumption Time: 15.89370
PPO Batch Consumption Time: 2.33634
Total Iteration Time: 19.51344

Cumulative Model Updates: 10364
Cumulative Timesteps: 86758530

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1612.34794
Policy Entropy: -0.27422
Value Function Loss: 2.00935

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.16921
Policy Update Magnitude: 0.06769
Value Function Update Magnitude: 0.08127

Collected Steps per Second: 14276.74573
Overall Steps per Second: 1463.72912

Timestep Collection Time: 3.50556
Timestep Consumption Time: 30.68656
PPO Batch Consumption Time: 2.35897
Total Iteration Time: 34.19212

Cumulative Model Updates: 10370
Cumulative Timesteps: 86808578

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.46444
Policy Entropy: -0.27784
Value Function Loss: 2.01664

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12508
Policy Update Magnitude: 0.07744
Value Function Update Magnitude: 0.07762

Collected Steps per Second: 14156.31106
Overall Steps per Second: 2521.70070

Timestep Collection Time: 3.53623
Timestep Consumption Time: 16.31545
PPO Batch Consumption Time: 2.39899
Total Iteration Time: 19.85168

Cumulative Model Updates: 10376
Cumulative Timesteps: 86858638

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 955.99714
Policy Entropy: -0.28070
Value Function Loss: 2.05155

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.16456
Policy Update Magnitude: 0.08235
Value Function Update Magnitude: 0.07586

Collected Steps per Second: 13358.32628
Overall Steps per Second: 2532.66318

Timestep Collection Time: 3.74358
Timestep Consumption Time: 16.00164
PPO Batch Consumption Time: 2.39268
Total Iteration Time: 19.74522

Cumulative Model Updates: 10382
Cumulative Timesteps: 86908646

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1632.00197
Policy Entropy: -0.28736
Value Function Loss: 2.02265

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.20478
Policy Update Magnitude: 0.08190
Value Function Update Magnitude: 0.07428

Collected Steps per Second: 13078.56986
Overall Steps per Second: 2517.60618

Timestep Collection Time: 3.82427
Timestep Consumption Time: 16.04222
PPO Batch Consumption Time: 2.35801
Total Iteration Time: 19.86649

Cumulative Model Updates: 10388
Cumulative Timesteps: 86958662

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1089.78488
Policy Entropy: -0.28403
Value Function Loss: 2.00645

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.18496
Policy Update Magnitude: 0.06221
Value Function Update Magnitude: 0.07424

Collected Steps per Second: 14216.51621
Overall Steps per Second: 2558.58491

Timestep Collection Time: 3.51718
Timestep Consumption Time: 16.02566
PPO Batch Consumption Time: 2.39119
Total Iteration Time: 19.54283

Cumulative Model Updates: 10394
Cumulative Timesteps: 87008664

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1861.16380
Policy Entropy: -0.28950
Value Function Loss: 2.03788

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.18295
Policy Update Magnitude: 0.06346
Value Function Update Magnitude: 0.07630

Collected Steps per Second: 15114.42089
Overall Steps per Second: 2567.75552

Timestep Collection Time: 3.30942
Timestep Consumption Time: 16.17063
PPO Batch Consumption Time: 2.36967
Total Iteration Time: 19.48005

Cumulative Model Updates: 10400
Cumulative Timesteps: 87058684

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 87058684...
Checkpoint 87058684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1888.20661
Policy Entropy: -0.29115
Value Function Loss: 2.09078

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.16017
Policy Update Magnitude: 0.08504
Value Function Update Magnitude: 0.08130

Collected Steps per Second: 12791.96201
Overall Steps per Second: 2528.22834

Timestep Collection Time: 3.91480
Timestep Consumption Time: 15.89274
PPO Batch Consumption Time: 2.35354
Total Iteration Time: 19.80755

Cumulative Model Updates: 10406
Cumulative Timesteps: 87108762

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1229.25752
Policy Entropy: -0.29442
Value Function Loss: 2.01890

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14687
Policy Update Magnitude: 0.07964
Value Function Update Magnitude: 0.08226

Collected Steps per Second: 13448.80135
Overall Steps per Second: 2516.18523

Timestep Collection Time: 3.72033
Timestep Consumption Time: 16.16453
PPO Batch Consumption Time: 2.38078
Total Iteration Time: 19.88486

Cumulative Model Updates: 10412
Cumulative Timesteps: 87158796

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1661.77538
Policy Entropy: -0.29910
Value Function Loss: 2.02173

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.20117
Policy Update Magnitude: 0.07056
Value Function Update Magnitude: 0.07448

Collected Steps per Second: 13396.71501
Overall Steps per Second: 2549.65681

Timestep Collection Time: 3.73584
Timestep Consumption Time: 15.89347
PPO Batch Consumption Time: 2.35747
Total Iteration Time: 19.62931

Cumulative Model Updates: 10418
Cumulative Timesteps: 87208844

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1083.84377
Policy Entropy: -0.30258
Value Function Loss: 2.02976

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.18960
Policy Update Magnitude: 0.06008
Value Function Update Magnitude: 0.07369

Collected Steps per Second: 14446.75322
Overall Steps per Second: 2552.22763

Timestep Collection Time: 3.46445
Timestep Consumption Time: 16.14587
PPO Batch Consumption Time: 2.37929
Total Iteration Time: 19.61032

Cumulative Model Updates: 10424
Cumulative Timesteps: 87258894

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.26193
Policy Entropy: -0.30638
Value Function Loss: 2.04587

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15882
Policy Update Magnitude: 0.06130
Value Function Update Magnitude: 0.07372

Collected Steps per Second: 12922.49549
Overall Steps per Second: 2489.81416

Timestep Collection Time: 3.87464
Timestep Consumption Time: 16.23530
PPO Batch Consumption Time: 2.35279
Total Iteration Time: 20.10993

Cumulative Model Updates: 10430
Cumulative Timesteps: 87308964

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 905.32282
Policy Entropy: -0.30741
Value Function Loss: 2.02890

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15316
Policy Update Magnitude: 0.06526
Value Function Update Magnitude: 0.07675

Collected Steps per Second: 12922.74848
Overall Steps per Second: 2500.21485

Timestep Collection Time: 3.87425
Timestep Consumption Time: 16.15043
PPO Batch Consumption Time: 2.41932
Total Iteration Time: 20.02468

Cumulative Model Updates: 10436
Cumulative Timesteps: 87359030

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1689.39698
Policy Entropy: -0.31410
Value Function Loss: 2.01356

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.15219
Policy Update Magnitude: 0.07016
Value Function Update Magnitude: 0.07948

Collected Steps per Second: 12475.62437
Overall Steps per Second: 2440.47898

Timestep Collection Time: 4.01022
Timestep Consumption Time: 16.48985
PPO Batch Consumption Time: 2.42736
Total Iteration Time: 20.50007

Cumulative Model Updates: 10442
Cumulative Timesteps: 87409060

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2038.85977
Policy Entropy: -0.31313
Value Function Loss: 1.98397

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.07657
Value Function Update Magnitude: 0.08644

Collected Steps per Second: 14261.46857
Overall Steps per Second: 2562.94986

Timestep Collection Time: 3.50679
Timestep Consumption Time: 16.00666
PPO Batch Consumption Time: 2.38163
Total Iteration Time: 19.51345

Cumulative Model Updates: 10448
Cumulative Timesteps: 87459072

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2041.57144
Policy Entropy: -0.31881
Value Function Loss: 1.97103

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.16970
Policy Update Magnitude: 0.08479
Value Function Update Magnitude: 0.08805

Collected Steps per Second: 12747.87532
Overall Steps per Second: 2514.29464

Timestep Collection Time: 3.92301
Timestep Consumption Time: 15.96726
PPO Batch Consumption Time: 2.35850
Total Iteration Time: 19.89027

Cumulative Model Updates: 10454
Cumulative Timesteps: 87509082

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1518.64165
Policy Entropy: -0.32178
Value Function Loss: 1.94656

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.15465
Policy Update Magnitude: 0.07793
Value Function Update Magnitude: 0.07660

Collected Steps per Second: 12545.59654
Overall Steps per Second: 2537.32262

Timestep Collection Time: 3.99104
Timestep Consumption Time: 15.74236
PPO Batch Consumption Time: 2.33305
Total Iteration Time: 19.73340

Cumulative Model Updates: 10460
Cumulative Timesteps: 87559152

Timesteps Collected: 50070
--------END ITERATION REPORT--------


Saving checkpoint 87559152...
Checkpoint 87559152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1033.48156
Policy Entropy: -0.32884
Value Function Loss: 2.00226

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.17245
Policy Update Magnitude: 0.07783
Value Function Update Magnitude: 0.07427

Collected Steps per Second: 13066.48694
Overall Steps per Second: 2518.01440

Timestep Collection Time: 3.83378
Timestep Consumption Time: 16.06047
PPO Batch Consumption Time: 2.36503
Total Iteration Time: 19.89425

Cumulative Model Updates: 10466
Cumulative Timesteps: 87609246

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1542.60615
Policy Entropy: -0.33116
Value Function Loss: 1.96544

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14792
Policy Update Magnitude: 0.07098
Value Function Update Magnitude: 0.08054

Collected Steps per Second: 15739.15966
Overall Steps per Second: 2602.51272

Timestep Collection Time: 3.17920
Timestep Consumption Time: 16.04760
PPO Batch Consumption Time: 2.35964
Total Iteration Time: 19.22680

Cumulative Model Updates: 10472
Cumulative Timesteps: 87659284

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1285.00036
Policy Entropy: -0.33596
Value Function Loss: 1.93778

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.19394
Policy Update Magnitude: 0.08556
Value Function Update Magnitude: 0.08118

Collected Steps per Second: 15828.70499
Overall Steps per Second: 2640.30005

Timestep Collection Time: 3.16109
Timestep Consumption Time: 15.78978
PPO Batch Consumption Time: 2.34036
Total Iteration Time: 18.95088

Cumulative Model Updates: 10478
Cumulative Timesteps: 87709320

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1285.52613
Policy Entropy: -0.33571
Value Function Loss: 1.93358

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.16872
Policy Update Magnitude: 0.07378
Value Function Update Magnitude: 0.07787

Collected Steps per Second: 14938.62541
Overall Steps per Second: 2504.06295

Timestep Collection Time: 3.35078
Timestep Consumption Time: 16.63914
PPO Batch Consumption Time: 2.45355
Total Iteration Time: 19.98991

Cumulative Model Updates: 10484
Cumulative Timesteps: 87759376

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1100.04866
Policy Entropy: -0.33891
Value Function Loss: 1.94555

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.16553
Policy Update Magnitude: 0.06296
Value Function Update Magnitude: 0.07094

Collected Steps per Second: 13842.54764
Overall Steps per Second: 2517.58179

Timestep Collection Time: 3.61350
Timestep Consumption Time: 16.25478
PPO Batch Consumption Time: 2.41666
Total Iteration Time: 19.86827

Cumulative Model Updates: 10490
Cumulative Timesteps: 87809396

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1357.96516
Policy Entropy: -0.34150
Value Function Loss: 1.92896

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.16511
Policy Update Magnitude: 0.06097
Value Function Update Magnitude: 0.07222

Collected Steps per Second: 12954.92387
Overall Steps per Second: 2493.24497

Timestep Collection Time: 3.86031
Timestep Consumption Time: 16.19789
PPO Batch Consumption Time: 2.39764
Total Iteration Time: 20.05820

Cumulative Model Updates: 10496
Cumulative Timesteps: 87859406

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1511.62907
Policy Entropy: -0.34355
Value Function Loss: 1.94490

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.06161
Value Function Update Magnitude: 0.07017

Collected Steps per Second: 12654.69321
Overall Steps per Second: 2521.72379

Timestep Collection Time: 3.95774
Timestep Consumption Time: 15.90328
PPO Batch Consumption Time: 2.34526
Total Iteration Time: 19.86102

Cumulative Model Updates: 10502
Cumulative Timesteps: 87909490

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1880.60572
Policy Entropy: -0.34959
Value Function Loss: 1.91908

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.17945
Policy Update Magnitude: 0.07140
Value Function Update Magnitude: 0.06871

Collected Steps per Second: 13213.01135
Overall Steps per Second: 2514.16654

Timestep Collection Time: 3.78627
Timestep Consumption Time: 16.11218
PPO Batch Consumption Time: 2.38210
Total Iteration Time: 19.89844

Cumulative Model Updates: 10508
Cumulative Timesteps: 87959518

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1472.64243
Policy Entropy: -0.35353
Value Function Loss: 1.94525

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.15894
Policy Update Magnitude: 0.06871
Value Function Update Magnitude: 0.06832

Collected Steps per Second: 12493.01016
Overall Steps per Second: 2545.74530

Timestep Collection Time: 4.00656
Timestep Consumption Time: 15.65527
PPO Batch Consumption Time: 2.32286
Total Iteration Time: 19.66183

Cumulative Model Updates: 10514
Cumulative Timesteps: 88009572

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1641.50267
Policy Entropy: -0.35750
Value Function Loss: 1.82817

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.16293
Policy Update Magnitude: 0.06437
Value Function Update Magnitude: 0.07164

Collected Steps per Second: 13457.77228
Overall Steps per Second: 2565.40492

Timestep Collection Time: 3.71845
Timestep Consumption Time: 15.78803
PPO Batch Consumption Time: 2.34214
Total Iteration Time: 19.50647

Cumulative Model Updates: 10520
Cumulative Timesteps: 88059614

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 88059614...
Checkpoint 88059614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1666.46028
Policy Entropy: -0.36067
Value Function Loss: 1.82756

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.16476
Policy Update Magnitude: 0.06430
Value Function Update Magnitude: 0.07033

Collected Steps per Second: 15695.60043
Overall Steps per Second: 2554.02469

Timestep Collection Time: 3.18701
Timestep Consumption Time: 16.39855
PPO Batch Consumption Time: 2.40344
Total Iteration Time: 19.58556

Cumulative Model Updates: 10526
Cumulative Timesteps: 88109636

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 865.67188
Policy Entropy: -0.36136
Value Function Loss: 1.86528

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14711
Policy Update Magnitude: 0.06123
Value Function Update Magnitude: 0.06986

Collected Steps per Second: 15829.33613
Overall Steps per Second: 2621.33628

Timestep Collection Time: 3.16349
Timestep Consumption Time: 15.93974
PPO Batch Consumption Time: 2.37521
Total Iteration Time: 19.10323

Cumulative Model Updates: 10532
Cumulative Timesteps: 88159712

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1372.79632
Policy Entropy: -0.36668
Value Function Loss: 1.98305

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.06025
Value Function Update Magnitude: 0.09847

Collected Steps per Second: 14508.91398
Overall Steps per Second: 2521.20954

Timestep Collection Time: 3.45333
Timestep Consumption Time: 16.41968
PPO Batch Consumption Time: 2.41310
Total Iteration Time: 19.87300

Cumulative Model Updates: 10538
Cumulative Timesteps: 88209816

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1154.27353
Policy Entropy: -0.36620
Value Function Loss: 1.95606

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14259
Policy Update Magnitude: 0.06178
Value Function Update Magnitude: 0.09498

Collected Steps per Second: 12524.86577
Overall Steps per Second: 2463.21195

Timestep Collection Time: 3.99797
Timestep Consumption Time: 16.33077
PPO Batch Consumption Time: 2.41772
Total Iteration Time: 20.32874

Cumulative Model Updates: 10544
Cumulative Timesteps: 88259890

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1784.34214
Policy Entropy: -0.36779
Value Function Loss: 1.93040

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.07726
Value Function Update Magnitude: 0.09882

Collected Steps per Second: 13345.28570
Overall Steps per Second: 2594.83411

Timestep Collection Time: 3.74994
Timestep Consumption Time: 15.53607
PPO Batch Consumption Time: 2.29537
Total Iteration Time: 19.28601

Cumulative Model Updates: 10550
Cumulative Timesteps: 88309934

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1922.62312
Policy Entropy: -0.37039
Value Function Loss: 1.83676

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.16852
Policy Update Magnitude: 0.08238
Value Function Update Magnitude: 0.10297

Collected Steps per Second: 12472.95885
Overall Steps per Second: 2532.90824

Timestep Collection Time: 4.01589
Timestep Consumption Time: 15.75980
PPO Batch Consumption Time: 2.31619
Total Iteration Time: 19.77569

Cumulative Model Updates: 10556
Cumulative Timesteps: 88360024

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1427.83899
Policy Entropy: -0.37174
Value Function Loss: 1.93353

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.15620
Policy Update Magnitude: 0.07144
Value Function Update Magnitude: 0.12682

Collected Steps per Second: 13149.60725
Overall Steps per Second: 2507.04941

Timestep Collection Time: 3.80437
Timestep Consumption Time: 16.14976
PPO Batch Consumption Time: 2.36124
Total Iteration Time: 19.95413

Cumulative Model Updates: 10562
Cumulative Timesteps: 88410050

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1914.46092
Policy Entropy: -0.37422
Value Function Loss: 2.04935

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.17013
Policy Update Magnitude: 0.06821
Value Function Update Magnitude: 0.10839

Collected Steps per Second: 12844.52894
Overall Steps per Second: 2463.52042

Timestep Collection Time: 3.89831
Timestep Consumption Time: 16.42707
PPO Batch Consumption Time: 2.43258
Total Iteration Time: 20.32538

Cumulative Model Updates: 10568
Cumulative Timesteps: 88460122

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1502.74940
Policy Entropy: -0.37330
Value Function Loss: 2.10303

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.17463
Policy Update Magnitude: 0.06071
Value Function Update Magnitude: 0.11557

Collected Steps per Second: 14280.63972
Overall Steps per Second: 2474.65771

Timestep Collection Time: 3.50643
Timestep Consumption Time: 16.72829
PPO Batch Consumption Time: 2.46563
Total Iteration Time: 20.23472

Cumulative Model Updates: 10574
Cumulative Timesteps: 88510196

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2353.60555
Policy Entropy: -0.37496
Value Function Loss: 1.99616

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.17124
Policy Update Magnitude: 0.05955
Value Function Update Magnitude: 0.11700

Collected Steps per Second: 14832.53672
Overall Steps per Second: 2494.36720

Timestep Collection Time: 3.37205
Timestep Consumption Time: 16.67953
PPO Batch Consumption Time: 2.43954
Total Iteration Time: 20.05158

Cumulative Model Updates: 10580
Cumulative Timesteps: 88560212

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 88560212...
Checkpoint 88560212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1997.93992
Policy Entropy: -0.37511
Value Function Loss: 1.94974

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.17759
Policy Update Magnitude: 0.10082
Value Function Update Magnitude: 0.12579

Collected Steps per Second: 16779.63340
Overall Steps per Second: 2594.93502

Timestep Collection Time: 2.98254
Timestep Consumption Time: 16.30349
PPO Batch Consumption Time: 2.39367
Total Iteration Time: 19.28603

Cumulative Model Updates: 10586
Cumulative Timesteps: 88610258

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1256.49523
Policy Entropy: -0.37642
Value Function Loss: 1.94847

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.08940
Value Function Update Magnitude: 0.10545

Collected Steps per Second: 12930.73517
Overall Steps per Second: 2513.83968

Timestep Collection Time: 3.87093
Timestep Consumption Time: 16.04044
PPO Batch Consumption Time: 2.36089
Total Iteration Time: 19.91137

Cumulative Model Updates: 10592
Cumulative Timesteps: 88660312

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1478.67891
Policy Entropy: -0.37855
Value Function Loss: 2.03660

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.08361
Value Function Update Magnitude: 0.09203

Collected Steps per Second: 13048.64394
Overall Steps per Second: 2552.80640

Timestep Collection Time: 3.83503
Timestep Consumption Time: 15.76771
PPO Batch Consumption Time: 2.33146
Total Iteration Time: 19.60274

Cumulative Model Updates: 10598
Cumulative Timesteps: 88710354

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2166.23827
Policy Entropy: -0.37897
Value Function Loss: 2.02294

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.15279
Policy Update Magnitude: 0.07990
Value Function Update Magnitude: 0.13441

Collected Steps per Second: 12577.21318
Overall Steps per Second: 2479.66220

Timestep Collection Time: 3.97560
Timestep Consumption Time: 16.18924
PPO Batch Consumption Time: 2.38366
Total Iteration Time: 20.16484

Cumulative Model Updates: 10604
Cumulative Timesteps: 88760356

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1562.44973
Policy Entropy: -0.37939
Value Function Loss: 2.04752

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.16112
Policy Update Magnitude: 0.07952
Value Function Update Magnitude: 0.13294

Collected Steps per Second: 14148.94956
Overall Steps per Second: 2587.42663

Timestep Collection Time: 3.53638
Timestep Consumption Time: 15.80176
PPO Batch Consumption Time: 2.34953
Total Iteration Time: 19.33813

Cumulative Model Updates: 10610
Cumulative Timesteps: 88810392

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 886.37023
Policy Entropy: -0.37541
Value Function Loss: 1.97310

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.08257
Value Function Update Magnitude: 0.12311

Collected Steps per Second: 13235.15399
Overall Steps per Second: 2530.27096

Timestep Collection Time: 3.77842
Timestep Consumption Time: 15.98547
PPO Batch Consumption Time: 2.34320
Total Iteration Time: 19.76389

Cumulative Model Updates: 10616
Cumulative Timesteps: 88860400

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1713.56889
Policy Entropy: -0.37276
Value Function Loss: 1.94960

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.18183
Policy Update Magnitude: 0.07350
Value Function Update Magnitude: 0.15563

Collected Steps per Second: 13785.55578
Overall Steps per Second: 2560.74305

Timestep Collection Time: 3.62757
Timestep Consumption Time: 15.90114
PPO Batch Consumption Time: 2.36847
Total Iteration Time: 19.52871

Cumulative Model Updates: 10622
Cumulative Timesteps: 88910408

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3082.29867
Policy Entropy: -0.36929
Value Function Loss: 1.92231

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.17159
Policy Update Magnitude: 0.06841
Value Function Update Magnitude: 0.16187

Collected Steps per Second: 12912.05463
Overall Steps per Second: 2445.77703

Timestep Collection Time: 3.87684
Timestep Consumption Time: 16.59027
PPO Batch Consumption Time: 2.42327
Total Iteration Time: 20.46712

Cumulative Model Updates: 10628
Cumulative Timesteps: 88960466

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1772.92383
Policy Entropy: -0.36993
Value Function Loss: 1.91286

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.17616
Policy Update Magnitude: 0.07296
Value Function Update Magnitude: 0.14808

Collected Steps per Second: 12789.26370
Overall Steps per Second: 2496.63002

Timestep Collection Time: 3.91453
Timestep Consumption Time: 16.13810
PPO Batch Consumption Time: 2.38370
Total Iteration Time: 20.05263

Cumulative Model Updates: 10634
Cumulative Timesteps: 89010530

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1339.28419
Policy Entropy: -0.37390
Value Function Loss: 1.95250

Mean KL Divergence: 0.02680
SB3 Clip Fraction: 0.28615
Policy Update Magnitude: 0.07352
Value Function Update Magnitude: 0.13130

Collected Steps per Second: 13478.83577
Overall Steps per Second: 2470.39427

Timestep Collection Time: 3.71085
Timestep Consumption Time: 16.53612
PPO Batch Consumption Time: 2.43177
Total Iteration Time: 20.24697

Cumulative Model Updates: 10640
Cumulative Timesteps: 89060548

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 89060548...
Checkpoint 89060548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1672.78034
Policy Entropy: -0.36922
Value Function Loss: 1.99873

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.16787
Policy Update Magnitude: 0.05896
Value Function Update Magnitude: 0.12095

Collected Steps per Second: 15161.29156
Overall Steps per Second: 2488.10758

Timestep Collection Time: 3.29866
Timestep Consumption Time: 16.80175
PPO Batch Consumption Time: 2.49873
Total Iteration Time: 20.10042

Cumulative Model Updates: 10646
Cumulative Timesteps: 89110560

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1269.90128
Policy Entropy: -0.36917
Value Function Loss: 1.97055

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14250
Policy Update Magnitude: 0.07164
Value Function Update Magnitude: 0.11595

Collected Steps per Second: 15055.77535
Overall Steps per Second: 2589.13627

Timestep Collection Time: 3.32098
Timestep Consumption Time: 15.99047
PPO Batch Consumption Time: 2.37910
Total Iteration Time: 19.31146

Cumulative Model Updates: 10652
Cumulative Timesteps: 89160560

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1949.07670
Policy Entropy: -0.36549
Value Function Loss: 1.96262

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.18432
Policy Update Magnitude: 0.06892
Value Function Update Magnitude: 0.12505

Collected Steps per Second: 12815.08543
Overall Steps per Second: 2544.20768

Timestep Collection Time: 3.90524
Timestep Consumption Time: 15.76532
PPO Batch Consumption Time: 2.29985
Total Iteration Time: 19.67056

Cumulative Model Updates: 10658
Cumulative Timesteps: 89210606

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1973.64624
Policy Entropy: -0.36293
Value Function Loss: 1.86737

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.18193
Policy Update Magnitude: 0.06725
Value Function Update Magnitude: 0.16210

Collected Steps per Second: 16092.21380
Overall Steps per Second: 2604.49177

Timestep Collection Time: 3.11256
Timestep Consumption Time: 16.11883
PPO Batch Consumption Time: 2.38090
Total Iteration Time: 19.23139

Cumulative Model Updates: 10664
Cumulative Timesteps: 89260694

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1384.89166
Policy Entropy: -0.36344
Value Function Loss: 1.94026

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.19778
Policy Update Magnitude: 0.08103
Value Function Update Magnitude: 0.17028

Collected Steps per Second: 16636.69509
Overall Steps per Second: 2561.48355

Timestep Collection Time: 3.01093
Timestep Consumption Time: 16.54492
PPO Batch Consumption Time: 2.42557
Total Iteration Time: 19.55585

Cumulative Model Updates: 10670
Cumulative Timesteps: 89310786

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2704.28133
Policy Entropy: -0.36041
Value Function Loss: 1.91747

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.15719
Policy Update Magnitude: 0.06848
Value Function Update Magnitude: 0.16717

Collected Steps per Second: 15201.45264
Overall Steps per Second: 2535.95275

Timestep Collection Time: 3.29429
Timestep Consumption Time: 16.45292
PPO Batch Consumption Time: 2.41807
Total Iteration Time: 19.74721

Cumulative Model Updates: 10676
Cumulative Timesteps: 89360864

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1222.79509
Policy Entropy: -0.35824
Value Function Loss: 1.96028

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.06612
Value Function Update Magnitude: 0.13379

Collected Steps per Second: 12177.03347
Overall Steps per Second: 2511.83682

Timestep Collection Time: 4.11217
Timestep Consumption Time: 15.82304
PPO Batch Consumption Time: 2.37334
Total Iteration Time: 19.93521

Cumulative Model Updates: 10682
Cumulative Timesteps: 89410938

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1840.99657
Policy Entropy: -0.35637
Value Function Loss: 1.97542

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.16397
Policy Update Magnitude: 0.06138
Value Function Update Magnitude: 0.11672

Collected Steps per Second: 12863.18668
Overall Steps per Second: 2566.45091

Timestep Collection Time: 3.89204
Timestep Consumption Time: 15.61506
PPO Batch Consumption Time: 2.29993
Total Iteration Time: 19.50709

Cumulative Model Updates: 10688
Cumulative Timesteps: 89461002

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 809.43440
Policy Entropy: -0.35582
Value Function Loss: 2.01768

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.17501
Policy Update Magnitude: 0.07024
Value Function Update Magnitude: 0.12314

Collected Steps per Second: 12606.82082
Overall Steps per Second: 2525.45239

Timestep Collection Time: 3.96769
Timestep Consumption Time: 15.83866
PPO Batch Consumption Time: 2.37215
Total Iteration Time: 19.80635

Cumulative Model Updates: 10694
Cumulative Timesteps: 89511022

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1943.98124
Policy Entropy: -0.35236
Value Function Loss: 2.02315

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14957
Policy Update Magnitude: 0.06571
Value Function Update Magnitude: 0.13573

Collected Steps per Second: 14224.37210
Overall Steps per Second: 2490.10916

Timestep Collection Time: 3.52128
Timestep Consumption Time: 16.59350
PPO Batch Consumption Time: 2.41446
Total Iteration Time: 20.11478

Cumulative Model Updates: 10700
Cumulative Timesteps: 89561110

Timesteps Collected: 50088
--------END ITERATION REPORT--------


Saving checkpoint 89561110...
Checkpoint 89561110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1517.65042
Policy Entropy: -0.35198
Value Function Loss: 1.99711

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.15592
Policy Update Magnitude: 0.07079
Value Function Update Magnitude: 0.12356

Collected Steps per Second: 12625.23894
Overall Steps per Second: 2534.35499

Timestep Collection Time: 3.96365
Timestep Consumption Time: 15.78181
PPO Batch Consumption Time: 2.31144
Total Iteration Time: 19.74546

Cumulative Model Updates: 10706
Cumulative Timesteps: 89611152

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1554.90768
Policy Entropy: -0.34831
Value Function Loss: 1.93002

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.18664
Policy Update Magnitude: 0.06800
Value Function Update Magnitude: 0.13339

Collected Steps per Second: 14134.54216
Overall Steps per Second: 2595.57351

Timestep Collection Time: 3.54111
Timestep Consumption Time: 15.74249
PPO Batch Consumption Time: 2.30548
Total Iteration Time: 19.28360

Cumulative Model Updates: 10712
Cumulative Timesteps: 89661204

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1686.42256
Policy Entropy: -0.35116
Value Function Loss: 1.92275

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.18071
Policy Update Magnitude: 0.07139
Value Function Update Magnitude: 0.11549

Collected Steps per Second: 14924.87083
Overall Steps per Second: 2546.51540

Timestep Collection Time: 3.35494
Timestep Consumption Time: 16.30801
PPO Batch Consumption Time: 2.40749
Total Iteration Time: 19.66295

Cumulative Model Updates: 10718
Cumulative Timesteps: 89711276

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1938.49672
Policy Entropy: -0.35170
Value Function Loss: 1.92821

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14943
Policy Update Magnitude: 0.06602
Value Function Update Magnitude: 0.11355

Collected Steps per Second: 12510.80707
Overall Steps per Second: 2492.31762

Timestep Collection Time: 3.99926
Timestep Consumption Time: 16.07603
PPO Batch Consumption Time: 2.39767
Total Iteration Time: 20.07529

Cumulative Model Updates: 10724
Cumulative Timesteps: 89761310

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2619.33029
Policy Entropy: -0.35423
Value Function Loss: 1.93260

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13013
Policy Update Magnitude: 0.07904
Value Function Update Magnitude: 0.10683

Collected Steps per Second: 12851.55458
Overall Steps per Second: 2533.71635

Timestep Collection Time: 3.89276
Timestep Consumption Time: 15.85215
PPO Batch Consumption Time: 2.33436
Total Iteration Time: 19.74491

Cumulative Model Updates: 10730
Cumulative Timesteps: 89811338

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2597.71919
Policy Entropy: -0.35345
Value Function Loss: 1.90926

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.16152
Policy Update Magnitude: 0.07284
Value Function Update Magnitude: 0.12102

Collected Steps per Second: 12836.13564
Overall Steps per Second: 2598.07446

Timestep Collection Time: 3.89681
Timestep Consumption Time: 15.35591
PPO Batch Consumption Time: 2.27011
Total Iteration Time: 19.25272

Cumulative Model Updates: 10736
Cumulative Timesteps: 89861358

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1731.78374
Policy Entropy: -0.35259
Value Function Loss: 1.88129

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.16150
Policy Update Magnitude: 0.06973
Value Function Update Magnitude: 0.15664

Collected Steps per Second: 14849.31138
Overall Steps per Second: 2621.13266

Timestep Collection Time: 3.36999
Timestep Consumption Time: 15.72176
PPO Batch Consumption Time: 2.30496
Total Iteration Time: 19.09175

Cumulative Model Updates: 10742
Cumulative Timesteps: 89911400

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 983.15860
Policy Entropy: -0.35318
Value Function Loss: 1.98264

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.15711
Policy Update Magnitude: 0.07219
Value Function Update Magnitude: 0.14262

Collected Steps per Second: 16367.31471
Overall Steps per Second: 2704.68857

Timestep Collection Time: 3.05524
Timestep Consumption Time: 15.43340
PPO Batch Consumption Time: 2.26503
Total Iteration Time: 18.48864

Cumulative Model Updates: 10748
Cumulative Timesteps: 89961406

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1766.86209
Policy Entropy: -0.34925
Value Function Loss: 1.95835

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09988
Policy Update Magnitude: 0.08737
Value Function Update Magnitude: 0.14462

Collected Steps per Second: 14942.38857
Overall Steps per Second: 2613.73343

Timestep Collection Time: 3.34699
Timestep Consumption Time: 15.78733
PPO Batch Consumption Time: 2.34409
Total Iteration Time: 19.13432

Cumulative Model Updates: 10754
Cumulative Timesteps: 90011418

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1525.84775
Policy Entropy: -0.34905
Value Function Loss: 1.96831

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14204
Policy Update Magnitude: 0.08632
Value Function Update Magnitude: 0.12414

Collected Steps per Second: 13186.61966
Overall Steps per Second: 2450.72861

Timestep Collection Time: 3.79642
Timestep Consumption Time: 16.63097
PPO Batch Consumption Time: 2.43855
Total Iteration Time: 20.42739

Cumulative Model Updates: 10760
Cumulative Timesteps: 90061480

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 90061480...
Checkpoint 90061480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1987.07288
Policy Entropy: -0.34505
Value Function Loss: 1.92554

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.07841
Value Function Update Magnitude: 0.14308

Collected Steps per Second: 13659.92026
Overall Steps per Second: 2498.68576

Timestep Collection Time: 3.66488
Timestep Consumption Time: 16.37045
PPO Batch Consumption Time: 2.44089
Total Iteration Time: 20.03533

Cumulative Model Updates: 10766
Cumulative Timesteps: 90111542

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1130.82852
Policy Entropy: -0.34427
Value Function Loss: 1.93966

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12865
Policy Update Magnitude: 0.07508
Value Function Update Magnitude: 0.18032

Collected Steps per Second: 12582.55446
Overall Steps per Second: 2479.88990

Timestep Collection Time: 3.97391
Timestep Consumption Time: 16.18908
PPO Batch Consumption Time: 2.40766
Total Iteration Time: 20.16299

Cumulative Model Updates: 10772
Cumulative Timesteps: 90161544

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1660.13548
Policy Entropy: -0.34370
Value Function Loss: 1.93094

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15628
Policy Update Magnitude: 0.07491
Value Function Update Magnitude: 0.14192

Collected Steps per Second: 12729.75748
Overall Steps per Second: 2597.59062

Timestep Collection Time: 3.92828
Timestep Consumption Time: 15.32264
PPO Batch Consumption Time: 2.28276
Total Iteration Time: 19.25092

Cumulative Model Updates: 10778
Cumulative Timesteps: 90211550

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3096.94786
Policy Entropy: -0.34242
Value Function Loss: 1.87564

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.18210
Policy Update Magnitude: 0.07760
Value Function Update Magnitude: 0.12590

Collected Steps per Second: 12624.45552
Overall Steps per Second: 2520.79063

Timestep Collection Time: 3.96088
Timestep Consumption Time: 15.87575
PPO Batch Consumption Time: 2.33645
Total Iteration Time: 19.83663

Cumulative Model Updates: 10784
Cumulative Timesteps: 90261554

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2049.76027
Policy Entropy: -0.33914
Value Function Loss: 1.80690

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.06929
Value Function Update Magnitude: 0.12741

Collected Steps per Second: 12150.90479
Overall Steps per Second: 2531.85459

Timestep Collection Time: 4.12002
Timestep Consumption Time: 15.65284
PPO Batch Consumption Time: 2.30025
Total Iteration Time: 19.77286

Cumulative Model Updates: 10790
Cumulative Timesteps: 90311616

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1852.02865
Policy Entropy: -0.33829
Value Function Loss: 1.77805

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15851
Policy Update Magnitude: 0.06257
Value Function Update Magnitude: 0.13048

Collected Steps per Second: 16293.93800
Overall Steps per Second: 2629.63381

Timestep Collection Time: 3.06998
Timestep Consumption Time: 15.95244
PPO Batch Consumption Time: 2.33414
Total Iteration Time: 19.02242

Cumulative Model Updates: 10796
Cumulative Timesteps: 90361638

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1099.96031
Policy Entropy: -0.33603
Value Function Loss: 1.80267

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14755
Policy Update Magnitude: 0.06334
Value Function Update Magnitude: 0.15681

Collected Steps per Second: 13379.98407
Overall Steps per Second: 2475.12212

Timestep Collection Time: 3.74335
Timestep Consumption Time: 16.49242
PPO Batch Consumption Time: 2.41631
Total Iteration Time: 20.23577

Cumulative Model Updates: 10802
Cumulative Timesteps: 90411724

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1891.94478
Policy Entropy: -0.33617
Value Function Loss: 1.79110

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.06040
Value Function Update Magnitude: 0.18526

Collected Steps per Second: 13267.82308
Overall Steps per Second: 2513.70976

Timestep Collection Time: 3.77138
Timestep Consumption Time: 16.13466
PPO Batch Consumption Time: 2.42122
Total Iteration Time: 19.90604

Cumulative Model Updates: 10808
Cumulative Timesteps: 90461762

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.88547
Policy Entropy: -0.33442
Value Function Loss: 1.88635

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14332
Policy Update Magnitude: 0.06311
Value Function Update Magnitude: 0.16946

Collected Steps per Second: 12889.31271
Overall Steps per Second: 2464.23763

Timestep Collection Time: 3.88384
Timestep Consumption Time: 16.43076
PPO Batch Consumption Time: 2.42228
Total Iteration Time: 20.31460

Cumulative Model Updates: 10814
Cumulative Timesteps: 90511822

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2353.80360
Policy Entropy: -0.33285
Value Function Loss: 1.92374

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14589
Policy Update Magnitude: 0.06965
Value Function Update Magnitude: 0.12696

Collected Steps per Second: 12632.63985
Overall Steps per Second: 2476.37958

Timestep Collection Time: 3.95911
Timestep Consumption Time: 16.23731
PPO Batch Consumption Time: 2.38391
Total Iteration Time: 20.19642

Cumulative Model Updates: 10820
Cumulative Timesteps: 90561836

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 90561836...
Checkpoint 90561836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2679.15194
Policy Entropy: -0.33003
Value Function Loss: 1.99041

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.07291
Value Function Update Magnitude: 0.13697

Collected Steps per Second: 13089.03269
Overall Steps per Second: 2448.54890

Timestep Collection Time: 3.82183
Timestep Consumption Time: 16.60823
PPO Batch Consumption Time: 2.45360
Total Iteration Time: 20.43006

Cumulative Model Updates: 10826
Cumulative Timesteps: 90611860

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1659.13347
Policy Entropy: -0.32884
Value Function Loss: 1.97258

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.07229
Value Function Update Magnitude: 0.12704

Collected Steps per Second: 12742.44179
Overall Steps per Second: 2477.26196

Timestep Collection Time: 3.92437
Timestep Consumption Time: 16.26163
PPO Batch Consumption Time: 2.39854
Total Iteration Time: 20.18600

Cumulative Model Updates: 10832
Cumulative Timesteps: 90661866

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1181.39843
Policy Entropy: -0.32624
Value Function Loss: 1.93560

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14409
Policy Update Magnitude: 0.07015
Value Function Update Magnitude: 0.12221

Collected Steps per Second: 12491.67758
Overall Steps per Second: 2460.52882

Timestep Collection Time: 4.00331
Timestep Consumption Time: 16.32078
PPO Batch Consumption Time: 2.44469
Total Iteration Time: 20.32409

Cumulative Model Updates: 10838
Cumulative Timesteps: 90711874

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1941.29087
Policy Entropy: -0.32592
Value Function Loss: 1.92690

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13076
Policy Update Magnitude: 0.07364
Value Function Update Magnitude: 0.12582

Collected Steps per Second: 12563.57984
Overall Steps per Second: 1932.91062

Timestep Collection Time: 3.98008
Timestep Consumption Time: 21.88972
PPO Batch Consumption Time: 2.43308
Total Iteration Time: 25.86979

Cumulative Model Updates: 10844
Cumulative Timesteps: 90761878

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3882.50866
Policy Entropy: -0.32246
Value Function Loss: 1.86235

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.16054
Policy Update Magnitude: 0.08038
Value Function Update Magnitude: 0.11739

Collected Steps per Second: 12461.18414
Overall Steps per Second: 2459.84850

Timestep Collection Time: 4.01695
Timestep Consumption Time: 16.33227
PPO Batch Consumption Time: 2.44321
Total Iteration Time: 20.34922

Cumulative Model Updates: 10850
Cumulative Timesteps: 90811934

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1553.67630
Policy Entropy: -0.32183
Value Function Loss: 1.83655

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10201
Policy Update Magnitude: 0.09048
Value Function Update Magnitude: 0.10405

Collected Steps per Second: 12592.25480
Overall Steps per Second: 2439.23464

Timestep Collection Time: 3.97800
Timestep Consumption Time: 16.55795
PPO Batch Consumption Time: 2.43681
Total Iteration Time: 20.53595

Cumulative Model Updates: 10856
Cumulative Timesteps: 90862026

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1724.83708
Policy Entropy: -0.31952
Value Function Loss: 1.86416

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.09643
Value Function Update Magnitude: 0.09667

Collected Steps per Second: 12394.10352
Overall Steps per Second: 2508.00726

Timestep Collection Time: 4.03740
Timestep Consumption Time: 15.91469
PPO Batch Consumption Time: 2.34290
Total Iteration Time: 19.95210

Cumulative Model Updates: 10862
Cumulative Timesteps: 90912066

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1152.14194
Policy Entropy: -0.31873
Value Function Loss: 1.81549

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14584
Policy Update Magnitude: 0.08851
Value Function Update Magnitude: 0.10523

Collected Steps per Second: 13281.37346
Overall Steps per Second: 2500.38970

Timestep Collection Time: 3.76512
Timestep Consumption Time: 16.23416
PPO Batch Consumption Time: 2.38592
Total Iteration Time: 19.99928

Cumulative Model Updates: 10868
Cumulative Timesteps: 90962072

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1962.05690
Policy Entropy: -0.31849
Value Function Loss: 1.84671

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.16075
Policy Update Magnitude: 0.08351
Value Function Update Magnitude: 0.10995

Collected Steps per Second: 12498.52110
Overall Steps per Second: 1517.00480

Timestep Collection Time: 4.00239
Timestep Consumption Time: 28.97311
PPO Batch Consumption Time: 2.29009
Total Iteration Time: 32.97551

Cumulative Model Updates: 10874
Cumulative Timesteps: 91012096

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2342.37955
Policy Entropy: -0.31839
Value Function Loss: 1.76832

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.06831
Value Function Update Magnitude: 0.12865

Collected Steps per Second: 12360.54666
Overall Steps per Second: 2476.40070

Timestep Collection Time: 4.04950
Timestep Consumption Time: 16.16290
PPO Batch Consumption Time: 2.41551
Total Iteration Time: 20.21240

Cumulative Model Updates: 10880
Cumulative Timesteps: 91062150

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 91062150...
Checkpoint 91062150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2058.13579
Policy Entropy: -0.31650
Value Function Loss: 1.79193

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14935
Policy Update Magnitude: 0.06293
Value Function Update Magnitude: 0.13818

Collected Steps per Second: 12584.50462
Overall Steps per Second: 543.90976

Timestep Collection Time: 3.97823
Timestep Consumption Time: 88.06646
PPO Batch Consumption Time: 2.33113
Total Iteration Time: 92.04468

Cumulative Model Updates: 10886
Cumulative Timesteps: 91112214

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1174.40334
Policy Entropy: -0.31640
Value Function Loss: 1.80798

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.07190
Value Function Update Magnitude: 0.11850

Collected Steps per Second: 12413.70849
Overall Steps per Second: 2470.53414

Timestep Collection Time: 4.03425
Timestep Consumption Time: 16.23667
PPO Batch Consumption Time: 2.43065
Total Iteration Time: 20.27092

Cumulative Model Updates: 10892
Cumulative Timesteps: 91162294

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1253.09126
Policy Entropy: -0.31521
Value Function Loss: 1.82708

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.16703
Policy Update Magnitude: 0.06971
Value Function Update Magnitude: 0.11812

Collected Steps per Second: 12599.51880
Overall Steps per Second: 1279.32618

Timestep Collection Time: 3.97142
Timestep Consumption Time: 35.14136
PPO Batch Consumption Time: 2.38370
Total Iteration Time: 39.11278

Cumulative Model Updates: 10898
Cumulative Timesteps: 91212332

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 882.13767
Policy Entropy: -0.31669
Value Function Loss: 1.80312

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.06857
Value Function Update Magnitude: 0.18411

Collected Steps per Second: 12360.16225
Overall Steps per Second: 2419.84420

Timestep Collection Time: 4.04865
Timestep Consumption Time: 16.63119
PPO Batch Consumption Time: 2.44757
Total Iteration Time: 20.67984

Cumulative Model Updates: 10904
Cumulative Timesteps: 91262374

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1326.68578
Policy Entropy: -0.31587
Value Function Loss: 1.79578

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.07497
Value Function Update Magnitude: 0.15362

Collected Steps per Second: 13357.78890
Overall Steps per Second: 2444.83101

Timestep Collection Time: 3.74837
Timestep Consumption Time: 16.73157
PPO Batch Consumption Time: 2.35848
Total Iteration Time: 20.47994

Cumulative Model Updates: 10910
Cumulative Timesteps: 91312444

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1532.79573
Policy Entropy: -0.31592
Value Function Loss: 1.88370

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.07532
Value Function Update Magnitude: 0.12851

Collected Steps per Second: 12599.50437
Overall Steps per Second: 2464.40901

Timestep Collection Time: 3.96936
Timestep Consumption Time: 16.32435
PPO Batch Consumption Time: 2.41953
Total Iteration Time: 20.29371

Cumulative Model Updates: 10916
Cumulative Timesteps: 91362456

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1184.85897
Policy Entropy: -0.31238
Value Function Loss: 1.85148

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.07433
Value Function Update Magnitude: 0.12890

Collected Steps per Second: 12549.12572
Overall Steps per Second: 2466.84671

Timestep Collection Time: 3.98801
Timestep Consumption Time: 16.29943
PPO Batch Consumption Time: 2.44015
Total Iteration Time: 20.28744

Cumulative Model Updates: 10922
Cumulative Timesteps: 91412502

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1427.59726
Policy Entropy: -0.31269
Value Function Loss: 1.86046

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12671
Policy Update Magnitude: 0.07778
Value Function Update Magnitude: 0.12702

Collected Steps per Second: 12586.67131
Overall Steps per Second: 786.09791

Timestep Collection Time: 3.97500
Timestep Consumption Time: 59.67102
PPO Batch Consumption Time: 2.41313
Total Iteration Time: 63.64602

Cumulative Model Updates: 10928
Cumulative Timesteps: 91462534

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1251.82017
Policy Entropy: -0.31074
Value Function Loss: 1.74134

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.19861
Policy Update Magnitude: 0.08049
Value Function Update Magnitude: 0.13942

Collected Steps per Second: 12439.37849
Overall Steps per Second: 2522.33422

Timestep Collection Time: 4.02432
Timestep Consumption Time: 15.82238
PPO Batch Consumption Time: 2.35957
Total Iteration Time: 19.84670

Cumulative Model Updates: 10934
Cumulative Timesteps: 91512594

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2146.60466
Policy Entropy: -0.31031
Value Function Loss: 1.76704

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.18071
Policy Update Magnitude: 0.07236
Value Function Update Magnitude: 0.12865

Collected Steps per Second: 12722.18989
Overall Steps per Second: 2509.97592

Timestep Collection Time: 3.93439
Timestep Consumption Time: 16.00764
PPO Batch Consumption Time: 2.35209
Total Iteration Time: 19.94202

Cumulative Model Updates: 10940
Cumulative Timesteps: 91562648

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 91562648...
Checkpoint 91562648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1813.74995
Policy Entropy: -0.30893
Value Function Loss: 1.74603

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.15531
Policy Update Magnitude: 0.06865
Value Function Update Magnitude: 0.12154

Collected Steps per Second: 12375.00837
Overall Steps per Second: 2482.46559

Timestep Collection Time: 4.04040
Timestep Consumption Time: 16.10086
PPO Batch Consumption Time: 2.41501
Total Iteration Time: 20.14127

Cumulative Model Updates: 10946
Cumulative Timesteps: 91612648

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1773.36533
Policy Entropy: -0.31092
Value Function Loss: 1.75160

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.07233
Value Function Update Magnitude: 0.11901

Collected Steps per Second: 12740.78258
Overall Steps per Second: 498.66949

Timestep Collection Time: 3.93241
Timestep Consumption Time: 96.53895
PPO Batch Consumption Time: 2.31477
Total Iteration Time: 100.47136

Cumulative Model Updates: 10952
Cumulative Timesteps: 91662750

Timesteps Collected: 50102
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1627.87800
Policy Entropy: -0.30849
Value Function Loss: 1.75206

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14704
Policy Update Magnitude: 0.06747
Value Function Update Magnitude: 0.10514

Collected Steps per Second: 12487.15909
Overall Steps per Second: 2466.06533

Timestep Collection Time: 4.00604
Timestep Consumption Time: 16.27891
PPO Batch Consumption Time: 2.40295
Total Iteration Time: 20.28495

Cumulative Model Updates: 10958
Cumulative Timesteps: 91712774

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2456.37330
Policy Entropy: -0.30846
Value Function Loss: 1.75071

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.17091
Policy Update Magnitude: 0.07351
Value Function Update Magnitude: 0.11526

Collected Steps per Second: 13430.06972
Overall Steps per Second: 497.44017

Timestep Collection Time: 3.72969
Timestep Consumption Time: 96.96584
PPO Batch Consumption Time: 2.41202
Total Iteration Time: 100.69553

Cumulative Model Updates: 10964
Cumulative Timesteps: 91762864

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2858.87421
Policy Entropy: -0.30879
Value Function Loss: 1.71102

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.16531
Policy Update Magnitude: 0.06050
Value Function Update Magnitude: 0.11220

Collected Steps per Second: 12419.96583
Overall Steps per Second: 2404.60866

Timestep Collection Time: 4.02787
Timestep Consumption Time: 16.77635
PPO Batch Consumption Time: 2.46840
Total Iteration Time: 20.80422

Cumulative Model Updates: 10970
Cumulative Timesteps: 91812890

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1723.69559
Policy Entropy: -0.31025
Value Function Loss: 1.68754

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.15811
Policy Update Magnitude: 0.06052
Value Function Update Magnitude: 0.10580

Collected Steps per Second: 12285.14590
Overall Steps per Second: 2551.92458

Timestep Collection Time: 4.07223
Timestep Consumption Time: 15.53179
PPO Batch Consumption Time: 2.31849
Total Iteration Time: 19.60403

Cumulative Model Updates: 10976
Cumulative Timesteps: 91862918

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2036.52128
Policy Entropy: -0.31025
Value Function Loss: 1.72102

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.15053
Policy Update Magnitude: 0.06132
Value Function Update Magnitude: 0.09754

Collected Steps per Second: 12423.31442
Overall Steps per Second: 2444.94469

Timestep Collection Time: 4.02872
Timestep Consumption Time: 16.44210
PPO Batch Consumption Time: 2.42688
Total Iteration Time: 20.47081

Cumulative Model Updates: 10982
Cumulative Timesteps: 91912968

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1550.00038
Policy Entropy: -0.30764
Value Function Loss: 1.81401

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.15791
Policy Update Magnitude: 0.06497
Value Function Update Magnitude: 0.10065

Collected Steps per Second: 12401.62195
Overall Steps per Second: 2503.56661

Timestep Collection Time: 4.03544
Timestep Consumption Time: 15.95444
PPO Batch Consumption Time: 2.38489
Total Iteration Time: 19.98988

Cumulative Model Updates: 10988
Cumulative Timesteps: 91963014

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1491.89789
Policy Entropy: -0.30633
Value Function Loss: 1.79213

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.15001
Policy Update Magnitude: 0.06604
Value Function Update Magnitude: 0.10862

Collected Steps per Second: 12730.36052
Overall Steps per Second: 722.90903

Timestep Collection Time: 3.93155
Timestep Consumption Time: 65.30261
PPO Batch Consumption Time: 2.39358
Total Iteration Time: 69.23416

Cumulative Model Updates: 10994
Cumulative Timesteps: 92013064

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1517.25719
Policy Entropy: -0.30344
Value Function Loss: 1.73862

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.06653
Value Function Update Magnitude: 0.09896

Collected Steps per Second: 12443.58602
Overall Steps per Second: 2415.96605

Timestep Collection Time: 4.02360
Timestep Consumption Time: 16.70020
PPO Batch Consumption Time: 2.47413
Total Iteration Time: 20.72380

Cumulative Model Updates: 11000
Cumulative Timesteps: 92063132

Timesteps Collected: 50068
--------END ITERATION REPORT--------


Saving checkpoint 92063132...
Checkpoint 92063132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1054.75741
Policy Entropy: -0.30244
Value Function Loss: 1.71801

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.12960
Policy Update Magnitude: 0.06854
Value Function Update Magnitude: 0.09439

Collected Steps per Second: 13193.17531
Overall Steps per Second: 2503.29166

Timestep Collection Time: 3.79135
Timestep Consumption Time: 16.19034
PPO Batch Consumption Time: 2.38933
Total Iteration Time: 19.98169

Cumulative Model Updates: 11006
Cumulative Timesteps: 92113152

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 976.54134
Policy Entropy: -0.30033
Value Function Loss: 1.74598

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.07182
Value Function Update Magnitude: 0.09551

Collected Steps per Second: 12701.58310
Overall Steps per Second: 2516.90317

Timestep Collection Time: 3.94124
Timestep Consumption Time: 15.94828
PPO Batch Consumption Time: 2.34404
Total Iteration Time: 19.88952

Cumulative Model Updates: 11012
Cumulative Timesteps: 92163212

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1722.80330
Policy Entropy: -0.29992
Value Function Loss: 1.72539

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.07487
Value Function Update Magnitude: 0.10751

Collected Steps per Second: 12692.95216
Overall Steps per Second: 2493.03376

Timestep Collection Time: 3.94471
Timestep Consumption Time: 16.13926
PPO Batch Consumption Time: 2.41576
Total Iteration Time: 20.08396

Cumulative Model Updates: 11018
Cumulative Timesteps: 92213282

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1440.88107
Policy Entropy: -0.29951
Value Function Loss: 1.75567

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13657
Policy Update Magnitude: 0.07554
Value Function Update Magnitude: 0.10595

Collected Steps per Second: 12734.55920
Overall Steps per Second: 2486.31544

Timestep Collection Time: 3.92695
Timestep Consumption Time: 16.18634
PPO Batch Consumption Time: 2.38252
Total Iteration Time: 20.11330

Cumulative Model Updates: 11024
Cumulative Timesteps: 92263290

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2299.79674
Policy Entropy: -0.29864
Value Function Loss: 1.76835

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.07945
Value Function Update Magnitude: 0.11060

Collected Steps per Second: 12517.07389
Overall Steps per Second: 2532.79821

Timestep Collection Time: 4.00094
Timestep Consumption Time: 15.77166
PPO Batch Consumption Time: 2.32303
Total Iteration Time: 19.77260

Cumulative Model Updates: 11030
Cumulative Timesteps: 92313370

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1437.88230
Policy Entropy: -0.29578
Value Function Loss: 1.78348

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12613
Policy Update Magnitude: 0.07479
Value Function Update Magnitude: 0.10777

Collected Steps per Second: 13326.58458
Overall Steps per Second: 2508.04509

Timestep Collection Time: 3.75520
Timestep Consumption Time: 16.19819
PPO Batch Consumption Time: 2.38751
Total Iteration Time: 19.95339

Cumulative Model Updates: 11036
Cumulative Timesteps: 92363414

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2465.47165
Policy Entropy: -0.29870
Value Function Loss: 1.78304

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14910
Policy Update Magnitude: 0.09011
Value Function Update Magnitude: 0.10401

Collected Steps per Second: 12563.70697
Overall Steps per Second: 2472.58148

Timestep Collection Time: 3.98370
Timestep Consumption Time: 16.25831
PPO Batch Consumption Time: 2.39385
Total Iteration Time: 20.24200

Cumulative Model Updates: 11042
Cumulative Timesteps: 92413464

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1269.43108
Policy Entropy: -0.29670
Value Function Loss: 1.74612

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.15177
Policy Update Magnitude: 0.08640
Value Function Update Magnitude: 0.10294

Collected Steps per Second: 12610.48082
Overall Steps per Second: 665.84534

Timestep Collection Time: 3.96845
Timestep Consumption Time: 71.19015
PPO Batch Consumption Time: 2.37790
Total Iteration Time: 75.15860

Cumulative Model Updates: 11048
Cumulative Timesteps: 92463508

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1453.88668
Policy Entropy: -0.29677
Value Function Loss: 1.77950

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14960
Policy Update Magnitude: 0.07809
Value Function Update Magnitude: 0.10039

Collected Steps per Second: 13609.29662
Overall Steps per Second: 2453.29199

Timestep Collection Time: 3.67690
Timestep Consumption Time: 16.72018
PPO Batch Consumption Time: 2.44583
Total Iteration Time: 20.39708

Cumulative Model Updates: 11054
Cumulative Timesteps: 92513548

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1352.54693
Policy Entropy: -0.29511
Value Function Loss: 1.71883

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.07382
Value Function Update Magnitude: 0.11578

Collected Steps per Second: 12993.49011
Overall Steps per Second: 2497.55826

Timestep Collection Time: 3.84854
Timestep Consumption Time: 16.17341
PPO Batch Consumption Time: 2.41868
Total Iteration Time: 20.02196

Cumulative Model Updates: 11060
Cumulative Timesteps: 92563554

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 92563554...
Checkpoint 92563554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2115.39800
Policy Entropy: -0.29770
Value Function Loss: 1.68708

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14918
Policy Update Magnitude: 0.08090
Value Function Update Magnitude: 0.15562

Collected Steps per Second: 12683.78073
Overall Steps per Second: 2440.42802

Timestep Collection Time: 3.95024
Timestep Consumption Time: 16.58058
PPO Batch Consumption Time: 2.44340
Total Iteration Time: 20.53082

Cumulative Model Updates: 11066
Cumulative Timesteps: 92613658

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1001.47504
Policy Entropy: -0.29969
Value Function Loss: 1.68626

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.16637
Policy Update Magnitude: 0.07014
Value Function Update Magnitude: 0.17117

Collected Steps per Second: 12805.45279
Overall Steps per Second: 2494.92459

Timestep Collection Time: 3.90880
Timestep Consumption Time: 16.15353
PPO Batch Consumption Time: 2.37932
Total Iteration Time: 20.06233

Cumulative Model Updates: 11072
Cumulative Timesteps: 92663712

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1199.26394
Policy Entropy: -0.29967
Value Function Loss: 1.74254

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.15498
Policy Update Magnitude: 0.06412
Value Function Update Magnitude: 0.13197

Collected Steps per Second: 15382.78656
Overall Steps per Second: 2552.62639

Timestep Collection Time: 3.25533
Timestep Consumption Time: 16.36211
PPO Batch Consumption Time: 2.39912
Total Iteration Time: 19.61744

Cumulative Model Updates: 11078
Cumulative Timesteps: 92713788

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1364.67588
Policy Entropy: -0.30072
Value Function Loss: 1.76188

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14072
Policy Update Magnitude: 0.06021
Value Function Update Magnitude: 0.10127

Collected Steps per Second: 12705.53482
Overall Steps per Second: 2550.04640

Timestep Collection Time: 3.93561
Timestep Consumption Time: 15.67345
PPO Batch Consumption Time: 2.30428
Total Iteration Time: 19.60905

Cumulative Model Updates: 11084
Cumulative Timesteps: 92763792

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2010.94205
Policy Entropy: -0.30033
Value Function Loss: 1.76580

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14503
Policy Update Magnitude: 0.06177
Value Function Update Magnitude: 0.09505

Collected Steps per Second: 13332.01568
Overall Steps per Second: 2544.58848

Timestep Collection Time: 3.75157
Timestep Consumption Time: 15.90426
PPO Batch Consumption Time: 2.33428
Total Iteration Time: 19.65583

Cumulative Model Updates: 11090
Cumulative Timesteps: 92813808

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2486.00148
Policy Entropy: -0.29877
Value Function Loss: 1.73960

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.13653
Policy Update Magnitude: 0.06498
Value Function Update Magnitude: 0.09493

Collected Steps per Second: 12705.42550
Overall Steps per Second: 2527.56370

Timestep Collection Time: 3.94414
Timestep Consumption Time: 15.88206
PPO Batch Consumption Time: 2.32915
Total Iteration Time: 19.82621

Cumulative Model Updates: 11096
Cumulative Timesteps: 92863920

Timesteps Collected: 50112
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2165.25550
Policy Entropy: -0.29635
Value Function Loss: 1.81677

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.14914
Policy Update Magnitude: 0.06708
Value Function Update Magnitude: 0.09832

Collected Steps per Second: 15327.41074
Overall Steps per Second: 2673.47135

Timestep Collection Time: 3.26448
Timestep Consumption Time: 15.45126
PPO Batch Consumption Time: 2.29548
Total Iteration Time: 18.71574

Cumulative Model Updates: 11102
Cumulative Timesteps: 92913956

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1013.42892
Policy Entropy: -0.29649
Value Function Loss: 1.78400

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.06489
Value Function Update Magnitude: 0.10102

Collected Steps per Second: 15755.58625
Overall Steps per Second: 2656.12482

Timestep Collection Time: 3.17602
Timestep Consumption Time: 15.66346
PPO Batch Consumption Time: 2.31065
Total Iteration Time: 18.83948

Cumulative Model Updates: 11108
Cumulative Timesteps: 92963996

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2508.01104
Policy Entropy: -0.29673
Value Function Loss: 1.74244

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.07093
Value Function Update Magnitude: 0.15844

Collected Steps per Second: 12703.12489
Overall Steps per Second: 2490.23230

Timestep Collection Time: 3.93840
Timestep Consumption Time: 16.15209
PPO Batch Consumption Time: 2.40334
Total Iteration Time: 20.09050

Cumulative Model Updates: 11114
Cumulative Timesteps: 93014026

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1443.73759
Policy Entropy: -0.29839
Value Function Loss: 1.68284

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.08013
Value Function Update Magnitude: 0.15291

Collected Steps per Second: 14441.88234
Overall Steps per Second: 2486.57593

Timestep Collection Time: 3.46243
Timestep Consumption Time: 16.64715
PPO Batch Consumption Time: 2.45065
Total Iteration Time: 20.10958

Cumulative Model Updates: 11120
Cumulative Timesteps: 93064030

Timesteps Collected: 50004
--------END ITERATION REPORT--------


Saving checkpoint 93064030...
Checkpoint 93064030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1568.45761
Policy Entropy: -0.29848
Value Function Loss: 1.68446

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.09225
Value Function Update Magnitude: 0.11244

Collected Steps per Second: 12913.66623
Overall Steps per Second: 2553.49482

Timestep Collection Time: 3.87698
Timestep Consumption Time: 15.72988
PPO Batch Consumption Time: 2.31908
Total Iteration Time: 19.60685

Cumulative Model Updates: 11126
Cumulative Timesteps: 93114096

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2500.05183
Policy Entropy: -0.29672
Value Function Loss: 1.71365

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15862
Policy Update Magnitude: 0.09230
Value Function Update Magnitude: 0.09644

Collected Steps per Second: 13241.98513
Overall Steps per Second: 2476.13418

Timestep Collection Time: 3.77859
Timestep Consumption Time: 16.42872
PPO Batch Consumption Time: 2.41490
Total Iteration Time: 20.20731

Cumulative Model Updates: 11132
Cumulative Timesteps: 93164132

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1456.73360
Policy Entropy: -0.29527
Value Function Loss: 1.68944

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.07977
Value Function Update Magnitude: 0.09157

Collected Steps per Second: 13576.18352
Overall Steps per Second: 2477.18580

Timestep Collection Time: 3.68498
Timestep Consumption Time: 16.51052
PPO Batch Consumption Time: 2.42944
Total Iteration Time: 20.19550

Cumulative Model Updates: 11138
Cumulative Timesteps: 93214160

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1321.15739
Policy Entropy: -0.29521
Value Function Loss: 1.69010

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13465
Policy Update Magnitude: 0.08524
Value Function Update Magnitude: 0.09264

Collected Steps per Second: 13610.53883
Overall Steps per Second: 2486.63603

Timestep Collection Time: 3.67583
Timestep Consumption Time: 16.44372
PPO Batch Consumption Time: 2.45034
Total Iteration Time: 20.11955

Cumulative Model Updates: 11144
Cumulative Timesteps: 93264190

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1567.11034
Policy Entropy: -0.29083
Value Function Loss: 1.65956

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13452
Policy Update Magnitude: 0.07381
Value Function Update Magnitude: 0.09277

Collected Steps per Second: 12657.86282
Overall Steps per Second: 2473.46889

Timestep Collection Time: 3.95011
Timestep Consumption Time: 16.26441
PPO Batch Consumption Time: 2.40842
Total Iteration Time: 20.21453

Cumulative Model Updates: 11150
Cumulative Timesteps: 93314190

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1270.02466
Policy Entropy: -0.29374
Value Function Loss: 1.67874

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.07398
Value Function Update Magnitude: 0.10047

Collected Steps per Second: 12672.81052
Overall Steps per Second: 2489.44621

Timestep Collection Time: 3.95082
Timestep Consumption Time: 16.16128
PPO Batch Consumption Time: 2.37374
Total Iteration Time: 20.11210

Cumulative Model Updates: 11156
Cumulative Timesteps: 93364258

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2523.38771
Policy Entropy: -0.29372
Value Function Loss: 1.65169

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.16666
Policy Update Magnitude: 0.07109
Value Function Update Magnitude: 0.09211

Collected Steps per Second: 13240.93701
Overall Steps per Second: 2561.21663

Timestep Collection Time: 3.77632
Timestep Consumption Time: 15.74643
PPO Batch Consumption Time: 2.31330
Total Iteration Time: 19.52275

Cumulative Model Updates: 11162
Cumulative Timesteps: 93414260

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2270.88390
Policy Entropy: -0.29608
Value Function Loss: 1.67613

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14257
Policy Update Magnitude: 0.06202
Value Function Update Magnitude: 0.09230

Collected Steps per Second: 12640.76851
Overall Steps per Second: 2587.29493

Timestep Collection Time: 3.95941
Timestep Consumption Time: 15.38512
PPO Batch Consumption Time: 2.27370
Total Iteration Time: 19.34453

Cumulative Model Updates: 11168
Cumulative Timesteps: 93464310

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3197.01235
Policy Entropy: -0.29553
Value Function Loss: 1.63175

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.06026
Value Function Update Magnitude: 0.13080

Collected Steps per Second: 12288.97569
Overall Steps per Second: 2591.62186

Timestep Collection Time: 4.06966
Timestep Consumption Time: 15.22790
PPO Batch Consumption Time: 2.27253
Total Iteration Time: 19.29757

Cumulative Model Updates: 11174
Cumulative Timesteps: 93514322

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2908.94615
Policy Entropy: -0.29567
Value Function Loss: 1.67689

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13013
Policy Update Magnitude: 0.06061
Value Function Update Magnitude: 0.11819

Collected Steps per Second: 14290.53065
Overall Steps per Second: 2600.25277

Timestep Collection Time: 3.50204
Timestep Consumption Time: 15.74455
PPO Batch Consumption Time: 2.28446
Total Iteration Time: 19.24659

Cumulative Model Updates: 11180
Cumulative Timesteps: 93564368

Timesteps Collected: 50046
--------END ITERATION REPORT--------


Saving checkpoint 93564368...
Checkpoint 93564368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2206.51419
Policy Entropy: -0.29525
Value Function Loss: 1.67015

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12227
Policy Update Magnitude: 0.06016
Value Function Update Magnitude: 0.10364

Collected Steps per Second: 12815.91163
Overall Steps per Second: 2512.01098

Timestep Collection Time: 3.90202
Timestep Consumption Time: 16.00553
PPO Batch Consumption Time: 2.39685
Total Iteration Time: 19.90756

Cumulative Model Updates: 11186
Cumulative Timesteps: 93614376

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1131.69724
Policy Entropy: -0.29636
Value Function Loss: 1.69919

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12289
Policy Update Magnitude: 0.06370
Value Function Update Magnitude: 0.09730

Collected Steps per Second: 13646.02802
Overall Steps per Second: 2486.98953

Timestep Collection Time: 3.66627
Timestep Consumption Time: 16.45042
PPO Batch Consumption Time: 2.41058
Total Iteration Time: 20.11669

Cumulative Model Updates: 11192
Cumulative Timesteps: 93664406

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2228.23905
Policy Entropy: -0.29669
Value Function Loss: 1.74560

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.06537
Value Function Update Magnitude: 0.10792

Collected Steps per Second: 15420.55422
Overall Steps per Second: 2597.39189

Timestep Collection Time: 3.24359
Timestep Consumption Time: 16.01342
PPO Batch Consumption Time: 2.39248
Total Iteration Time: 19.25701

Cumulative Model Updates: 11198
Cumulative Timesteps: 93714424

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 907.91085
Policy Entropy: -0.29611
Value Function Loss: 1.68218

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.06684
Value Function Update Magnitude: 0.10575

Collected Steps per Second: 16270.62244
Overall Steps per Second: 2593.26027

Timestep Collection Time: 3.07438
Timestep Consumption Time: 16.21486
PPO Batch Consumption Time: 2.37448
Total Iteration Time: 19.28923

Cumulative Model Updates: 11204
Cumulative Timesteps: 93764446

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1735.79806
Policy Entropy: -0.29514
Value Function Loss: 1.74426

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13456
Policy Update Magnitude: 0.06488
Value Function Update Magnitude: 0.11401

Collected Steps per Second: 12668.18338
Overall Steps per Second: 2529.19750

Timestep Collection Time: 3.95021
Timestep Consumption Time: 15.83551
PPO Batch Consumption Time: 2.33953
Total Iteration Time: 19.78572

Cumulative Model Updates: 11210
Cumulative Timesteps: 93814488

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1293.67062
Policy Entropy: -0.29312
Value Function Loss: 1.72030

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.06187
Value Function Update Magnitude: 0.10853

Collected Steps per Second: 13136.07564
Overall Steps per Second: 2584.98652

Timestep Collection Time: 3.80951
Timestep Consumption Time: 15.54920
PPO Batch Consumption Time: 2.27955
Total Iteration Time: 19.35871

Cumulative Model Updates: 11216
Cumulative Timesteps: 93864530

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1344.28057
Policy Entropy: -0.29033
Value Function Loss: 1.77202

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14885
Policy Update Magnitude: 0.06294
Value Function Update Magnitude: 0.10139

Collected Steps per Second: 12278.76404
Overall Steps per Second: 2526.45503

Timestep Collection Time: 4.07468
Timestep Consumption Time: 15.72856
PPO Batch Consumption Time: 2.29987
Total Iteration Time: 19.80324

Cumulative Model Updates: 11222
Cumulative Timesteps: 93914562

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1625.71916
Policy Entropy: -0.28983
Value Function Loss: 1.70044

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.15180
Policy Update Magnitude: 0.06249
Value Function Update Magnitude: 0.11628

Collected Steps per Second: 13223.73260
Overall Steps per Second: 2560.83095

Timestep Collection Time: 3.78123
Timestep Consumption Time: 15.74446
PPO Batch Consumption Time: 2.33611
Total Iteration Time: 19.52569

Cumulative Model Updates: 11228
Cumulative Timesteps: 93964564

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1853.12208
Policy Entropy: -0.28738
Value Function Loss: 1.70650

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14740
Policy Update Magnitude: 0.06416
Value Function Update Magnitude: 0.12291

Collected Steps per Second: 13083.94422
Overall Steps per Second: 2493.25868

Timestep Collection Time: 3.82622
Timestep Consumption Time: 16.25273
PPO Batch Consumption Time: 2.38338
Total Iteration Time: 20.07894

Cumulative Model Updates: 11234
Cumulative Timesteps: 94014626

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1046.05798
Policy Entropy: -0.28751
Value Function Loss: 1.70210

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.13922
Policy Update Magnitude: 0.06154
Value Function Update Magnitude: 0.12708

Collected Steps per Second: 12736.31606
Overall Steps per Second: 2481.06192

Timestep Collection Time: 3.92971
Timestep Consumption Time: 16.24311
PPO Batch Consumption Time: 2.39826
Total Iteration Time: 20.17281

Cumulative Model Updates: 11240
Cumulative Timesteps: 94064676

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 94064676...
Checkpoint 94064676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911.06749
Policy Entropy: -0.28262
Value Function Loss: 1.73866

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.15008
Policy Update Magnitude: 0.06157
Value Function Update Magnitude: 0.10498

Collected Steps per Second: 13585.83329
Overall Steps per Second: 2515.73218

Timestep Collection Time: 3.68340
Timestep Consumption Time: 16.20823
PPO Batch Consumption Time: 2.38515
Total Iteration Time: 19.89162

Cumulative Model Updates: 11246
Cumulative Timesteps: 94114718

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2490.46713
Policy Entropy: -0.28070
Value Function Loss: 1.71058

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14669
Policy Update Magnitude: 0.06308
Value Function Update Magnitude: 0.10137

Collected Steps per Second: 16109.55003
Overall Steps per Second: 2602.70343

Timestep Collection Time: 3.10685
Timestep Consumption Time: 16.12315
PPO Batch Consumption Time: 2.37193
Total Iteration Time: 19.23000

Cumulative Model Updates: 11252
Cumulative Timesteps: 94164768

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1995.87605
Policy Entropy: -0.28034
Value Function Loss: 1.72767

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.15287
Policy Update Magnitude: 0.06233
Value Function Update Magnitude: 0.10702

Collected Steps per Second: 12436.26441
Overall Steps per Second: 2502.69582

Timestep Collection Time: 4.02179
Timestep Consumption Time: 15.96306
PPO Batch Consumption Time: 2.38232
Total Iteration Time: 19.98485

Cumulative Model Updates: 11258
Cumulative Timesteps: 94214784

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1077.16897
Policy Entropy: -0.28224
Value Function Loss: 1.67578

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.14815
Policy Update Magnitude: 0.05817
Value Function Update Magnitude: 0.10902

Collected Steps per Second: 12671.77331
Overall Steps per Second: 791.59160

Timestep Collection Time: 3.94925
Timestep Consumption Time: 59.27022
PPO Batch Consumption Time: 2.45026
Total Iteration Time: 63.21947

Cumulative Model Updates: 11264
Cumulative Timesteps: 94264828

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 948.69968
Policy Entropy: -0.27851
Value Function Loss: 1.66200

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.15063
Policy Update Magnitude: 0.05975
Value Function Update Magnitude: 0.12555

Collected Steps per Second: 15041.29542
Overall Steps per Second: 2584.95647

Timestep Collection Time: 3.32458
Timestep Consumption Time: 16.02043
PPO Batch Consumption Time: 2.35196
Total Iteration Time: 19.34501

Cumulative Model Updates: 11270
Cumulative Timesteps: 94314834

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2254.92212
Policy Entropy: -0.27917
Value Function Loss: 1.66848

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13690
Policy Update Magnitude: 0.06309
Value Function Update Magnitude: 0.10914

Collected Steps per Second: 13389.49998
Overall Steps per Second: 933.63807

Timestep Collection Time: 3.73531
Timestep Consumption Time: 49.83362
PPO Batch Consumption Time: 2.43439
Total Iteration Time: 53.56894

Cumulative Model Updates: 11276
Cumulative Timesteps: 94364848

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2018.98245
Policy Entropy: -0.27714
Value Function Loss: 1.70320

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13475
Policy Update Magnitude: 0.06148
Value Function Update Magnitude: 0.09575

Collected Steps per Second: 12507.43841
Overall Steps per Second: 2473.71270

Timestep Collection Time: 3.99890
Timestep Consumption Time: 16.22010
PPO Batch Consumption Time: 2.38730
Total Iteration Time: 20.21900

Cumulative Model Updates: 11282
Cumulative Timesteps: 94414864

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1306.39559
Policy Entropy: -0.27706
Value Function Loss: 1.69943

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.05915
Value Function Update Magnitude: 0.09710

Collected Steps per Second: 13497.95434
Overall Steps per Second: 2457.06508

Timestep Collection Time: 3.70530
Timestep Consumption Time: 16.64988
PPO Batch Consumption Time: 2.45659
Total Iteration Time: 20.35518

Cumulative Model Updates: 11288
Cumulative Timesteps: 94464878

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2152.05340
Policy Entropy: -0.27591
Value Function Loss: 1.67411

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13705
Policy Update Magnitude: 0.06074
Value Function Update Magnitude: 0.09395

Collected Steps per Second: 12420.00791
Overall Steps per Second: 2437.91858

Timestep Collection Time: 4.03108
Timestep Consumption Time: 16.50529
PPO Batch Consumption Time: 2.44280
Total Iteration Time: 20.53637

Cumulative Model Updates: 11294
Cumulative Timesteps: 94514944

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1133.60134
Policy Entropy: -0.27716
Value Function Loss: 1.66701

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.06394
Value Function Update Magnitude: 0.09994

Collected Steps per Second: 12629.73783
Overall Steps per Second: 2498.72569

Timestep Collection Time: 3.96160
Timestep Consumption Time: 16.06220
PPO Batch Consumption Time: 2.40513
Total Iteration Time: 20.02381

Cumulative Model Updates: 11300
Cumulative Timesteps: 94564978

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 94564978...
Checkpoint 94564978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730.52227
Policy Entropy: -0.27329
Value Function Loss: 1.73220

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.06466
Value Function Update Magnitude: 0.11611

Collected Steps per Second: 12402.87282
Overall Steps per Second: 2415.61117

Timestep Collection Time: 4.04052
Timestep Consumption Time: 16.70537
PPO Batch Consumption Time: 2.45073
Total Iteration Time: 20.74589

Cumulative Model Updates: 11306
Cumulative Timesteps: 94615092

Timesteps Collected: 50114
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1535.71113
Policy Entropy: -0.27327
Value Function Loss: 1.69396

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14571
Policy Update Magnitude: 0.06354
Value Function Update Magnitude: 0.10456

Collected Steps per Second: 12272.76813
Overall Steps per Second: 2462.49382

Timestep Collection Time: 4.07732
Timestep Consumption Time: 16.24354
PPO Batch Consumption Time: 2.39902
Total Iteration Time: 20.32086

Cumulative Model Updates: 11312
Cumulative Timesteps: 94665132

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1712.90469
Policy Entropy: -0.26902
Value Function Loss: 1.74679

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.15444
Policy Update Magnitude: 0.06105
Value Function Update Magnitude: 0.09683

Collected Steps per Second: 13254.87846
Overall Steps per Second: 2484.95480

Timestep Collection Time: 3.77280
Timestep Consumption Time: 16.35151
PPO Batch Consumption Time: 2.40864
Total Iteration Time: 20.12431

Cumulative Model Updates: 11318
Cumulative Timesteps: 94715140

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3173.20357
Policy Entropy: -0.26695
Value Function Loss: 1.71349

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14810
Policy Update Magnitude: 0.06104
Value Function Update Magnitude: 0.09018

Collected Steps per Second: 12585.96396
Overall Steps per Second: 2485.11112

Timestep Collection Time: 3.97872
Timestep Consumption Time: 16.17169
PPO Batch Consumption Time: 2.39130
Total Iteration Time: 20.15041

Cumulative Model Updates: 11324
Cumulative Timesteps: 94765216

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 916.21045
Policy Entropy: -0.26631
Value Function Loss: 1.73966

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13991
Policy Update Magnitude: 0.06251
Value Function Update Magnitude: 0.09462

Collected Steps per Second: 13278.66085
Overall Steps per Second: 2457.42626

Timestep Collection Time: 3.76981
Timestep Consumption Time: 16.60028
PPO Batch Consumption Time: 2.45032
Total Iteration Time: 20.37009

Cumulative Model Updates: 11330
Cumulative Timesteps: 94815274

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2071.73449
Policy Entropy: -0.26677
Value Function Loss: 1.63988

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.06142
Value Function Update Magnitude: 0.10257

Collected Steps per Second: 12412.00875
Overall Steps per Second: 2424.43612

Timestep Collection Time: 4.03142
Timestep Consumption Time: 16.60761
PPO Batch Consumption Time: 2.45534
Total Iteration Time: 20.63903

Cumulative Model Updates: 11336
Cumulative Timesteps: 94865312

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2074.78304
Policy Entropy: -0.26781
Value Function Loss: 1.61749

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14626
Policy Update Magnitude: 0.06499
Value Function Update Magnitude: 0.11422

Collected Steps per Second: 12493.05568
Overall Steps per Second: 275.51211

Timestep Collection Time: 4.00607
Timestep Consumption Time: 177.64838
PPO Batch Consumption Time: 2.38174
Total Iteration Time: 181.65445

Cumulative Model Updates: 11342
Cumulative Timesteps: 94915360

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1163.92231
Policy Entropy: -0.26758
Value Function Loss: 1.55491

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.06943
Value Function Update Magnitude: 0.09582

Collected Steps per Second: 12613.04092
Overall Steps per Second: 2474.37733

Timestep Collection Time: 3.96415
Timestep Consumption Time: 16.24295
PPO Batch Consumption Time: 2.39037
Total Iteration Time: 20.20710

Cumulative Model Updates: 11348
Cumulative Timesteps: 94965360

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1483.25376
Policy Entropy: -0.26584
Value Function Loss: 1.58424

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.15258
Policy Update Magnitude: 0.06837
Value Function Update Magnitude: 0.08804

Collected Steps per Second: 12415.74674
Overall Steps per Second: 784.83240

Timestep Collection Time: 4.02779
Timestep Consumption Time: 59.69027
PPO Batch Consumption Time: 2.42281
Total Iteration Time: 63.71806

Cumulative Model Updates: 11354
Cumulative Timesteps: 95015368

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3162.30128
Policy Entropy: -0.26260
Value Function Loss: 1.54347

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.07178
Value Function Update Magnitude: 0.08593

Collected Steps per Second: 13470.65254
Overall Steps per Second: 2471.59613

Timestep Collection Time: 3.71548
Timestep Consumption Time: 16.53459
PPO Batch Consumption Time: 2.43887
Total Iteration Time: 20.25007

Cumulative Model Updates: 11360
Cumulative Timesteps: 95065418

Timesteps Collected: 50050
--------END ITERATION REPORT--------


Saving checkpoint 95065418...
Checkpoint 95065418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1834.61243
Policy Entropy: -0.26229
Value Function Loss: 1.55748

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.06218
Value Function Update Magnitude: 0.08557

Collected Steps per Second: 12379.73812
Overall Steps per Second: 757.64808

Timestep Collection Time: 4.03886
Timestep Consumption Time: 61.95484
PPO Batch Consumption Time: 2.41070
Total Iteration Time: 65.99370

Cumulative Model Updates: 11366
Cumulative Timesteps: 95115418

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3070.69699
Policy Entropy: -0.26196
Value Function Loss: 1.57335

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14666
Policy Update Magnitude: 0.06019
Value Function Update Magnitude: 0.08966

Collected Steps per Second: 12423.27052
Overall Steps per Second: 1184.76762

Timestep Collection Time: 4.02503
Timestep Consumption Time: 38.18072
PPO Batch Consumption Time: 2.44198
Total Iteration Time: 42.20575

Cumulative Model Updates: 11372
Cumulative Timesteps: 95165422

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 867.98999
Policy Entropy: -0.26174
Value Function Loss: 1.61091

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.15667
Policy Update Magnitude: 0.06179
Value Function Update Magnitude: 0.10891

Collected Steps per Second: 12611.99139
Overall Steps per Second: 2484.54612

Timestep Collection Time: 3.97098
Timestep Consumption Time: 16.18642
PPO Batch Consumption Time: 2.38209
Total Iteration Time: 20.15740

Cumulative Model Updates: 11378
Cumulative Timesteps: 95215504

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2060.94773
Policy Entropy: -0.25915
Value Function Loss: 1.60078

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.15047
Policy Update Magnitude: 0.06557
Value Function Update Magnitude: 0.13781

Collected Steps per Second: 12286.27154
Overall Steps per Second: 1703.29872

Timestep Collection Time: 4.07121
Timestep Consumption Time: 25.29534
PPO Batch Consumption Time: 2.42289
Total Iteration Time: 29.36655

Cumulative Model Updates: 11384
Cumulative Timesteps: 95265524

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1229.06653
Policy Entropy: -0.25651
Value Function Loss: 1.56188

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14434
Policy Update Magnitude: 0.06425
Value Function Update Magnitude: 0.15447

Collected Steps per Second: 12459.75815
Overall Steps per Second: 1600.07604

Timestep Collection Time: 4.01324
Timestep Consumption Time: 27.23777
PPO Batch Consumption Time: 2.37697
Total Iteration Time: 31.25101

Cumulative Model Updates: 11390
Cumulative Timesteps: 95315528

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1700.52999
Policy Entropy: -0.25538
Value Function Loss: 1.54277

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.13848
Policy Update Magnitude: 0.06612
Value Function Update Magnitude: 0.16213

Collected Steps per Second: 12528.55861
Overall Steps per Second: 2457.33997

Timestep Collection Time: 3.99232
Timestep Consumption Time: 16.36221
PPO Batch Consumption Time: 2.41817
Total Iteration Time: 20.35453

Cumulative Model Updates: 11396
Cumulative Timesteps: 95365546

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2866.92646
Policy Entropy: -0.25369
Value Function Loss: 1.57546

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.06578
Value Function Update Magnitude: 0.13976

Collected Steps per Second: 13232.79521
Overall Steps per Second: 2508.47812

Timestep Collection Time: 3.77849
Timestep Consumption Time: 16.15391
PPO Batch Consumption Time: 2.38148
Total Iteration Time: 19.93240

Cumulative Model Updates: 11402
Cumulative Timesteps: 95415546

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1192.34561
Policy Entropy: -0.25172
Value Function Loss: 1.60089

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14341
Policy Update Magnitude: 0.06602
Value Function Update Magnitude: 0.10452

Collected Steps per Second: 12374.69429
Overall Steps per Second: 2479.86055

Timestep Collection Time: 4.04309
Timestep Consumption Time: 16.13224
PPO Batch Consumption Time: 2.38047
Total Iteration Time: 20.17533

Cumulative Model Updates: 11408
Cumulative Timesteps: 95465578

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1556.77213
Policy Entropy: -0.24833
Value Function Loss: 1.56630

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14738
Policy Update Magnitude: 0.06212
Value Function Update Magnitude: 0.10462

Collected Steps per Second: 13247.09623
Overall Steps per Second: 2497.14065

Timestep Collection Time: 3.77607
Timestep Consumption Time: 16.25564
PPO Batch Consumption Time: 2.38696
Total Iteration Time: 20.03171

Cumulative Model Updates: 11414
Cumulative Timesteps: 95515600

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1225.67509
Policy Entropy: -0.24538
Value Function Loss: 1.50734

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14400
Policy Update Magnitude: 0.06751
Value Function Update Magnitude: 0.09918

Collected Steps per Second: 12559.33731
Overall Steps per Second: 2450.72415

Timestep Collection Time: 3.98158
Timestep Consumption Time: 16.42300
PPO Batch Consumption Time: 2.42963
Total Iteration Time: 20.40458

Cumulative Model Updates: 11420
Cumulative Timesteps: 95565606

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 95565606...
Checkpoint 95565606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2075.97556
Policy Entropy: -0.24592
Value Function Loss: 1.50258

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.16637
Policy Update Magnitude: 0.07407
Value Function Update Magnitude: 0.08850

Collected Steps per Second: 12485.85724
Overall Steps per Second: 2035.86624

Timestep Collection Time: 4.01190
Timestep Consumption Time: 20.59286
PPO Batch Consumption Time: 2.32670
Total Iteration Time: 24.60476

Cumulative Model Updates: 11426
Cumulative Timesteps: 95615698

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1985.66162
Policy Entropy: -0.24623
Value Function Loss: 1.56928

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.17151
Policy Update Magnitude: 0.06472
Value Function Update Magnitude: 0.09957

Collected Steps per Second: 12562.49971
Overall Steps per Second: 2513.46778

Timestep Collection Time: 3.98328
Timestep Consumption Time: 15.92547
PPO Batch Consumption Time: 2.34082
Total Iteration Time: 19.90875

Cumulative Model Updates: 11432
Cumulative Timesteps: 95665738

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1605.09916
Policy Entropy: -0.24662
Value Function Loss: 1.61761

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.15677
Policy Update Magnitude: 0.06225
Value Function Update Magnitude: 0.13398

Collected Steps per Second: 12373.36064
Overall Steps per Second: 2539.87809

Timestep Collection Time: 4.04320
Timestep Consumption Time: 15.65381
PPO Batch Consumption Time: 2.33709
Total Iteration Time: 19.69701

Cumulative Model Updates: 11438
Cumulative Timesteps: 95715766

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 942.59834
Policy Entropy: -0.24685
Value Function Loss: 1.61455

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.25984
Policy Update Magnitude: 0.06733
Value Function Update Magnitude: 0.10940

Collected Steps per Second: 12789.41371
Overall Steps per Second: 1765.68145

Timestep Collection Time: 3.91277
Timestep Consumption Time: 24.42870
PPO Batch Consumption Time: 2.47079
Total Iteration Time: 28.34147

Cumulative Model Updates: 11444
Cumulative Timesteps: 95765808

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1893.26165
Policy Entropy: -0.24373
Value Function Loss: 1.55991

Mean KL Divergence: 0.01506
SB3 Clip Fraction: 0.19680
Policy Update Magnitude: 0.05370
Value Function Update Magnitude: 0.10174

Collected Steps per Second: 12490.42417
Overall Steps per Second: 2412.18290

Timestep Collection Time: 4.00739
Timestep Consumption Time: 16.74311
PPO Batch Consumption Time: 2.47499
Total Iteration Time: 20.75050

Cumulative Model Updates: 11450
Cumulative Timesteps: 95815862

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2120.34866
Policy Entropy: -0.24152
Value Function Loss: 1.62545

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.06195
Value Function Update Magnitude: 0.09505

Collected Steps per Second: 13056.85493
Overall Steps per Second: 2180.48706

Timestep Collection Time: 3.83354
Timestep Consumption Time: 19.12188
PPO Batch Consumption Time: 2.42917
Total Iteration Time: 22.95542

Cumulative Model Updates: 11456
Cumulative Timesteps: 95865916

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1638.74027
Policy Entropy: -0.23993
Value Function Loss: 1.58129

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.17087
Policy Update Magnitude: 0.06401
Value Function Update Magnitude: 0.10758

Collected Steps per Second: 13136.68154
Overall Steps per Second: 2486.50148

Timestep Collection Time: 3.80796
Timestep Consumption Time: 16.31026
PPO Batch Consumption Time: 2.40990
Total Iteration Time: 20.11823

Cumulative Model Updates: 11462
Cumulative Timesteps: 95915940

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2477.95382
Policy Entropy: -0.23682
Value Function Loss: 1.58410

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.16934
Policy Update Magnitude: 0.06109
Value Function Update Magnitude: 0.12068

Collected Steps per Second: 13015.90360
Overall Steps per Second: 2432.35823

Timestep Collection Time: 3.84207
Timestep Consumption Time: 16.71740
PPO Batch Consumption Time: 2.35620
Total Iteration Time: 20.55947

Cumulative Model Updates: 11468
Cumulative Timesteps: 95965948

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2665.36971
Policy Entropy: -0.23524
Value Function Loss: 1.48490

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.17534
Policy Update Magnitude: 0.05823
Value Function Update Magnitude: 0.12181

Collected Steps per Second: 12826.66334
Overall Steps per Second: 2486.30892

Timestep Collection Time: 3.89844
Timestep Consumption Time: 16.21330
PPO Batch Consumption Time: 2.38902
Total Iteration Time: 20.11174

Cumulative Model Updates: 11474
Cumulative Timesteps: 96015952

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2993.21243
Policy Entropy: -0.23392
Value Function Loss: 1.52091

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.17346
Policy Update Magnitude: 0.05887
Value Function Update Magnitude: 0.09841

Collected Steps per Second: 12602.03847
Overall Steps per Second: 2487.21343

Timestep Collection Time: 3.97253
Timestep Consumption Time: 16.15521
PPO Batch Consumption Time: 2.41649
Total Iteration Time: 20.12775

Cumulative Model Updates: 11480
Cumulative Timesteps: 96066014

Timesteps Collected: 50062
--------END ITERATION REPORT--------


Saving checkpoint 96066014...
Checkpoint 96066014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2152.43449
Policy Entropy: -0.23353
Value Function Loss: 1.56796

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.17658
Policy Update Magnitude: 0.06400
Value Function Update Magnitude: 0.08292

Collected Steps per Second: 12384.74772
Overall Steps per Second: 1019.20432

Timestep Collection Time: 4.04062
Timestep Consumption Time: 45.05847
PPO Batch Consumption Time: 2.34557
Total Iteration Time: 49.09909

Cumulative Model Updates: 11486
Cumulative Timesteps: 96116056

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1787.16859
Policy Entropy: -0.23507
Value Function Loss: 1.57746

Mean KL Divergence: 0.04270
SB3 Clip Fraction: 0.36177
Policy Update Magnitude: 0.06777
Value Function Update Magnitude: 0.10276

Collected Steps per Second: 12291.39519
Overall Steps per Second: 2531.30916

Timestep Collection Time: 4.06789
Timestep Consumption Time: 15.68474
PPO Batch Consumption Time: 2.33753
Total Iteration Time: 19.75262

Cumulative Model Updates: 11492
Cumulative Timesteps: 96166056

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 950.71786
Policy Entropy: -0.23141
Value Function Loss: 1.56631

Mean KL Divergence: 0.02091
SB3 Clip Fraction: 0.25913
Policy Update Magnitude: 0.05814
Value Function Update Magnitude: 0.11947

Collected Steps per Second: 12599.82792
Overall Steps per Second: 2524.78238

Timestep Collection Time: 3.96894
Timestep Consumption Time: 15.83791
PPO Batch Consumption Time: 2.32767
Total Iteration Time: 19.80686

Cumulative Model Updates: 11498
Cumulative Timesteps: 96216064

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1615.31638
Policy Entropy: -0.23012
Value Function Loss: 1.48995

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.19871
Policy Update Magnitude: 0.06300
Value Function Update Magnitude: 0.11886

Collected Steps per Second: 12600.39349
Overall Steps per Second: 2487.60451

Timestep Collection Time: 3.96829
Timestep Consumption Time: 16.13217
PPO Batch Consumption Time: 2.41618
Total Iteration Time: 20.10046

Cumulative Model Updates: 11504
Cumulative Timesteps: 96266066

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1467.08849
Policy Entropy: -0.23031
Value Function Loss: 1.52530

Mean KL Divergence: 0.02242
SB3 Clip Fraction: 0.27345
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.10326

Collected Steps per Second: 12583.72318
Overall Steps per Second: 1393.45973

Timestep Collection Time: 3.97672
Timestep Consumption Time: 31.93533
PPO Batch Consumption Time: 2.31649
Total Iteration Time: 35.91205

Cumulative Model Updates: 11510
Cumulative Timesteps: 96316108

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1439.25243
Policy Entropy: -0.23130
Value Function Loss: 1.52249

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.18156
Policy Update Magnitude: 0.05956
Value Function Update Magnitude: 0.08876

Collected Steps per Second: 12626.03387
Overall Steps per Second: 2523.33840

Timestep Collection Time: 3.96197
Timestep Consumption Time: 15.86256
PPO Batch Consumption Time: 2.33124
Total Iteration Time: 19.82453

Cumulative Model Updates: 11516
Cumulative Timesteps: 96366132

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1868.03164
Policy Entropy: -0.23054
Value Function Loss: 1.66772

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14432
Policy Update Magnitude: 0.06139
Value Function Update Magnitude: 0.08420

Collected Steps per Second: 13279.67117
Overall Steps per Second: 343.60394

Timestep Collection Time: 3.76741
Timestep Consumption Time: 141.83627
PPO Batch Consumption Time: 2.35505
Total Iteration Time: 145.60369

Cumulative Model Updates: 11522
Cumulative Timesteps: 96416162

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1032.92188
Policy Entropy: -0.22821
Value Function Loss: 1.61584

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.06274
Value Function Update Magnitude: 0.09603

Collected Steps per Second: 12787.67337
Overall Steps per Second: 2462.14662

Timestep Collection Time: 3.91017
Timestep Consumption Time: 16.39812
PPO Batch Consumption Time: 2.41380
Total Iteration Time: 20.30830

Cumulative Model Updates: 11528
Cumulative Timesteps: 96466164

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2561.81872
Policy Entropy: -0.22586
Value Function Loss: 1.62187

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.06890
Value Function Update Magnitude: 0.10630

Collected Steps per Second: 12803.04325
Overall Steps per Second: 2488.00579

Timestep Collection Time: 3.90532
Timestep Consumption Time: 16.19109
PPO Batch Consumption Time: 2.42582
Total Iteration Time: 20.09642

Cumulative Model Updates: 11534
Cumulative Timesteps: 96516164

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934.78576
Policy Entropy: -0.22659
Value Function Loss: 1.55981

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14611
Policy Update Magnitude: 0.06269
Value Function Update Magnitude: 0.10003

Collected Steps per Second: 13687.00112
Overall Steps per Second: 2475.32888

Timestep Collection Time: 3.65588
Timestep Consumption Time: 16.55881
PPO Batch Consumption Time: 2.44197
Total Iteration Time: 20.21469

Cumulative Model Updates: 11540
Cumulative Timesteps: 96566202

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 96566202...
Checkpoint 96566202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1229.48069
Policy Entropy: -0.22546
Value Function Loss: 1.62627

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.06442
Value Function Update Magnitude: 0.09474

Collected Steps per Second: 13110.35761
Overall Steps per Second: 2500.45975

Timestep Collection Time: 3.81927
Timestep Consumption Time: 16.20585
PPO Batch Consumption Time: 2.40589
Total Iteration Time: 20.02512

Cumulative Model Updates: 11546
Cumulative Timesteps: 96616274

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1608.38348
Policy Entropy: -0.22478
Value Function Loss: 1.56313

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.07535
Value Function Update Magnitude: 0.09691

Collected Steps per Second: 13704.06890
Overall Steps per Second: 2546.48221

Timestep Collection Time: 3.65045
Timestep Consumption Time: 15.99469
PPO Batch Consumption Time: 2.36825
Total Iteration Time: 19.64514

Cumulative Model Updates: 11552
Cumulative Timesteps: 96666300

Timesteps Collected: 50026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2437.85779
Policy Entropy: -0.22439
Value Function Loss: 1.49927

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.07020
Value Function Update Magnitude: 0.10183

Collected Steps per Second: 12139.64435
Overall Steps per Second: 2510.77627

Timestep Collection Time: 4.12351
Timestep Consumption Time: 15.81375
PPO Batch Consumption Time: 2.32876
Total Iteration Time: 19.93726

Cumulative Model Updates: 11558
Cumulative Timesteps: 96716358

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2389.74703
Policy Entropy: -0.22969
Value Function Loss: 1.40094

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.15370
Policy Update Magnitude: 0.06641
Value Function Update Magnitude: 0.09199

Collected Steps per Second: 13280.89572
Overall Steps per Second: 2541.07984

Timestep Collection Time: 3.77173
Timestep Consumption Time: 15.94115
PPO Batch Consumption Time: 2.35365
Total Iteration Time: 19.71288

Cumulative Model Updates: 11564
Cumulative Timesteps: 96766450

Timesteps Collected: 50092
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3798.60079
Policy Entropy: -0.23252
Value Function Loss: 1.43097

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.15061
Policy Update Magnitude: 0.06450
Value Function Update Magnitude: 0.09046

Collected Steps per Second: 12472.25426
Overall Steps per Second: 2563.70367

Timestep Collection Time: 4.01162
Timestep Consumption Time: 15.50467
PPO Batch Consumption Time: 2.27651
Total Iteration Time: 19.51630

Cumulative Model Updates: 11570
Cumulative Timesteps: 96816484

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2922.25560
Policy Entropy: -0.23367
Value Function Loss: 1.46055

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.05853
Value Function Update Magnitude: 0.10561

Collected Steps per Second: 16471.92028
Overall Steps per Second: 2637.41471

Timestep Collection Time: 3.03899
Timestep Consumption Time: 15.94096
PPO Batch Consumption Time: 2.34624
Total Iteration Time: 18.97995

Cumulative Model Updates: 11576
Cumulative Timesteps: 96866542

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1258.70736
Policy Entropy: -0.23169
Value Function Loss: 1.48056

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.06418
Value Function Update Magnitude: 0.11348

Collected Steps per Second: 14680.96343
Overall Steps per Second: 2593.98586

Timestep Collection Time: 3.40768
Timestep Consumption Time: 15.87847
PPO Batch Consumption Time: 2.32523
Total Iteration Time: 19.28615

Cumulative Model Updates: 11582
Cumulative Timesteps: 96916570

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1823.98402
Policy Entropy: -0.23123
Value Function Loss: 1.56089

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14517
Policy Update Magnitude: 0.06206
Value Function Update Magnitude: 0.11460

Collected Steps per Second: 14743.26397
Overall Steps per Second: 2545.42259

Timestep Collection Time: 3.39219
Timestep Consumption Time: 16.25562
PPO Batch Consumption Time: 2.42644
Total Iteration Time: 19.64782

Cumulative Model Updates: 11588
Cumulative Timesteps: 96966582

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1685.71845
Policy Entropy: -0.23048
Value Function Loss: 1.57293

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.07297
Value Function Update Magnitude: 0.10353

Collected Steps per Second: 13243.23529
Overall Steps per Second: 2470.29458

Timestep Collection Time: 3.77597
Timestep Consumption Time: 16.46696
PPO Batch Consumption Time: 2.41516
Total Iteration Time: 20.24293

Cumulative Model Updates: 11594
Cumulative Timesteps: 97016588

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2532.43986
Policy Entropy: -0.23454
Value Function Loss: 1.54669

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14658
Policy Update Magnitude: 0.06921
Value Function Update Magnitude: 0.08916

Collected Steps per Second: 12580.44294
Overall Steps per Second: 2466.47163

Timestep Collection Time: 3.97713
Timestep Consumption Time: 16.30853
PPO Batch Consumption Time: 2.44762
Total Iteration Time: 20.28566

Cumulative Model Updates: 11600
Cumulative Timesteps: 97066622

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 97066622...
Checkpoint 97066622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2784.81787
Policy Entropy: -0.23533
Value Function Loss: 1.49270

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.15112
Policy Update Magnitude: 0.06117
Value Function Update Magnitude: 0.08519

Collected Steps per Second: 12436.78836
Overall Steps per Second: 2433.66695

Timestep Collection Time: 4.02789
Timestep Consumption Time: 16.55586
PPO Batch Consumption Time: 2.44431
Total Iteration Time: 20.58375

Cumulative Model Updates: 11606
Cumulative Timesteps: 97116716

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1896.57088
Policy Entropy: -0.23495
Value Function Loss: 1.48526

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.19232
Policy Update Magnitude: 0.07264
Value Function Update Magnitude: 0.08705

Collected Steps per Second: 12468.70142
Overall Steps per Second: 874.23303

Timestep Collection Time: 4.01132
Timestep Consumption Time: 53.19997
PPO Batch Consumption Time: 2.43673
Total Iteration Time: 57.21129

Cumulative Model Updates: 11612
Cumulative Timesteps: 97166732

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1981.33623
Policy Entropy: -0.23164
Value Function Loss: 1.52609

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.19681
Policy Update Magnitude: 0.06874
Value Function Update Magnitude: 0.11943

Collected Steps per Second: 13136.51430
Overall Steps per Second: 2507.48649

Timestep Collection Time: 3.80801
Timestep Consumption Time: 16.14185
PPO Batch Consumption Time: 2.37120
Total Iteration Time: 19.94986

Cumulative Model Updates: 11618
Cumulative Timesteps: 97216756

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3637.31377
Policy Entropy: -0.22951
Value Function Loss: 1.51698

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.06172
Value Function Update Magnitude: 0.12487

Collected Steps per Second: 12364.82318
Overall Steps per Second: 2462.90695

Timestep Collection Time: 4.04858
Timestep Consumption Time: 16.27699
PPO Batch Consumption Time: 2.40566
Total Iteration Time: 20.32558

Cumulative Model Updates: 11624
Cumulative Timesteps: 97266816

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1961.56837
Policy Entropy: -0.23168
Value Function Loss: 1.54435

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.06969
Value Function Update Magnitude: 0.10851

Collected Steps per Second: 13093.33275
Overall Steps per Second: 2476.75886

Timestep Collection Time: 3.82699
Timestep Consumption Time: 16.40429
PPO Batch Consumption Time: 2.41928
Total Iteration Time: 20.23128

Cumulative Model Updates: 11630
Cumulative Timesteps: 97316924

Timesteps Collected: 50108
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2810.55449
Policy Entropy: -0.23085
Value Function Loss: 1.55308

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.06998
Value Function Update Magnitude: 0.09562

Collected Steps per Second: 12527.50218
Overall Steps per Second: 2495.83780

Timestep Collection Time: 3.99537
Timestep Consumption Time: 16.05882
PPO Batch Consumption Time: 2.36621
Total Iteration Time: 20.05419

Cumulative Model Updates: 11636
Cumulative Timesteps: 97366976

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1558.48494
Policy Entropy: -0.22601
Value Function Loss: 1.57027

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14898
Policy Update Magnitude: 0.07367
Value Function Update Magnitude: 0.09518

Collected Steps per Second: 12761.22379
Overall Steps per Second: 2548.80293

Timestep Collection Time: 3.92313
Timestep Consumption Time: 15.71903
PPO Batch Consumption Time: 2.34881
Total Iteration Time: 19.64216

Cumulative Model Updates: 11642
Cumulative Timesteps: 97417040

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1063.44004
Policy Entropy: -0.22363
Value Function Loss: 1.52531

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.06588
Value Function Update Magnitude: 0.11965

Collected Steps per Second: 12750.65152
Overall Steps per Second: 2434.52487

Timestep Collection Time: 3.92278
Timestep Consumption Time: 16.62250
PPO Batch Consumption Time: 2.46064
Total Iteration Time: 20.54528

Cumulative Model Updates: 11648
Cumulative Timesteps: 97467058

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2281.91534
Policy Entropy: -0.22197
Value Function Loss: 1.49765

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.07789
Value Function Update Magnitude: 0.11864

Collected Steps per Second: 12432.85472
Overall Steps per Second: 622.51565

Timestep Collection Time: 4.02482
Timestep Consumption Time: 76.35870
PPO Batch Consumption Time: 2.29372
Total Iteration Time: 80.38352

Cumulative Model Updates: 11654
Cumulative Timesteps: 97517098

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2071.71252
Policy Entropy: -0.22015
Value Function Loss: 1.45253

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.16409
Policy Update Magnitude: 0.06844
Value Function Update Magnitude: 0.10331

Collected Steps per Second: 12557.40563
Overall Steps per Second: 2459.72596

Timestep Collection Time: 3.98601
Timestep Consumption Time: 16.36341
PPO Batch Consumption Time: 2.40698
Total Iteration Time: 20.34942

Cumulative Model Updates: 11660
Cumulative Timesteps: 97567152

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 97567152...
Checkpoint 97567152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2058.38299
Policy Entropy: -0.22033
Value Function Loss: 1.47128

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14597
Policy Update Magnitude: 0.05730
Value Function Update Magnitude: 0.08441

Collected Steps per Second: 12559.66717
Overall Steps per Second: 2476.64909

Timestep Collection Time: 3.98179
Timestep Consumption Time: 16.21081
PPO Batch Consumption Time: 2.39386
Total Iteration Time: 20.19261

Cumulative Model Updates: 11666
Cumulative Timesteps: 97617162

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1090.94936
Policy Entropy: -0.22025
Value Function Loss: 1.44550

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.05699
Value Function Update Magnitude: 0.07163

Collected Steps per Second: 13612.18690
Overall Steps per Second: 2546.83632

Timestep Collection Time: 3.67538
Timestep Consumption Time: 15.96860
PPO Batch Consumption Time: 2.36494
Total Iteration Time: 19.64398

Cumulative Model Updates: 11672
Cumulative Timesteps: 97667192

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3180.34806
Policy Entropy: -0.22315
Value Function Loss: 1.42872

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12990
Policy Update Magnitude: 0.06392
Value Function Update Magnitude: 0.06344

Collected Steps per Second: 12409.29956
Overall Steps per Second: 1210.79953

Timestep Collection Time: 4.03020
Timestep Consumption Time: 37.27474
PPO Batch Consumption Time: 2.40004
Total Iteration Time: 41.30494

Cumulative Model Updates: 11678
Cumulative Timesteps: 97717204

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1586.93127
Policy Entropy: -0.22366
Value Function Loss: 1.44967

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.06009
Value Function Update Magnitude: 0.06090

Collected Steps per Second: 12646.69160
Overall Steps per Second: 2478.49661

Timestep Collection Time: 3.95661
Timestep Consumption Time: 16.23224
PPO Batch Consumption Time: 2.43070
Total Iteration Time: 20.18885

Cumulative Model Updates: 11684
Cumulative Timesteps: 97767242

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1336.27053
Policy Entropy: -0.22601
Value Function Loss: 1.46694

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14923
Policy Update Magnitude: 0.05507
Value Function Update Magnitude: 0.05868

Collected Steps per Second: 12609.26257
Overall Steps per Second: 2461.81476

Timestep Collection Time: 3.96883
Timestep Consumption Time: 16.35926
PPO Batch Consumption Time: 2.41113
Total Iteration Time: 20.32809

Cumulative Model Updates: 11690
Cumulative Timesteps: 97817286

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2104.36734
Policy Entropy: -0.22753
Value Function Loss: 1.45613

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14683
Policy Update Magnitude: 0.05515
Value Function Update Magnitude: 0.06623

Collected Steps per Second: 12442.36479
Overall Steps per Second: 2444.24052

Timestep Collection Time: 4.02046
Timestep Consumption Time: 16.44561
PPO Batch Consumption Time: 2.46287
Total Iteration Time: 20.46607

Cumulative Model Updates: 11696
Cumulative Timesteps: 97867310

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2088.41505
Policy Entropy: -0.23088
Value Function Loss: 1.46707

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.05236
Value Function Update Magnitude: 0.06545

Collected Steps per Second: 12546.04326
Overall Steps per Second: 2438.53379

Timestep Collection Time: 3.98755
Timestep Consumption Time: 16.52805
PPO Batch Consumption Time: 2.43789
Total Iteration Time: 20.51561

Cumulative Model Updates: 11702
Cumulative Timesteps: 97917338

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1597.73954
Policy Entropy: -0.23206
Value Function Loss: 1.45347

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.05127
Value Function Update Magnitude: 0.08010

Collected Steps per Second: 12380.02341
Overall Steps per Second: 2486.30788

Timestep Collection Time: 4.04038
Timestep Consumption Time: 16.07780
PPO Batch Consumption Time: 2.35157
Total Iteration Time: 20.11818

Cumulative Model Updates: 11708
Cumulative Timesteps: 97967358

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2352.07657
Policy Entropy: -0.23590
Value Function Loss: 1.41406

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.15515
Policy Update Magnitude: 0.05936
Value Function Update Magnitude: 0.08287

Collected Steps per Second: 13527.45411
Overall Steps per Second: 2476.28050

Timestep Collection Time: 3.70417
Timestep Consumption Time: 16.53102
PPO Batch Consumption Time: 2.44314
Total Iteration Time: 20.23519

Cumulative Model Updates: 11714
Cumulative Timesteps: 98017466

Timesteps Collected: 50108
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1650.55866
Policy Entropy: -0.24008
Value Function Loss: 1.40318

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.15229
Policy Update Magnitude: 0.05961
Value Function Update Magnitude: 0.07182

Collected Steps per Second: 12524.46472
Overall Steps per Second: 2446.92002

Timestep Collection Time: 3.99330
Timestep Consumption Time: 16.44627
PPO Batch Consumption Time: 2.42480
Total Iteration Time: 20.43957

Cumulative Model Updates: 11720
Cumulative Timesteps: 98067480

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 98067480...
Checkpoint 98067480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1535.70853
Policy Entropy: -0.24342
Value Function Loss: 1.34231

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.15693
Policy Update Magnitude: 0.05496
Value Function Update Magnitude: 0.06545

Collected Steps per Second: 13286.49717
Overall Steps per Second: 2476.01647

Timestep Collection Time: 3.76969
Timestep Consumption Time: 16.45877
PPO Batch Consumption Time: 2.43323
Total Iteration Time: 20.22846

Cumulative Model Updates: 11726
Cumulative Timesteps: 98117566

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2359.96585
Policy Entropy: -0.24604
Value Function Loss: 1.37089

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14888
Policy Update Magnitude: 0.05609
Value Function Update Magnitude: 0.06952

Collected Steps per Second: 13125.02277
Overall Steps per Second: 2473.60777

Timestep Collection Time: 3.81058
Timestep Consumption Time: 16.40847
PPO Batch Consumption Time: 2.42769
Total Iteration Time: 20.21905

Cumulative Model Updates: 11732
Cumulative Timesteps: 98167580

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1176.57510
Policy Entropy: -0.25060
Value Function Loss: 1.34055

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14445
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.06850

Collected Steps per Second: 12695.04700
Overall Steps per Second: 443.37189

Timestep Collection Time: 3.94280
Timestep Consumption Time: 108.95114
PPO Batch Consumption Time: 2.42675
Total Iteration Time: 112.89394

Cumulative Model Updates: 11738
Cumulative Timesteps: 98217634

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1284.83802
Policy Entropy: -0.25358
Value Function Loss: 1.38877

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14977
Policy Update Magnitude: 0.05450
Value Function Update Magnitude: 0.06382

Collected Steps per Second: 12632.14532
Overall Steps per Second: 2499.65846

Timestep Collection Time: 3.95816
Timestep Consumption Time: 16.04458
PPO Batch Consumption Time: 2.35438
Total Iteration Time: 20.00273

Cumulative Model Updates: 11744
Cumulative Timesteps: 98267634

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2160.80502
Policy Entropy: -0.25899
Value Function Loss: 1.37459

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.16308
Policy Update Magnitude: 0.05445
Value Function Update Magnitude: 0.06432

Collected Steps per Second: 12602.78105
Overall Steps per Second: 503.83008

Timestep Collection Time: 3.96785
Timestep Consumption Time: 95.28386
PPO Batch Consumption Time: 2.41704
Total Iteration Time: 99.25172

Cumulative Model Updates: 11750
Cumulative Timesteps: 98317640

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2868.78312
Policy Entropy: -0.26413
Value Function Loss: 1.41547

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.16923
Policy Update Magnitude: 0.05530
Value Function Update Magnitude: 0.06027

Collected Steps per Second: 12545.66132
Overall Steps per Second: 2469.12574

Timestep Collection Time: 3.99086
Timestep Consumption Time: 16.28676
PPO Batch Consumption Time: 2.39373
Total Iteration Time: 20.27762

Cumulative Model Updates: 11756
Cumulative Timesteps: 98367708

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1065.78583
Policy Entropy: -0.26931
Value Function Loss: 1.45343

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.16650
Policy Update Magnitude: 0.06073
Value Function Update Magnitude: 0.06322

Collected Steps per Second: 12626.16203
Overall Steps per Second: 2466.30203

Timestep Collection Time: 3.96383
Timestep Consumption Time: 16.32890
PPO Batch Consumption Time: 2.40824
Total Iteration Time: 20.29273

Cumulative Model Updates: 11762
Cumulative Timesteps: 98417756

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1439.72718
Policy Entropy: -0.27459
Value Function Loss: 1.49656

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.17907
Policy Update Magnitude: 0.06511
Value Function Update Magnitude: 0.06249

Collected Steps per Second: 13064.33144
Overall Steps per Second: 2473.27329

Timestep Collection Time: 3.83058
Timestep Consumption Time: 16.40333
PPO Batch Consumption Time: 2.41966
Total Iteration Time: 20.23391

Cumulative Model Updates: 11768
Cumulative Timesteps: 98467800

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1612.36496
Policy Entropy: -0.28173
Value Function Loss: 1.43344

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.17970
Policy Update Magnitude: 0.06284
Value Function Update Magnitude: 0.06720

Collected Steps per Second: 12526.54485
Overall Steps per Second: 1327.53418

Timestep Collection Time: 3.99599
Timestep Consumption Time: 33.71000
PPO Batch Consumption Time: 2.34851
Total Iteration Time: 37.70600

Cumulative Model Updates: 11774
Cumulative Timesteps: 98517856

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4209.98395
Policy Entropy: -0.28700
Value Function Loss: 1.39300

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.15504
Policy Update Magnitude: 0.06484
Value Function Update Magnitude: 0.06612

Collected Steps per Second: 12117.29540
Overall Steps per Second: 2514.26467

Timestep Collection Time: 4.13079
Timestep Consumption Time: 15.77722
PPO Batch Consumption Time: 2.36120
Total Iteration Time: 19.90801

Cumulative Model Updates: 11780
Cumulative Timesteps: 98567910

Timesteps Collected: 50054
--------END ITERATION REPORT--------


Saving checkpoint 98567910...
Checkpoint 98567910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2135.98509
Policy Entropy: -0.29193
Value Function Loss: 1.38450

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.17803
Policy Update Magnitude: 0.06144
Value Function Update Magnitude: 0.05995

Collected Steps per Second: 12833.63774
Overall Steps per Second: 1911.26667

Timestep Collection Time: 3.89944
Timestep Consumption Time: 22.28424
PPO Batch Consumption Time: 2.44929
Total Iteration Time: 26.18368

Cumulative Model Updates: 11786
Cumulative Timesteps: 98617954

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2302.47747
Policy Entropy: -0.29815
Value Function Loss: 1.46490

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.20048
Policy Update Magnitude: 0.06836
Value Function Update Magnitude: 0.05730

Collected Steps per Second: 12537.41734
Overall Steps per Second: 2527.49013

Timestep Collection Time: 3.99253
Timestep Consumption Time: 15.81210
PPO Batch Consumption Time: 2.32193
Total Iteration Time: 19.80463

Cumulative Model Updates: 11792
Cumulative Timesteps: 98668010

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3584.86050
Policy Entropy: -0.30584
Value Function Loss: 1.46299

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.19846
Policy Update Magnitude: 0.07497
Value Function Update Magnitude: 0.06089

Collected Steps per Second: 13046.91892
Overall Steps per Second: 614.45309

Timestep Collection Time: 3.83294
Timestep Consumption Time: 77.55326
PPO Batch Consumption Time: 2.34020
Total Iteration Time: 81.38620

Cumulative Model Updates: 11798
Cumulative Timesteps: 98718018

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2311.20949
Policy Entropy: -0.31365
Value Function Loss: 1.45500

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.18154
Policy Update Magnitude: 0.07557
Value Function Update Magnitude: 0.05580

Collected Steps per Second: 12456.22472
Overall Steps per Second: 1039.89517

Timestep Collection Time: 4.02080
Timestep Consumption Time: 44.14175
PPO Batch Consumption Time: 3.91794
Total Iteration Time: 48.16255

Cumulative Model Updates: 11804
Cumulative Timesteps: 98768102

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1904.62547
Policy Entropy: -0.31877
Value Function Loss: 1.44532

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.19754
Policy Update Magnitude: 0.06930
Value Function Update Magnitude: 0.05421

Collected Steps per Second: 13123.91673
Overall Steps per Second: 659.71638

Timestep Collection Time: 3.81091
Timestep Consumption Time: 72.00046
PPO Batch Consumption Time: 2.37010
Total Iteration Time: 75.81137

Cumulative Model Updates: 11810
Cumulative Timesteps: 98818116

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2102.62281
Policy Entropy: -0.32180
Value Function Loss: 1.40826

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.18026
Policy Update Magnitude: 0.06400
Value Function Update Magnitude: 0.05709

Collected Steps per Second: 12852.51229
Overall Steps per Second: 2485.43517

Timestep Collection Time: 3.89262
Timestep Consumption Time: 16.23665
PPO Batch Consumption Time: 2.40121
Total Iteration Time: 20.12927

Cumulative Model Updates: 11816
Cumulative Timesteps: 98868146

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1287.72669
Policy Entropy: -0.32854
Value Function Loss: 1.34654

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.17681
Policy Update Magnitude: 0.05467
Value Function Update Magnitude: 0.05996

Collected Steps per Second: 12350.97028
Overall Steps per Second: 2474.75114

Timestep Collection Time: 4.05134
Timestep Consumption Time: 16.16807
PPO Batch Consumption Time: 2.42345
Total Iteration Time: 20.21941

Cumulative Model Updates: 11822
Cumulative Timesteps: 98918184

Timesteps Collected: 50038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1601.97965
Policy Entropy: -0.33539
Value Function Loss: 1.29302

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.18181
Policy Update Magnitude: 0.05999
Value Function Update Magnitude: 0.05648

Collected Steps per Second: 12499.27297
Overall Steps per Second: 2457.44477

Timestep Collection Time: 4.00615
Timestep Consumption Time: 16.37030
PPO Batch Consumption Time: 2.40950
Total Iteration Time: 20.37645

Cumulative Model Updates: 11828
Cumulative Timesteps: 98968258

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1972.32708
Policy Entropy: -0.34399
Value Function Loss: 1.31901

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.24830
Policy Update Magnitude: 0.06165
Value Function Update Magnitude: 0.05773

Collected Steps per Second: 12592.30021
Overall Steps per Second: 2559.78180

Timestep Collection Time: 3.97608
Timestep Consumption Time: 15.58340
PPO Batch Consumption Time: 2.32855
Total Iteration Time: 19.55948

Cumulative Model Updates: 11834
Cumulative Timesteps: 99018326

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2331.13490
Policy Entropy: -0.34590
Value Function Loss: 1.34355

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.16009
Policy Update Magnitude: 0.05479
Value Function Update Magnitude: 0.05733

Collected Steps per Second: 12659.41434
Overall Steps per Second: 2466.63586

Timestep Collection Time: 3.95295
Timestep Consumption Time: 16.33460
PPO Batch Consumption Time: 2.40893
Total Iteration Time: 20.28755

Cumulative Model Updates: 11840
Cumulative Timesteps: 99068368

Timesteps Collected: 50042
--------END ITERATION REPORT--------


Saving checkpoint 99068368...
Checkpoint 99068368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3230.07689
Policy Entropy: -0.35108
Value Function Loss: 1.32966

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.17071
Policy Update Magnitude: 0.05655
Value Function Update Magnitude: 0.06267

Collected Steps per Second: 12371.67694
Overall Steps per Second: 2465.68829

Timestep Collection Time: 4.04505
Timestep Consumption Time: 16.25111
PPO Batch Consumption Time: 2.39885
Total Iteration Time: 20.29616

Cumulative Model Updates: 11846
Cumulative Timesteps: 99118412

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2048.20193
Policy Entropy: -0.35509
Value Function Loss: 1.35573

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14587
Policy Update Magnitude: 0.06657
Value Function Update Magnitude: 0.06667

Collected Steps per Second: 13049.79935
Overall Steps per Second: 2455.27064

Timestep Collection Time: 3.83316
Timestep Consumption Time: 16.54015
PPO Batch Consumption Time: 2.44253
Total Iteration Time: 20.37331

Cumulative Model Updates: 11852
Cumulative Timesteps: 99168434

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3214.86534
Policy Entropy: -0.35789
Value Function Loss: 1.36416

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.16104
Policy Update Magnitude: 0.06428
Value Function Update Magnitude: 0.06232

Collected Steps per Second: 12611.52495
Overall Steps per Second: 2431.53388

Timestep Collection Time: 3.96510
Timestep Consumption Time: 16.60052
PPO Batch Consumption Time: 2.45886
Total Iteration Time: 20.56562

Cumulative Model Updates: 11858
Cumulative Timesteps: 99218440

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1717.97233
Policy Entropy: -0.36225
Value Function Loss: 1.36443

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.16596
Policy Update Magnitude: 0.06272
Value Function Update Magnitude: 0.05410

Collected Steps per Second: 12480.26826
Overall Steps per Second: 620.08206

Timestep Collection Time: 4.00632
Timestep Consumption Time: 76.62816
PPO Batch Consumption Time: 2.37669
Total Iteration Time: 80.63449

Cumulative Model Updates: 11864
Cumulative Timesteps: 99268440

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1506.57566
Policy Entropy: -0.36892
Value Function Loss: 1.30428

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.17724
Policy Update Magnitude: 0.07847
Value Function Update Magnitude: 0.05346

Collected Steps per Second: 12690.28991
Overall Steps per Second: 2461.18692

Timestep Collection Time: 3.94506
Timestep Consumption Time: 16.39634
PPO Batch Consumption Time: 2.41621
Total Iteration Time: 20.34141

Cumulative Model Updates: 11870
Cumulative Timesteps: 99318504

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2726.45357
Policy Entropy: -0.37285
Value Function Loss: 1.32608

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.14033
Policy Update Magnitude: 0.07511
Value Function Update Magnitude: 0.05252

Collected Steps per Second: 12665.89003
Overall Steps per Second: 2432.59489

Timestep Collection Time: 3.95345
Timestep Consumption Time: 16.63115
PPO Batch Consumption Time: 2.41040
Total Iteration Time: 20.58460

Cumulative Model Updates: 11876
Cumulative Timesteps: 99368578

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2509.89327
Policy Entropy: -0.37753
Value Function Loss: 1.30387

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.20567
Policy Update Magnitude: 0.07375
Value Function Update Magnitude: 0.05247

Collected Steps per Second: 13634.96928
Overall Steps per Second: 2495.69460

Timestep Collection Time: 3.66748
Timestep Consumption Time: 16.36943
PPO Batch Consumption Time: 2.40906
Total Iteration Time: 20.03691

Cumulative Model Updates: 11882
Cumulative Timesteps: 99418584

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1734.91839
Policy Entropy: -0.38467
Value Function Loss: 1.31321

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.15812
Policy Update Magnitude: 0.06795
Value Function Update Magnitude: 0.05535

Collected Steps per Second: 12711.72330
Overall Steps per Second: 2312.28092

Timestep Collection Time: 3.93464
Timestep Consumption Time: 17.69595
PPO Batch Consumption Time: 2.45649
Total Iteration Time: 21.63059

Cumulative Model Updates: 11888
Cumulative Timesteps: 99468600

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4833.12908
Policy Entropy: -0.38976
Value Function Loss: 1.23588

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.17747
Policy Update Magnitude: 0.06304
Value Function Update Magnitude: 0.05368

Collected Steps per Second: 12558.46911
Overall Steps per Second: 2459.81673

Timestep Collection Time: 3.98886
Timestep Consumption Time: 16.37607
PPO Batch Consumption Time: 2.44942
Total Iteration Time: 20.36493

Cumulative Model Updates: 11894
Cumulative Timesteps: 99518694

Timesteps Collected: 50094
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2553.19687
Policy Entropy: -0.39450
Value Function Loss: 1.25036

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.16064
Policy Update Magnitude: 0.06267
Value Function Update Magnitude: 0.05479

Collected Steps per Second: 12747.71333
Overall Steps per Second: 2462.22139

Timestep Collection Time: 3.92745
Timestep Consumption Time: 16.40622
PPO Batch Consumption Time: 2.41242
Total Iteration Time: 20.33367

Cumulative Model Updates: 11900
Cumulative Timesteps: 99568760

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 99568760...
Checkpoint 99568760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1357.33248
Policy Entropy: -0.39762
Value Function Loss: 1.23831

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12556
Policy Update Magnitude: 0.06797
Value Function Update Magnitude: 0.05776

Collected Steps per Second: 12338.27629
Overall Steps per Second: 1924.95993

Timestep Collection Time: 4.05275
Timestep Consumption Time: 21.92389
PPO Batch Consumption Time: 2.39849
Total Iteration Time: 25.97664

Cumulative Model Updates: 11906
Cumulative Timesteps: 99618764

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1707.05333
Policy Entropy: -0.40094
Value Function Loss: 1.29368

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13894
Policy Update Magnitude: 0.08162
Value Function Update Magnitude: 0.05681

Collected Steps per Second: 12604.43959
Overall Steps per Second: 2393.30132

Timestep Collection Time: 3.97352
Timestep Consumption Time: 16.95322
PPO Batch Consumption Time: 2.49778
Total Iteration Time: 20.92674

Cumulative Model Updates: 11912
Cumulative Timesteps: 99668848

Timesteps Collected: 50084
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1694.73187
Policy Entropy: -0.40791
Value Function Loss: 1.30785

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14350
Policy Update Magnitude: 0.08479
Value Function Update Magnitude: 0.06045

Collected Steps per Second: 12514.61038
Overall Steps per Second: 2464.56860

Timestep Collection Time: 3.99805
Timestep Consumption Time: 16.30327
PPO Batch Consumption Time: 2.44080
Total Iteration Time: 20.30132

Cumulative Model Updates: 11918
Cumulative Timesteps: 99718882

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2319.80733
Policy Entropy: -0.41396
Value Function Loss: 1.33064

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.16700
Policy Update Magnitude: 0.08303
Value Function Update Magnitude: 0.06036

Collected Steps per Second: 12498.22471
Overall Steps per Second: 2490.12281

Timestep Collection Time: 4.00105
Timestep Consumption Time: 16.08069
PPO Batch Consumption Time: 2.38070
Total Iteration Time: 20.08174

Cumulative Model Updates: 11924
Cumulative Timesteps: 99768888

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1426.58965
Policy Entropy: -0.41747
Value Function Loss: 1.31188

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15952
Policy Update Magnitude: 0.06468
Value Function Update Magnitude: 0.06337

Collected Steps per Second: 14184.65947
Overall Steps per Second: 2504.07944

Timestep Collection Time: 3.52959
Timestep Consumption Time: 16.46419
PPO Batch Consumption Time: 2.42043
Total Iteration Time: 19.99377

Cumulative Model Updates: 11930
Cumulative Timesteps: 99818954

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2387.27770
Policy Entropy: -0.41999
Value Function Loss: 1.31758

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.17080
Policy Update Magnitude: 0.06282
Value Function Update Magnitude: 0.06083

Collected Steps per Second: 13488.91347
Overall Steps per Second: 2471.17550

Timestep Collection Time: 3.70779
Timestep Consumption Time: 16.53117
PPO Batch Consumption Time: 2.41000
Total Iteration Time: 20.23895

Cumulative Model Updates: 11936
Cumulative Timesteps: 99868968

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2554.08571
Policy Entropy: -0.42436
Value Function Loss: 1.27098

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.16759
Policy Update Magnitude: 0.07716
Value Function Update Magnitude: 0.05818

Collected Steps per Second: 12814.48546
Overall Steps per Second: 2443.66971

Timestep Collection Time: 3.90636
Timestep Consumption Time: 16.57840
PPO Batch Consumption Time: 2.40431
Total Iteration Time: 20.48477

Cumulative Model Updates: 11942
Cumulative Timesteps: 99919026

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1641.41559
Policy Entropy: -0.42892
Value Function Loss: 1.27623

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.07360
Value Function Update Magnitude: 0.05785

Collected Steps per Second: 14864.71293
Overall Steps per Second: 2484.92921

Timestep Collection Time: 3.36407
Timestep Consumption Time: 16.75964
PPO Batch Consumption Time: 2.44598
Total Iteration Time: 20.12371

Cumulative Model Updates: 11948
Cumulative Timesteps: 99969032

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1675.67817
Policy Entropy: -0.43825
Value Function Loss: 1.18923

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.17672
Policy Update Magnitude: 0.08003
Value Function Update Magnitude: 0.05627

Collected Steps per Second: 12865.48800
Overall Steps per Second: 2475.21311

Timestep Collection Time: 3.89010
Timestep Consumption Time: 16.32958
PPO Batch Consumption Time: 2.40586
Total Iteration Time: 20.21967

Cumulative Model Updates: 11954
Cumulative Timesteps: 100019080

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1948.49821
Policy Entropy: -0.43921
Value Function Loss: 1.20667

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.18580
Policy Update Magnitude: 0.08160
Value Function Update Magnitude: 0.05657

Collected Steps per Second: 12541.32790
Overall Steps per Second: 2540.02282

Timestep Collection Time: 3.98825
Timestep Consumption Time: 15.70370
PPO Batch Consumption Time: 2.35399
Total Iteration Time: 19.69195

Cumulative Model Updates: 11960
Cumulative Timesteps: 100069098

Timesteps Collected: 50018
--------END ITERATION REPORT--------


Saving checkpoint 100069098...
Checkpoint 100069098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1886.42817
Policy Entropy: -0.44110
Value Function Loss: 1.25764

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.18004
Policy Update Magnitude: 0.06806
Value Function Update Magnitude: 0.05875

Collected Steps per Second: 12845.41681
Overall Steps per Second: 2524.50453

Timestep Collection Time: 3.89758
Timestep Consumption Time: 15.93443
PPO Batch Consumption Time: 2.33587
Total Iteration Time: 19.83201

Cumulative Model Updates: 11966
Cumulative Timesteps: 100119164

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1941.01323
Policy Entropy: -0.44599
Value Function Loss: 1.31968

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.06374
Value Function Update Magnitude: 0.06136

Collected Steps per Second: 12313.81765
Overall Steps per Second: 2556.43938

Timestep Collection Time: 4.06633
Timestep Consumption Time: 15.52029
PPO Batch Consumption Time: 2.32697
Total Iteration Time: 19.58662

Cumulative Model Updates: 11972
Cumulative Timesteps: 100169236

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2435.51509
Policy Entropy: -0.44877
Value Function Loss: 1.32664

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.16999
Policy Update Magnitude: 0.06469
Value Function Update Magnitude: 0.06377

Collected Steps per Second: 16515.97607
Overall Steps per Second: 2551.53304

Timestep Collection Time: 3.03040
Timestep Consumption Time: 16.58526
PPO Batch Consumption Time: 2.43253
Total Iteration Time: 19.61566

Cumulative Model Updates: 11978
Cumulative Timesteps: 100219286

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1815.60079
Policy Entropy: -0.45414
Value Function Loss: 1.30172

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15417
Policy Update Magnitude: 0.06582
Value Function Update Magnitude: 0.06432

Collected Steps per Second: 15816.32891
Overall Steps per Second: 2612.39292

Timestep Collection Time: 3.16281
Timestep Consumption Time: 15.98592
PPO Batch Consumption Time: 2.37747
Total Iteration Time: 19.14873

Cumulative Model Updates: 11984
Cumulative Timesteps: 100269310

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1770.52024
Policy Entropy: -0.45708
Value Function Loss: 1.26917

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.17162
Policy Update Magnitude: 0.06415
Value Function Update Magnitude: 0.06034

Collected Steps per Second: 12939.12333
Overall Steps per Second: 2440.81788

Timestep Collection Time: 3.87059
Timestep Consumption Time: 16.64795
PPO Batch Consumption Time: 2.44708
Total Iteration Time: 20.51853

Cumulative Model Updates: 11990
Cumulative Timesteps: 100319392

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3576.66758
Policy Entropy: -0.45910
Value Function Loss: 1.23561

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.17174
Policy Update Magnitude: 0.06373
Value Function Update Magnitude: 0.06034

Collected Steps per Second: 12950.49092
Overall Steps per Second: 2482.50908

Timestep Collection Time: 3.86580
Timestep Consumption Time: 16.30089
PPO Batch Consumption Time: 2.39089
Total Iteration Time: 20.16669

Cumulative Model Updates: 11996
Cumulative Timesteps: 100369456

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1017.60689
Policy Entropy: -0.46275
Value Function Loss: 1.20396

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.16517
Policy Update Magnitude: 0.06727
Value Function Update Magnitude: 0.05751

Collected Steps per Second: 13183.29873
Overall Steps per Second: 2493.24915

Timestep Collection Time: 3.79708
Timestep Consumption Time: 16.28034
PPO Batch Consumption Time: 2.41228
Total Iteration Time: 20.07742

Cumulative Model Updates: 12002
Cumulative Timesteps: 100419514

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2205.64070
Policy Entropy: -0.46699
Value Function Loss: 1.23896

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.16198
Policy Update Magnitude: 0.06648
Value Function Update Magnitude: 0.05495

Collected Steps per Second: 12615.49657
Overall Steps per Second: 2553.04949

Timestep Collection Time: 3.96782
Timestep Consumption Time: 15.63854
PPO Batch Consumption Time: 2.31099
Total Iteration Time: 19.60636

Cumulative Model Updates: 12008
Cumulative Timesteps: 100469570

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2232.65374
Policy Entropy: -0.47204
Value Function Loss: 1.27333

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.15538
Policy Update Magnitude: 0.06535
Value Function Update Magnitude: 0.05826

Collected Steps per Second: 12354.73285
Overall Steps per Second: 2546.69693

Timestep Collection Time: 4.04962
Timestep Consumption Time: 15.59622
PPO Batch Consumption Time: 2.32672
Total Iteration Time: 19.64584

Cumulative Model Updates: 12014
Cumulative Timesteps: 100519602

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3577.15763
Policy Entropy: -0.47871
Value Function Loss: 1.25676

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.16000
Policy Update Magnitude: 0.06369
Value Function Update Magnitude: 0.05690

Collected Steps per Second: 12544.41258
Overall Steps per Second: 2550.66074

Timestep Collection Time: 3.99046
Timestep Consumption Time: 15.63504
PPO Batch Consumption Time: 2.30365
Total Iteration Time: 19.62550

Cumulative Model Updates: 12020
Cumulative Timesteps: 100569660

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 100569660...
Checkpoint 100569660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2260.84627
Policy Entropy: -0.48190
Value Function Loss: 1.22710

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.15587
Policy Update Magnitude: 0.06870
Value Function Update Magnitude: 0.05264

Collected Steps per Second: 14413.30052
Overall Steps per Second: 2657.05178

Timestep Collection Time: 3.46930
Timestep Consumption Time: 15.35006
PPO Batch Consumption Time: 2.26030
Total Iteration Time: 18.81935

Cumulative Model Updates: 12026
Cumulative Timesteps: 100619664

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2409.53301
Policy Entropy: -0.48690
Value Function Loss: 1.22715

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15425
Policy Update Magnitude: 0.06933
Value Function Update Magnitude: 0.05207

Collected Steps per Second: 17856.23206
Overall Steps per Second: 2700.41495

Timestep Collection Time: 2.80149
Timestep Consumption Time: 15.72307
PPO Batch Consumption Time: 2.30983
Total Iteration Time: 18.52456

Cumulative Model Updates: 12032
Cumulative Timesteps: 100669688

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2933.00808
Policy Entropy: -0.48748
Value Function Loss: 1.26874

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.15133
Policy Update Magnitude: 0.07136
Value Function Update Magnitude: 0.05395

Collected Steps per Second: 13670.43153
Overall Steps per Second: 2529.99967

Timestep Collection Time: 3.66119
Timestep Consumption Time: 16.12142
PPO Batch Consumption Time: 2.37638
Total Iteration Time: 19.78261

Cumulative Model Updates: 12038
Cumulative Timesteps: 100719738

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1834.69276
Policy Entropy: -0.49039
Value Function Loss: 1.28092

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.15747
Policy Update Magnitude: 0.07556
Value Function Update Magnitude: 0.05414

Collected Steps per Second: 14121.33059
Overall Steps per Second: 2512.17841

Timestep Collection Time: 3.54924
Timestep Consumption Time: 16.40157
PPO Batch Consumption Time: 2.44321
Total Iteration Time: 19.95081

Cumulative Model Updates: 12044
Cumulative Timesteps: 100769858

Timesteps Collected: 50120
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1002.17858
Policy Entropy: -0.49099
Value Function Loss: 1.29249

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.17688
Policy Update Magnitude: 0.07351
Value Function Update Magnitude: 0.05652

Collected Steps per Second: 14049.31350
Overall Steps per Second: 2501.38528

Timestep Collection Time: 3.56430
Timestep Consumption Time: 16.45500
PPO Batch Consumption Time: 2.42658
Total Iteration Time: 20.01931

Cumulative Model Updates: 12050
Cumulative Timesteps: 100819934

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3457.52111
Policy Entropy: -0.49415
Value Function Loss: 1.25059

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.16434
Policy Update Magnitude: 0.07263
Value Function Update Magnitude: 0.05931

Collected Steps per Second: 12371.89494
Overall Steps per Second: 2449.08549

Timestep Collection Time: 4.04853
Timestep Consumption Time: 16.40318
PPO Batch Consumption Time: 2.45354
Total Iteration Time: 20.45172

Cumulative Model Updates: 12056
Cumulative Timesteps: 100870022

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1826.76046
Policy Entropy: -0.49648
Value Function Loss: 1.29198

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.16622
Policy Update Magnitude: 0.06725
Value Function Update Magnitude: 0.05915

Collected Steps per Second: 12636.79290
Overall Steps per Second: 490.19390

Timestep Collection Time: 3.96113
Timestep Consumption Time: 98.15356
PPO Batch Consumption Time: 2.36115
Total Iteration Time: 102.11469

Cumulative Model Updates: 12062
Cumulative Timesteps: 100920078

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2318.48719
Policy Entropy: -0.49644
Value Function Loss: 1.26782

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14792
Policy Update Magnitude: 0.06951
Value Function Update Magnitude: 0.05895

Collected Steps per Second: 12405.37030
Overall Steps per Second: 2545.34710

Timestep Collection Time: 4.03583
Timestep Consumption Time: 15.63378
PPO Batch Consumption Time: 2.31752
Total Iteration Time: 19.66962

Cumulative Model Updates: 12068
Cumulative Timesteps: 100970144

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1976.59419
Policy Entropy: -0.49768
Value Function Loss: 1.23852

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.07234
Value Function Update Magnitude: 0.05978

Collected Steps per Second: 12642.78386
Overall Steps per Second: 909.71944

Timestep Collection Time: 3.95925
Timestep Consumption Time: 51.06430
PPO Batch Consumption Time: 2.38487
Total Iteration Time: 55.02356

Cumulative Model Updates: 12074
Cumulative Timesteps: 101020200

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1618.29483
Policy Entropy: -0.50045
Value Function Loss: 1.23438

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14448
Policy Update Magnitude: 0.07499
Value Function Update Magnitude: 0.06517

Collected Steps per Second: 12396.91161
Overall Steps per Second: 2418.82644

Timestep Collection Time: 4.03649
Timestep Consumption Time: 16.65123
PPO Batch Consumption Time: 2.46076
Total Iteration Time: 20.68772

Cumulative Model Updates: 12080
Cumulative Timesteps: 101070240

Timesteps Collected: 50040
--------END ITERATION REPORT--------


Saving checkpoint 101070240...
Checkpoint 101070240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3279.02082
Policy Entropy: -0.50537
Value Function Loss: 1.21592

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.07132
Value Function Update Magnitude: 0.05764

Collected Steps per Second: 13263.54780
Overall Steps per Second: 2356.12603

Timestep Collection Time: 3.77003
Timestep Consumption Time: 17.45294
PPO Batch Consumption Time: 2.37739
Total Iteration Time: 21.22297

Cumulative Model Updates: 12086
Cumulative Timesteps: 101120244

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2026.43082
Policy Entropy: -0.50921
Value Function Loss: 1.24618

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.18529
Policy Update Magnitude: 0.07794
Value Function Update Magnitude: 0.05732

Collected Steps per Second: 12600.93445
Overall Steps per Second: 2450.85696

Timestep Collection Time: 3.97383
Timestep Consumption Time: 16.45739
PPO Batch Consumption Time: 2.42052
Total Iteration Time: 20.43122

Cumulative Model Updates: 12092
Cumulative Timesteps: 101170318

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1255.42967
Policy Entropy: -0.51207
Value Function Loss: 1.20661

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13982
Policy Update Magnitude: 0.07943
Value Function Update Magnitude: 0.05406

Collected Steps per Second: 13194.59689
Overall Steps per Second: 744.52168

Timestep Collection Time: 3.78973
Timestep Consumption Time: 63.37285
PPO Batch Consumption Time: 2.44927
Total Iteration Time: 67.16258

Cumulative Model Updates: 12098
Cumulative Timesteps: 101220322

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1630.71424
Policy Entropy: -0.51396
Value Function Loss: 1.21931

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.17709
Policy Update Magnitude: 0.07344
Value Function Update Magnitude: 0.06075

Collected Steps per Second: 12495.68572
Overall Steps per Second: 2460.06480

Timestep Collection Time: 4.00474
Timestep Consumption Time: 16.33700
PPO Batch Consumption Time: 2.39916
Total Iteration Time: 20.34174

Cumulative Model Updates: 12104
Cumulative Timesteps: 101270364

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2432.45235
Policy Entropy: -0.51597
Value Function Loss: 1.20305

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.23536
Policy Update Magnitude: 0.06990
Value Function Update Magnitude: 0.06054

Collected Steps per Second: 13155.11168
Overall Steps per Second: 2368.71784

Timestep Collection Time: 3.80202
Timestep Consumption Time: 17.31320
PPO Batch Consumption Time: 2.36207
Total Iteration Time: 21.11522

Cumulative Model Updates: 12110
Cumulative Timesteps: 101320380

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1850.12523
Policy Entropy: -0.51864
Value Function Loss: 1.23239

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.23866
Policy Update Magnitude: 0.05823
Value Function Update Magnitude: 0.06034

Collected Steps per Second: 12691.97658
Overall Steps per Second: 2434.44104

Timestep Collection Time: 3.94344
Timestep Consumption Time: 16.61570
PPO Batch Consumption Time: 2.44218
Total Iteration Time: 20.55913

Cumulative Model Updates: 12116
Cumulative Timesteps: 101370430

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2295.70741
Policy Entropy: -0.51917
Value Function Loss: 1.23382

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.16511
Policy Update Magnitude: 0.06012
Value Function Update Magnitude: 0.06164

Collected Steps per Second: 12660.77812
Overall Steps per Second: 400.25017

Timestep Collection Time: 3.95268
Timestep Consumption Time: 121.07912
PPO Batch Consumption Time: 2.39901
Total Iteration Time: 125.03180

Cumulative Model Updates: 12122
Cumulative Timesteps: 101420474

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4401.41334
Policy Entropy: -0.52188
Value Function Loss: 1.29368

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.17039
Policy Update Magnitude: 0.06051
Value Function Update Magnitude: 0.06739

Collected Steps per Second: 12646.39699
Overall Steps per Second: 2455.60305

Timestep Collection Time: 3.95385
Timestep Consumption Time: 16.40856
PPO Batch Consumption Time: 2.41392
Total Iteration Time: 20.36241

Cumulative Model Updates: 12128
Cumulative Timesteps: 101470476

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1979.05514
Policy Entropy: -0.52365
Value Function Loss: 1.28786

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.16113
Policy Update Magnitude: 0.06138
Value Function Update Magnitude: 0.06187

Collected Steps per Second: 12379.77647
Overall Steps per Second: 391.00026

Timestep Collection Time: 4.04353
Timestep Consumption Time: 123.98196
PPO Batch Consumption Time: 2.40507
Total Iteration Time: 128.02549

Cumulative Model Updates: 12134
Cumulative Timesteps: 101520534

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2747.49140
Policy Entropy: -0.52767
Value Function Loss: 1.32358

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.15734
Policy Update Magnitude: 0.06380
Value Function Update Magnitude: 0.06241

Collected Steps per Second: 13411.29092
Overall Steps per Second: 2539.33748

Timestep Collection Time: 3.73074
Timestep Consumption Time: 15.97283
PPO Batch Consumption Time: 2.34598
Total Iteration Time: 19.70356

Cumulative Model Updates: 12140
Cumulative Timesteps: 101570568

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 101570568...
Checkpoint 101570568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1322.21539
Policy Entropy: -0.52859
Value Function Loss: 1.26903

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.15324
Policy Update Magnitude: 0.06688
Value Function Update Magnitude: 0.06530

Collected Steps per Second: 12551.91353
Overall Steps per Second: 2482.91147

Timestep Collection Time: 3.98425
Timestep Consumption Time: 16.15742
PPO Batch Consumption Time: 2.38121
Total Iteration Time: 20.14168

Cumulative Model Updates: 12146
Cumulative Timesteps: 101620578

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1944.82712
Policy Entropy: -0.53057
Value Function Loss: 1.28167

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.16861
Policy Update Magnitude: 0.06854
Value Function Update Magnitude: 0.06547

Collected Steps per Second: 12610.34497
Overall Steps per Second: 1288.06638

Timestep Collection Time: 3.96500
Timestep Consumption Time: 34.85288
PPO Batch Consumption Time: 2.42808
Total Iteration Time: 38.81788

Cumulative Model Updates: 12152
Cumulative Timesteps: 101670578

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3867.42954
Policy Entropy: -0.52982
Value Function Loss: 1.26202

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.18665
Policy Update Magnitude: 0.07402
Value Function Update Magnitude: 0.06488

Collected Steps per Second: 12690.66747
Overall Steps per Second: 2451.45640

Timestep Collection Time: 3.94069
Timestep Consumption Time: 16.45943
PPO Batch Consumption Time: 2.41215
Total Iteration Time: 20.40012

Cumulative Model Updates: 12158
Cumulative Timesteps: 101720588

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1729.91048
Policy Entropy: -0.53353
Value Function Loss: 1.25232

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.15953
Policy Update Magnitude: 0.07414
Value Function Update Magnitude: 0.06360

Collected Steps per Second: 12724.16148
Overall Steps per Second: 1237.75537

Timestep Collection Time: 3.93472
Timestep Consumption Time: 36.51431
PPO Batch Consumption Time: 2.40808
Total Iteration Time: 40.44903

Cumulative Model Updates: 12164
Cumulative Timesteps: 101770654

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2327.38311
Policy Entropy: -0.53613
Value Function Loss: 1.20877

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.17517
Policy Update Magnitude: 0.09901
Value Function Update Magnitude: 0.06296

Collected Steps per Second: 15482.40091
Overall Steps per Second: 2431.38675

Timestep Collection Time: 3.23270
Timestep Consumption Time: 17.35226
PPO Batch Consumption Time: 2.55587
Total Iteration Time: 20.58496

Cumulative Model Updates: 12170
Cumulative Timesteps: 101820704

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2572.04750
Policy Entropy: -0.53789
Value Function Loss: 1.20190

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.16674
Policy Update Magnitude: 0.07956
Value Function Update Magnitude: 0.06158

Collected Steps per Second: 15078.33997
Overall Steps per Second: 2477.39936

Timestep Collection Time: 3.32145
Timestep Consumption Time: 16.89410
PPO Batch Consumption Time: 2.52349
Total Iteration Time: 20.21555

Cumulative Model Updates: 12176
Cumulative Timesteps: 101870786

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2595.53750
Policy Entropy: -0.53977
Value Function Loss: 1.20149

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.08370
Value Function Update Magnitude: 0.06362

Collected Steps per Second: 15211.45785
Overall Steps per Second: 2580.05641

Timestep Collection Time: 3.29475
Timestep Consumption Time: 16.13040
PPO Batch Consumption Time: 2.34815
Total Iteration Time: 19.42516

Cumulative Model Updates: 12182
Cumulative Timesteps: 101920904

Timesteps Collected: 50118
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1639.88424
Policy Entropy: -0.54153
Value Function Loss: 1.22072

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.22448
Policy Update Magnitude: 0.08634
Value Function Update Magnitude: 0.06473

Collected Steps per Second: 12976.50879
Overall Steps per Second: 2546.53925

Timestep Collection Time: 3.85404
Timestep Consumption Time: 15.78516
PPO Batch Consumption Time: 2.31437
Total Iteration Time: 19.63920

Cumulative Model Updates: 12188
Cumulative Timesteps: 101970916

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3026.55395
Policy Entropy: -0.53960
Value Function Loss: 1.17680

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.21248
Policy Update Magnitude: 0.06788
Value Function Update Magnitude: 0.06364

Collected Steps per Second: 13642.06144
Overall Steps per Second: 2622.35715

Timestep Collection Time: 3.67173
Timestep Consumption Time: 15.42940
PPO Batch Consumption Time: 2.26475
Total Iteration Time: 19.10114

Cumulative Model Updates: 12194
Cumulative Timesteps: 102021006

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2345.79423
Policy Entropy: -0.53926
Value Function Loss: 1.16780

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.16942
Policy Update Magnitude: 0.06589
Value Function Update Magnitude: 0.06350

Collected Steps per Second: 12442.66531
Overall Steps per Second: 2567.30780

Timestep Collection Time: 4.02550
Timestep Consumption Time: 15.48443
PPO Batch Consumption Time: 2.26881
Total Iteration Time: 19.50993

Cumulative Model Updates: 12200
Cumulative Timesteps: 102071094

Timesteps Collected: 50088
--------END ITERATION REPORT--------


Saving checkpoint 102071094...
Checkpoint 102071094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1901.89578
Policy Entropy: -0.53966
Value Function Loss: 1.15720

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.16999
Policy Update Magnitude: 0.06278
Value Function Update Magnitude: 0.06160

Collected Steps per Second: 12685.23144
Overall Steps per Second: 2573.56466

Timestep Collection Time: 3.94506
Timestep Consumption Time: 15.50034
PPO Batch Consumption Time: 2.31684
Total Iteration Time: 19.44540

Cumulative Model Updates: 12206
Cumulative Timesteps: 102121138

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2422.43752
Policy Entropy: -0.54138
Value Function Loss: 1.19852

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.17275
Policy Update Magnitude: 0.06723
Value Function Update Magnitude: 0.06508

Collected Steps per Second: 13390.37020
Overall Steps per Second: 2546.65072

Timestep Collection Time: 3.73791
Timestep Consumption Time: 15.91614
PPO Batch Consumption Time: 2.30965
Total Iteration Time: 19.65405

Cumulative Model Updates: 12212
Cumulative Timesteps: 102171190

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1785.19724
Policy Entropy: -0.54352
Value Function Loss: 1.20639

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.06944
Value Function Update Magnitude: 0.07016

Collected Steps per Second: 13050.58908
Overall Steps per Second: 2598.05310

Timestep Collection Time: 3.83278
Timestep Consumption Time: 15.42010
PPO Batch Consumption Time: 2.26601
Total Iteration Time: 19.25288

Cumulative Model Updates: 12218
Cumulative Timesteps: 102221210

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1638.19516
Policy Entropy: -0.54524
Value Function Loss: 1.17366

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.16276
Policy Update Magnitude: 0.06632
Value Function Update Magnitude: 0.07066

Collected Steps per Second: 13984.87283
Overall Steps per Second: 2580.83442

Timestep Collection Time: 3.57529
Timestep Consumption Time: 15.79829
PPO Batch Consumption Time: 2.31876
Total Iteration Time: 19.37358

Cumulative Model Updates: 12224
Cumulative Timesteps: 102271210

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3465.52731
Policy Entropy: -0.54867
Value Function Loss: 1.11678

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.16153
Policy Update Magnitude: 0.06949
Value Function Update Magnitude: 0.06708

Collected Steps per Second: 12377.72192
Overall Steps per Second: 2494.36595

Timestep Collection Time: 4.04856
Timestep Consumption Time: 16.04151
PPO Batch Consumption Time: 2.32783
Total Iteration Time: 20.09008

Cumulative Model Updates: 12230
Cumulative Timesteps: 102321322

Timesteps Collected: 50112
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2974.46200
Policy Entropy: -0.54718
Value Function Loss: 1.08731

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.15758
Policy Update Magnitude: 0.07478
Value Function Update Magnitude: 0.06590

Collected Steps per Second: 16184.06810
Overall Steps per Second: 2657.91919

Timestep Collection Time: 3.09168
Timestep Consumption Time: 15.73357
PPO Batch Consumption Time: 2.30748
Total Iteration Time: 18.82525

Cumulative Model Updates: 12236
Cumulative Timesteps: 102371358

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2992.42347
Policy Entropy: -0.54874
Value Function Loss: 1.13230

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.16347
Policy Update Magnitude: 0.06948
Value Function Update Magnitude: 0.06375

Collected Steps per Second: 12528.93558
Overall Steps per Second: 2545.35051

Timestep Collection Time: 3.99204
Timestep Consumption Time: 15.65791
PPO Batch Consumption Time: 2.29879
Total Iteration Time: 19.64995

Cumulative Model Updates: 12242
Cumulative Timesteps: 102421374

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2678.48618
Policy Entropy: -0.55016
Value Function Loss: 1.16194

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.15784
Policy Update Magnitude: 0.06718
Value Function Update Magnitude: 0.06935

Collected Steps per Second: 12504.08191
Overall Steps per Second: 2548.86004

Timestep Collection Time: 4.00349
Timestep Consumption Time: 15.63666
PPO Batch Consumption Time: 2.33978
Total Iteration Time: 19.64015

Cumulative Model Updates: 12248
Cumulative Timesteps: 102471434

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1677.69513
Policy Entropy: -0.55224
Value Function Loss: 1.16987

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.07063
Value Function Update Magnitude: 0.06650

Collected Steps per Second: 12798.95659
Overall Steps per Second: 2484.42854

Timestep Collection Time: 3.90657
Timestep Consumption Time: 16.21878
PPO Batch Consumption Time: 2.39010
Total Iteration Time: 20.12535

Cumulative Model Updates: 12254
Cumulative Timesteps: 102521434

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2370.87803
Policy Entropy: -0.55309
Value Function Loss: 1.16950

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.08750
Value Function Update Magnitude: 0.07010

Collected Steps per Second: 12573.65981
Overall Steps per Second: 2020.00693

Timestep Collection Time: 3.97927
Timestep Consumption Time: 20.78995
PPO Batch Consumption Time: 2.31901
Total Iteration Time: 24.76922

Cumulative Model Updates: 12260
Cumulative Timesteps: 102571468

Timesteps Collected: 50034
--------END ITERATION REPORT--------


Saving checkpoint 102571468...
Checkpoint 102571468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1731.59178
Policy Entropy: -0.55248
Value Function Loss: 1.18376

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13465
Policy Update Magnitude: 0.09636
Value Function Update Magnitude: 0.06426

Collected Steps per Second: 12681.88610
Overall Steps per Second: 2478.60829

Timestep Collection Time: 3.94484
Timestep Consumption Time: 16.23907
PPO Batch Consumption Time: 2.38671
Total Iteration Time: 20.18391

Cumulative Model Updates: 12266
Cumulative Timesteps: 102621496

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1558.47246
Policy Entropy: -0.55347
Value Function Loss: 1.17767

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.16015
Policy Update Magnitude: 0.07897
Value Function Update Magnitude: 0.06140

Collected Steps per Second: 12199.43190
Overall Steps per Second: 2472.40052

Timestep Collection Time: 4.09986
Timestep Consumption Time: 16.12987
PPO Batch Consumption Time: 2.37924
Total Iteration Time: 20.22973

Cumulative Model Updates: 12272
Cumulative Timesteps: 102671512

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1761.13585
Policy Entropy: -0.55515
Value Function Loss: 1.14854

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.15784
Policy Update Magnitude: 0.06930
Value Function Update Magnitude: 0.05898

Collected Steps per Second: 13214.47922
Overall Steps per Second: 2518.11305

Timestep Collection Time: 3.79054
Timestep Consumption Time: 16.10134
PPO Batch Consumption Time: 2.36850
Total Iteration Time: 19.89188

Cumulative Model Updates: 12278
Cumulative Timesteps: 102721602

Timesteps Collected: 50090
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3958.79671
Policy Entropy: -0.55717
Value Function Loss: 1.14570

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.15983
Policy Update Magnitude: 0.06716
Value Function Update Magnitude: 0.06058

Collected Steps per Second: 12583.63594
Overall Steps per Second: 2484.78653

Timestep Collection Time: 3.97755
Timestep Consumption Time: 16.16583
PPO Batch Consumption Time: 2.37160
Total Iteration Time: 20.14338

Cumulative Model Updates: 12284
Cumulative Timesteps: 102771654

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2907.04941
Policy Entropy: -0.56111
Value Function Loss: 1.14810

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14409
Policy Update Magnitude: 0.06897
Value Function Update Magnitude: 0.06168

Collected Steps per Second: 12449.95606
Overall Steps per Second: 689.71522

Timestep Collection Time: 4.01736
Timestep Consumption Time: 68.49952
PPO Batch Consumption Time: 2.35465
Total Iteration Time: 72.51689

Cumulative Model Updates: 12290
Cumulative Timesteps: 102821670

Timesteps Collected: 50016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1780.08126
Policy Entropy: -0.56160
Value Function Loss: 1.14994

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14591
Policy Update Magnitude: 0.07812
Value Function Update Magnitude: 0.05867

Collected Steps per Second: 12325.84568
Overall Steps per Second: 2444.22389

Timestep Collection Time: 4.06171
Timestep Consumption Time: 16.42087
PPO Batch Consumption Time: 2.40610
Total Iteration Time: 20.48258

Cumulative Model Updates: 12296
Cumulative Timesteps: 102871734

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2129.59512
Policy Entropy: -0.56157
Value Function Loss: 1.14810

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.07581
Value Function Update Magnitude: 0.05959

Collected Steps per Second: 12576.45772
Overall Steps per Second: 2508.21169

Timestep Collection Time: 3.98061
Timestep Consumption Time: 15.97863
PPO Batch Consumption Time: 2.38951
Total Iteration Time: 19.95924

Cumulative Model Updates: 12302
Cumulative Timesteps: 102921796

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2988.74365
Policy Entropy: -0.56288
Value Function Loss: 1.17228

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09474
Policy Update Magnitude: 0.09263
Value Function Update Magnitude: 0.06108

Collected Steps per Second: 12801.55487
Overall Steps per Second: 484.27540

Timestep Collection Time: 3.90578
Timestep Consumption Time: 99.34126
PPO Batch Consumption Time: 2.38895
Total Iteration Time: 103.24704

Cumulative Model Updates: 12308
Cumulative Timesteps: 102971796

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1790.25809
Policy Entropy: -0.56592
Value Function Loss: 1.20069

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12654
Policy Update Magnitude: 0.10268
Value Function Update Magnitude: 0.06480

Collected Steps per Second: 12200.31134
Overall Steps per Second: 844.89433

Timestep Collection Time: 4.09875
Timestep Consumption Time: 55.08735
PPO Batch Consumption Time: 2.40038
Total Iteration Time: 59.18610

Cumulative Model Updates: 12314
Cumulative Timesteps: 103021802

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4057.66282
Policy Entropy: -0.56818
Value Function Loss: 1.18617

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.16904
Policy Update Magnitude: 0.09578
Value Function Update Magnitude: 0.06466

Collected Steps per Second: 12663.21449
Overall Steps per Second: 2526.64885

Timestep Collection Time: 3.94971
Timestep Consumption Time: 15.84568
PPO Batch Consumption Time: 2.31601
Total Iteration Time: 19.79539

Cumulative Model Updates: 12320
Cumulative Timesteps: 103071818

Timesteps Collected: 50016
--------END ITERATION REPORT--------


Saving checkpoint 103071818...
Checkpoint 103071818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2271.74983
Policy Entropy: -0.56782
Value Function Loss: 1.17831

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.08927
Value Function Update Magnitude: 0.06210

Collected Steps per Second: 12678.80755
Overall Steps per Second: 1273.88505

Timestep Collection Time: 3.94390
Timestep Consumption Time: 35.30925
PPO Batch Consumption Time: 2.37637
Total Iteration Time: 39.25315

Cumulative Model Updates: 12326
Cumulative Timesteps: 103121822

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1806.27621
Policy Entropy: -0.56989
Value Function Loss: 1.14359

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14913
Policy Update Magnitude: 0.09442
Value Function Update Magnitude: 0.06080

Collected Steps per Second: 13347.65882
Overall Steps per Second: 2491.43479

Timestep Collection Time: 3.74747
Timestep Consumption Time: 16.32931
PPO Batch Consumption Time: 2.39683
Total Iteration Time: 20.07678

Cumulative Model Updates: 12332
Cumulative Timesteps: 103171842

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2631.30105
Policy Entropy: -0.57171
Value Function Loss: 1.16844

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.08575
Value Function Update Magnitude: 0.06187

Collected Steps per Second: 14108.49678
Overall Steps per Second: 2512.76273

Timestep Collection Time: 3.54609
Timestep Consumption Time: 16.36427
PPO Batch Consumption Time: 2.40642
Total Iteration Time: 19.91036

Cumulative Model Updates: 12338
Cumulative Timesteps: 103221872

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2714.80466
Policy Entropy: -0.57137
Value Function Loss: 1.15574

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13896
Policy Update Magnitude: 0.07013
Value Function Update Magnitude: 0.06110

Collected Steps per Second: 13388.42493
Overall Steps per Second: 2499.33780

Timestep Collection Time: 3.73905
Timestep Consumption Time: 16.29025
PPO Batch Consumption Time: 2.38743
Total Iteration Time: 20.02931

Cumulative Model Updates: 12344
Cumulative Timesteps: 103271932

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2268.81159
Policy Entropy: -0.57248
Value Function Loss: 1.17319

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14042
Policy Update Magnitude: 0.06571
Value Function Update Magnitude: 0.06081

Collected Steps per Second: 13115.10081
Overall Steps per Second: 2476.62979

Timestep Collection Time: 3.81697
Timestep Consumption Time: 16.39598
PPO Batch Consumption Time: 2.40162
Total Iteration Time: 20.21295

Cumulative Model Updates: 12350
Cumulative Timesteps: 103321992

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1372.52430
Policy Entropy: -0.57465
Value Function Loss: 1.14297

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.07286
Value Function Update Magnitude: 0.06327

Collected Steps per Second: 15871.59095
Overall Steps per Second: 2532.53358

Timestep Collection Time: 3.15091
Timestep Consumption Time: 16.59611
PPO Batch Consumption Time: 2.43552
Total Iteration Time: 19.74702

Cumulative Model Updates: 12356
Cumulative Timesteps: 103372002

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2578.53615
Policy Entropy: -0.57463
Value Function Loss: 1.11731

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.16753
Policy Update Magnitude: 0.08222
Value Function Update Magnitude: 0.06325

Collected Steps per Second: 12829.92864
Overall Steps per Second: 2529.90626

Timestep Collection Time: 3.89714
Timestep Consumption Time: 15.86644
PPO Batch Consumption Time: 2.32374
Total Iteration Time: 19.76358

Cumulative Model Updates: 12362
Cumulative Timesteps: 103422002

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3745.52191
Policy Entropy: -0.57869
Value Function Loss: 1.07448

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.17106
Policy Update Magnitude: 0.08707
Value Function Update Magnitude: 0.06091

Collected Steps per Second: 13156.14458
Overall Steps per Second: 2555.64866

Timestep Collection Time: 3.80537
Timestep Consumption Time: 15.78418
PPO Batch Consumption Time: 2.31232
Total Iteration Time: 19.58955

Cumulative Model Updates: 12368
Cumulative Timesteps: 103472066

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1523.48188
Policy Entropy: -0.57832
Value Function Loss: 1.08093

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.14809
Policy Update Magnitude: 0.06986
Value Function Update Magnitude: 0.06171

Collected Steps per Second: 12450.28594
Overall Steps per Second: 2526.53430

Timestep Collection Time: 4.01742
Timestep Consumption Time: 15.77966
PPO Batch Consumption Time: 2.33179
Total Iteration Time: 19.79708

Cumulative Model Updates: 12374
Cumulative Timesteps: 103522084

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4167.38925
Policy Entropy: -0.57971
Value Function Loss: 1.09637

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.15093
Policy Update Magnitude: 0.06070
Value Function Update Magnitude: 0.06585

Collected Steps per Second: 12285.93483
Overall Steps per Second: 2553.44251

Timestep Collection Time: 4.06969
Timestep Consumption Time: 15.51171
PPO Batch Consumption Time: 2.29987
Total Iteration Time: 19.58141

Cumulative Model Updates: 12380
Cumulative Timesteps: 103572084

Timesteps Collected: 50000
--------END ITERATION REPORT--------


Saving checkpoint 103572084...
Checkpoint 103572084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1859.60873
Policy Entropy: -0.57940
Value Function Loss: 1.10378

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.14897
Policy Update Magnitude: 0.06176
Value Function Update Magnitude: 0.06555

Collected Steps per Second: 13213.47822
Overall Steps per Second: 2520.55740

Timestep Collection Time: 3.78492
Timestep Consumption Time: 16.05672
PPO Batch Consumption Time: 2.33783
Total Iteration Time: 19.84164

Cumulative Model Updates: 12386
Cumulative Timesteps: 103622096

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1783.75751
Policy Entropy: -0.57858
Value Function Loss: 1.13639

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14231
Policy Update Magnitude: 0.06378
Value Function Update Magnitude: 0.06936

Collected Steps per Second: 13643.64550
Overall Steps per Second: 2454.73823

Timestep Collection Time: 3.66706
Timestep Consumption Time: 16.71475
PPO Batch Consumption Time: 2.46658
Total Iteration Time: 20.38181

Cumulative Model Updates: 12392
Cumulative Timesteps: 103672128

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2862.17839
Policy Entropy: -0.57923
Value Function Loss: 1.11600

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14247
Policy Update Magnitude: 0.06420
Value Function Update Magnitude: 0.06379

Collected Steps per Second: 13506.62534
Overall Steps per Second: 2504.38667

Timestep Collection Time: 3.70618
Timestep Consumption Time: 16.28195
PPO Batch Consumption Time: 2.40346
Total Iteration Time: 19.98813

Cumulative Model Updates: 12398
Cumulative Timesteps: 103722186

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2743.54149
Policy Entropy: -0.57973
Value Function Loss: 1.13251

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.06296
Value Function Update Magnitude: 0.06310

Collected Steps per Second: 14786.65370
Overall Steps per Second: 2550.73389

Timestep Collection Time: 3.38292
Timestep Consumption Time: 16.22791
PPO Batch Consumption Time: 2.40721
Total Iteration Time: 19.61083

Cumulative Model Updates: 12404
Cumulative Timesteps: 103772208

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3363.94967
Policy Entropy: -0.58023
Value Function Loss: 1.12510

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.14179
Policy Update Magnitude: 0.06215
Value Function Update Magnitude: 0.06485

Collected Steps per Second: 12741.22159
Overall Steps per Second: 2465.91373

Timestep Collection Time: 3.92490
Timestep Consumption Time: 16.35481
PPO Batch Consumption Time: 2.45312
Total Iteration Time: 20.27970

Cumulative Model Updates: 12410
Cumulative Timesteps: 103822216

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5056.95061
Policy Entropy: -0.58360
Value Function Loss: 1.15121

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14708
Policy Update Magnitude: 0.06337
Value Function Update Magnitude: 0.06655

Collected Steps per Second: 13126.44555
Overall Steps per Second: 2506.34114

Timestep Collection Time: 3.81566
Timestep Consumption Time: 16.16806
PPO Batch Consumption Time: 2.39801
Total Iteration Time: 19.98371

Cumulative Model Updates: 12416
Cumulative Timesteps: 103872302

Timesteps Collected: 50086
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1875.68598
Policy Entropy: -0.58393
Value Function Loss: 1.15361

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14391
Policy Update Magnitude: 0.06712
Value Function Update Magnitude: 0.06958

Collected Steps per Second: 12585.58370
Overall Steps per Second: 923.98548

Timestep Collection Time: 3.97391
Timestep Consumption Time: 50.15464
PPO Batch Consumption Time: 2.35116
Total Iteration Time: 54.12856

Cumulative Model Updates: 12422
Cumulative Timesteps: 103922316

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1661.42252
Policy Entropy: -0.58619
Value Function Loss: 1.12525

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.13861
Policy Update Magnitude: 0.07006
Value Function Update Magnitude: 0.06979

Collected Steps per Second: 13048.21564
Overall Steps per Second: 2491.21610

Timestep Collection Time: 3.83225
Timestep Consumption Time: 16.23988
PPO Batch Consumption Time: 2.38793
Total Iteration Time: 20.07212

Cumulative Model Updates: 12428
Cumulative Timesteps: 103972320

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1790.96077
Policy Entropy: -0.58765
Value Function Loss: 1.11959

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.07566
Value Function Update Magnitude: 0.07758

Collected Steps per Second: 12391.04278
Overall Steps per Second: 878.18703

Timestep Collection Time: 4.03695
Timestep Consumption Time: 52.92358
PPO Batch Consumption Time: 2.44511
Total Iteration Time: 56.96053

Cumulative Model Updates: 12434
Cumulative Timesteps: 104022342

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3413.66840
Policy Entropy: -0.58544
Value Function Loss: 1.11794

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.08089
Value Function Update Magnitude: 0.07157

Collected Steps per Second: 12454.06548
Overall Steps per Second: 1758.71507

Timestep Collection Time: 4.01893
Timestep Consumption Time: 24.44049
PPO Batch Consumption Time: 2.41227
Total Iteration Time: 28.45941

Cumulative Model Updates: 12440
Cumulative Timesteps: 104072394

Timesteps Collected: 50052
--------END ITERATION REPORT--------


Saving checkpoint 104072394...
Checkpoint 104072394 saved!
