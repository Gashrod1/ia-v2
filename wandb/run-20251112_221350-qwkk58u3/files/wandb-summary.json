{"_timestamp":1.7630131808904383e+09,"_step":4224,"Overall Steps per Second":1758.7150736965268,"Policy Entropy":-0.5854370991388956,"Value Function Loss":1.1179405649503071,"Cumulative Timesteps":104072394,"Timestep Consumption Time":24.440485175000504,"Total Iteration Time":28.459413778036833,"Timesteps Collected":50052,"Value Function Update Magnitude":0.07157247513532639,"_wandb":{"runtime":44915},"x_vel":12.525239126464879,"total_touches":0,"total_goals":0,"PPO Batch Consumption Time":2.4122734467188516,"_runtime":44915,"Policy Reward":3413.668402400371,"episode_goals":0,"Collected Steps per Second":12454.065484563562,"Cumulative Model Updates":12440,"episode_touches":0,"Policy Update Magnitude":0.08088511973619461,"Timestep Collection Time":4.018928603036329,"z_vel":-6.971440709843978,"SB3 Clip Fraction":0.13971332957347235,"Mean KL Divergence":0.01024231780320406,"y_vel":26.85138637788518}