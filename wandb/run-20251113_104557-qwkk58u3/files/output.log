Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.93616
Policy Entropy: 0.39451
Value Function Loss: 0.36461

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.16664
Policy Update Magnitude: 0.02812
Value Function Update Magnitude: 0.02229

Collected Steps per Second: 10604.41930
Overall Steps per Second: 3892.34513

Timestep Collection Time: 4.71822
Timestep Consumption Time: 8.13624
PPO Batch Consumption Time: 2.41384
Total Iteration Time: 12.85446

Cumulative Model Updates: 16228
Cumulative Timesteps: 136149592

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.89336
Policy Entropy: 0.38617
Value Function Loss: 0.35410

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.19383
Policy Update Magnitude: 0.02473
Value Function Update Magnitude: 0.03693

Collected Steps per Second: 12069.24893
Overall Steps per Second: 3864.25772

Timestep Collection Time: 4.14276
Timestep Consumption Time: 8.79634
PPO Batch Consumption Time: 2.38321
Total Iteration Time: 12.93910

Cumulative Model Updates: 16230
Cumulative Timesteps: 136199592

Timesteps Collected: 50000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.14191
Policy Entropy: 0.37725
Value Function Loss: 0.38356

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.21635
Policy Update Magnitude: 0.04427
Value Function Update Magnitude: 0.07668

Collected Steps per Second: 11405.34085
Overall Steps per Second: 3155.03279

Timestep Collection Time: 4.38987
Timestep Consumption Time: 11.47938
PPO Batch Consumption Time: 2.39617
Total Iteration Time: 15.86925

Cumulative Model Updates: 16234
Cumulative Timesteps: 136249660

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.28482
Policy Entropy: 0.36742
Value Function Loss: 0.38337

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.21579
Policy Update Magnitude: 0.05364
Value Function Update Magnitude: 0.11495

Collected Steps per Second: 11301.48468
Overall Steps per Second: 1854.93731

Timestep Collection Time: 4.42437
Timestep Consumption Time: 22.53179
PPO Batch Consumption Time: 2.33398
Total Iteration Time: 26.95617

Cumulative Model Updates: 16240
Cumulative Timesteps: 136299662

Timesteps Collected: 50002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.83548
Policy Entropy: 0.36329
Value Function Loss: 0.37267

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.23094
Policy Update Magnitude: 0.04430
Value Function Update Magnitude: 0.10571

Collected Steps per Second: 11698.97719
Overall Steps per Second: 2117.32614

Timestep Collection Time: 4.27730
Timestep Consumption Time: 19.35628
PPO Batch Consumption Time: 2.35979
Total Iteration Time: 23.63358

Cumulative Model Updates: 16246
Cumulative Timesteps: 136349702

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.16388
Policy Entropy: 0.35447
Value Function Loss: 0.36893

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.19732
Policy Update Magnitude: 0.04308
Value Function Update Magnitude: 0.10236

Collected Steps per Second: 11010.96389
Overall Steps per Second: 1747.53229

Timestep Collection Time: 4.54601
Timestep Consumption Time: 24.09781
PPO Batch Consumption Time: 2.39119
Total Iteration Time: 28.64382

Cumulative Model Updates: 16252
Cumulative Timesteps: 136399758

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.18116
Policy Entropy: 0.34498
Value Function Loss: 0.38579

Mean KL Divergence: 0.02543
SB3 Clip Fraction: 0.30481
Policy Update Magnitude: 0.03419
Value Function Update Magnitude: 0.09515

Collected Steps per Second: 11197.59412
Overall Steps per Second: 2499.57176

Timestep Collection Time: 4.46596
Timestep Consumption Time: 15.54067
PPO Batch Consumption Time: 2.31694
Total Iteration Time: 20.00663

Cumulative Model Updates: 16258
Cumulative Timesteps: 136449766

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.79863
Policy Entropy: 0.34082
Value Function Loss: 0.39812

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.21855
Policy Update Magnitude: 0.03314
Value Function Update Magnitude: 0.12581

Collected Steps per Second: 11226.61913
Overall Steps per Second: 2443.71258

Timestep Collection Time: 4.45530
Timestep Consumption Time: 16.01273
PPO Batch Consumption Time: 2.36318
Total Iteration Time: 20.46804

Cumulative Model Updates: 16264
Cumulative Timesteps: 136499784

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 487.88358
Policy Entropy: 0.33850
Value Function Loss: 0.40659

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.03583
Value Function Update Magnitude: 0.12731

Collected Steps per Second: 11271.75511
Overall Steps per Second: 2468.37302

Timestep Collection Time: 4.43622
Timestep Consumption Time: 15.82166
PPO Batch Consumption Time: 2.36197
Total Iteration Time: 20.25788

Cumulative Model Updates: 16270
Cumulative Timesteps: 136549788

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 496.46490
Policy Entropy: 0.33293
Value Function Loss: 0.41202

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.03946
Value Function Update Magnitude: 0.09677

Collected Steps per Second: 11253.25146
Overall Steps per Second: 2291.38673

Timestep Collection Time: 4.44369
Timestep Consumption Time: 17.37977
PPO Batch Consumption Time: 2.40664
Total Iteration Time: 21.82347

Cumulative Model Updates: 16276
Cumulative Timesteps: 136599794

Timesteps Collected: 50006
--------END ITERATION REPORT--------


Saving checkpoint 136599794...
Checkpoint 136599794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.08768
Policy Entropy: 0.32778
Value Function Loss: 0.40658

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.03951
Value Function Update Magnitude: 0.09108

Collected Steps per Second: 11076.53317
Overall Steps per Second: 1514.20813

Timestep Collection Time: 4.52019
Timestep Consumption Time: 28.54528
PPO Batch Consumption Time: 2.43601
Total Iteration Time: 33.06547

Cumulative Model Updates: 16282
Cumulative Timesteps: 136649862

Timesteps Collected: 50068
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.75116
Policy Entropy: 0.32350
Value Function Loss: 0.41921

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.04282
Value Function Update Magnitude: 0.09540

Collected Steps per Second: 11777.51796
Overall Steps per Second: 1273.16437

Timestep Collection Time: 4.24843
Timestep Consumption Time: 35.05207
PPO Batch Consumption Time: 2.42041
Total Iteration Time: 39.30050

Cumulative Model Updates: 16288
Cumulative Timesteps: 136699898

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507.71754
Policy Entropy: 0.31875
Value Function Loss: 0.42831

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.04584
Value Function Update Magnitude: 0.07322

Collected Steps per Second: 11497.19799
Overall Steps per Second: 2430.08944

Timestep Collection Time: 4.35393
Timestep Consumption Time: 16.24531
PPO Batch Consumption Time: 2.40278
Total Iteration Time: 20.59924

Cumulative Model Updates: 16294
Cumulative Timesteps: 136749956

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.99483
Policy Entropy: 0.31404
Value Function Loss: 0.45096

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.16286
Policy Update Magnitude: 0.04681
Value Function Update Magnitude: 0.07438

Collected Steps per Second: 11235.60134
Overall Steps per Second: 2444.98381

Timestep Collection Time: 4.45566
Timestep Consumption Time: 16.01973
PPO Batch Consumption Time: 2.39556
Total Iteration Time: 20.47539

Cumulative Model Updates: 16300
Cumulative Timesteps: 136800018

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.42595
Policy Entropy: 0.30863
Value Function Loss: 0.44460

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.06473
Value Function Update Magnitude: 0.08509

Collected Steps per Second: 11228.76193
Overall Steps per Second: 805.44903

Timestep Collection Time: 4.45410
Timestep Consumption Time: 57.64046
PPO Batch Consumption Time: 2.38083
Total Iteration Time: 62.09456

Cumulative Model Updates: 16306
Cumulative Timesteps: 136850032

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 424.20491
Policy Entropy: 0.30271
Value Function Loss: 0.45153

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.18668
Policy Update Magnitude: 0.06087
Value Function Update Magnitude: 0.08688

Collected Steps per Second: 11228.61569
Overall Steps per Second: 2454.08573

Timestep Collection Time: 4.45879
Timestep Consumption Time: 15.94229
PPO Batch Consumption Time: 2.37564
Total Iteration Time: 20.40108

Cumulative Model Updates: 16312
Cumulative Timesteps: 136900098

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704.29695
Policy Entropy: 0.29572
Value Function Loss: 0.46268

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.17066
Policy Update Magnitude: 0.05295
Value Function Update Magnitude: 0.07759

Collected Steps per Second: 11489.91656
Overall Steps per Second: 1052.25728

Timestep Collection Time: 4.35791
Timestep Consumption Time: 43.22741
PPO Batch Consumption Time: 2.34504
Total Iteration Time: 47.58532

Cumulative Model Updates: 16318
Cumulative Timesteps: 136950170

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655.57634
Policy Entropy: 0.28937
Value Function Loss: 0.47901

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14456
Policy Update Magnitude: 0.05182
Value Function Update Magnitude: 0.08028

Collected Steps per Second: 11368.41536
Overall Steps per Second: 2410.57060

Timestep Collection Time: 4.39885
Timestep Consumption Time: 16.34644
PPO Batch Consumption Time: 2.44507
Total Iteration Time: 20.74530

Cumulative Model Updates: 16324
Cumulative Timesteps: 137000178

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.96417
Policy Entropy: 0.28333
Value Function Loss: 0.48411

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.15114
Policy Update Magnitude: 0.05662
Value Function Update Magnitude: 0.07920

Collected Steps per Second: 11507.30180
Overall Steps per Second: 2311.81891

Timestep Collection Time: 4.34993
Timestep Consumption Time: 17.30228
PPO Batch Consumption Time: 2.39483
Total Iteration Time: 21.65221

Cumulative Model Updates: 16330
Cumulative Timesteps: 137050234

Timesteps Collected: 50056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 820.11564
Policy Entropy: 0.28035
Value Function Loss: 0.48487

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14690
Policy Update Magnitude: 0.05288
Value Function Update Magnitude: 0.07893

Collected Steps per Second: 11409.96680
Overall Steps per Second: 2414.11352

Timestep Collection Time: 4.38441
Timestep Consumption Time: 16.33789
PPO Batch Consumption Time: 2.43695
Total Iteration Time: 20.72231

Cumulative Model Updates: 16336
Cumulative Timesteps: 137100260

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 137100260...
Checkpoint 137100260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 559.09738
Policy Entropy: 0.27601
Value Function Loss: 0.48402

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.15844
Policy Update Magnitude: 0.05022
Value Function Update Magnitude: 0.08345

Collected Steps per Second: 11854.87541
Overall Steps per Second: 2439.30681

Timestep Collection Time: 4.22223
Timestep Consumption Time: 16.29753
PPO Batch Consumption Time: 2.39623
Total Iteration Time: 20.51976

Cumulative Model Updates: 16342
Cumulative Timesteps: 137150314

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706.00635
Policy Entropy: 0.27165
Value Function Loss: 0.46740

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.17451
Policy Update Magnitude: 0.04896
Value Function Update Magnitude: 0.08564

Collected Steps per Second: 11260.41375
Overall Steps per Second: 762.78057

Timestep Collection Time: 4.44442
Timestep Consumption Time: 61.16554
PPO Batch Consumption Time: 2.36655
Total Iteration Time: 65.60996

Cumulative Model Updates: 16348
Cumulative Timesteps: 137200360

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.93459
Policy Entropy: 0.26564
Value Function Loss: 0.47451

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.18278
Policy Update Magnitude: 0.04462
Value Function Update Magnitude: 0.07402

Collected Steps per Second: 11089.29361
Overall Steps per Second: 2426.34477

Timestep Collection Time: 4.51336
Timestep Consumption Time: 16.11437
PPO Batch Consumption Time: 2.41098
Total Iteration Time: 20.62774

Cumulative Model Updates: 16354
Cumulative Timesteps: 137250410

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713.60583
Policy Entropy: 0.25934
Value Function Loss: 0.46523

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.19862
Policy Update Magnitude: 0.04654
Value Function Update Magnitude: 0.07328

Collected Steps per Second: 11570.97368
Overall Steps per Second: 2410.09298

Timestep Collection Time: 4.32496
Timestep Consumption Time: 16.43938
PPO Batch Consumption Time: 2.42837
Total Iteration Time: 20.76434

Cumulative Model Updates: 16360
Cumulative Timesteps: 137300454

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.23809
Policy Entropy: 0.25375
Value Function Loss: 0.46829

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.18529
Policy Update Magnitude: 0.05156
Value Function Update Magnitude: 0.07743

Collected Steps per Second: 11221.38489
Overall Steps per Second: 2387.00457

Timestep Collection Time: 4.46148
Timestep Consumption Time: 16.51209
PPO Batch Consumption Time: 2.42503
Total Iteration Time: 20.97357

Cumulative Model Updates: 16366
Cumulative Timesteps: 137350518

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 766.12546
Policy Entropy: 0.24821
Value Function Loss: 0.47629

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.05608
Value Function Update Magnitude: 0.07185

Collected Steps per Second: 11764.20419
Overall Steps per Second: 2428.85766

Timestep Collection Time: 4.25562
Timestep Consumption Time: 16.35654
PPO Batch Consumption Time: 2.41088
Total Iteration Time: 20.61216

Cumulative Model Updates: 16372
Cumulative Timesteps: 137400582

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.81059
Policy Entropy: 0.24304
Value Function Loss: 0.49162

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.05757
Value Function Update Magnitude: 0.07339

Collected Steps per Second: 11351.64553
Overall Steps per Second: 2450.75694

Timestep Collection Time: 4.41328
Timestep Consumption Time: 16.02857
PPO Batch Consumption Time: 2.36621
Total Iteration Time: 20.44185

Cumulative Model Updates: 16378
Cumulative Timesteps: 137450680

Timesteps Collected: 50098
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.03940
Policy Entropy: 0.23838
Value Function Loss: 0.49946

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14629
Policy Update Magnitude: 0.06125
Value Function Update Magnitude: 0.07923

Collected Steps per Second: 11978.57069
Overall Steps per Second: 979.30235

Timestep Collection Time: 4.17846
Timestep Consumption Time: 46.93139
PPO Batch Consumption Time: 2.42562
Total Iteration Time: 51.10985

Cumulative Model Updates: 16384
Cumulative Timesteps: 137500732

Timesteps Collected: 50052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 781.81119
Policy Entropy: 0.23271
Value Function Loss: 0.47607

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.19586
Policy Update Magnitude: 0.05293
Value Function Update Magnitude: 0.07507

Collected Steps per Second: 11455.65367
Overall Steps per Second: 2498.46382

Timestep Collection Time: 4.36658
Timestep Consumption Time: 15.65452
PPO Batch Consumption Time: 2.29967
Total Iteration Time: 20.02110

Cumulative Model Updates: 16390
Cumulative Timesteps: 137550754

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 927.74471
Policy Entropy: 0.22813
Value Function Loss: 0.47805

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.24704
Policy Update Magnitude: 0.05277
Value Function Update Magnitude: 0.06577

Collected Steps per Second: 11269.58009
Overall Steps per Second: 2431.10475

Timestep Collection Time: 4.43938
Timestep Consumption Time: 16.13974
PPO Batch Consumption Time: 2.41354
Total Iteration Time: 20.57912

Cumulative Model Updates: 16396
Cumulative Timesteps: 137600784

Timesteps Collected: 50030
--------END ITERATION REPORT--------


Saving checkpoint 137600784...
Checkpoint 137600784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1053.18682
Policy Entropy: 0.22218
Value Function Loss: 0.49689

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.23539
Policy Update Magnitude: 0.04881
Value Function Update Magnitude: 0.06574

Collected Steps per Second: 11294.17944
Overall Steps per Second: 2457.24528

Timestep Collection Time: 4.43095
Timestep Consumption Time: 15.93494
PPO Batch Consumption Time: 2.33968
Total Iteration Time: 20.36590

Cumulative Model Updates: 16402
Cumulative Timesteps: 137650828

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 816.36796
Policy Entropy: 0.21802
Value Function Loss: 0.51444

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.19770
Policy Update Magnitude: 0.04505
Value Function Update Magnitude: 0.07441

Collected Steps per Second: 11372.36025
Overall Steps per Second: 2448.47071

Timestep Collection Time: 4.39750
Timestep Consumption Time: 16.02749
PPO Batch Consumption Time: 2.39698
Total Iteration Time: 20.42499

Cumulative Model Updates: 16408
Cumulative Timesteps: 137700838

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527.29279
Policy Entropy: 0.21432
Value Function Loss: 0.50347

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.15265
Policy Update Magnitude: 0.04696
Value Function Update Magnitude: 0.07129

Collected Steps per Second: 11645.50111
Overall Steps per Second: 2463.14225

Timestep Collection Time: 4.29591
Timestep Consumption Time: 16.01473
PPO Batch Consumption Time: 2.35359
Total Iteration Time: 20.31064

Cumulative Model Updates: 16414
Cumulative Timesteps: 137750866

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614.20250
Policy Entropy: 0.20933
Value Function Loss: 0.48996

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.16871
Policy Update Magnitude: 0.04496
Value Function Update Magnitude: 0.07486

Collected Steps per Second: 10974.45862
Overall Steps per Second: 2399.17699

Timestep Collection Time: 4.55694
Timestep Consumption Time: 16.28770
PPO Batch Consumption Time: 2.42536
Total Iteration Time: 20.84465

Cumulative Model Updates: 16420
Cumulative Timesteps: 137800876

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692.15378
Policy Entropy: 0.20122
Value Function Loss: 0.49076

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.20282
Policy Update Magnitude: 0.05689
Value Function Update Magnitude: 0.07339

Collected Steps per Second: 11089.61040
Overall Steps per Second: 2398.69389

Timestep Collection Time: 4.51125
Timestep Consumption Time: 16.34510
PPO Batch Consumption Time: 2.41324
Total Iteration Time: 20.85635

Cumulative Model Updates: 16426
Cumulative Timesteps: 137850904

Timesteps Collected: 50028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1237.35691
Policy Entropy: 0.19509
Value Function Loss: 0.48636

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.15562
Policy Update Magnitude: 0.05744
Value Function Update Magnitude: 0.07303

Collected Steps per Second: 11799.83432
Overall Steps per Second: 2401.07184

Timestep Collection Time: 4.24362
Timestep Consumption Time: 16.61123
PPO Batch Consumption Time: 2.46017
Total Iteration Time: 20.85485

Cumulative Model Updates: 16432
Cumulative Timesteps: 137900978

Timesteps Collected: 50074
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 861.90655
Policy Entropy: 0.19035
Value Function Loss: 0.48983

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14229
Policy Update Magnitude: 0.06014
Value Function Update Magnitude: 0.07259

Collected Steps per Second: 11471.14375
Overall Steps per Second: 2453.00324

Timestep Collection Time: 4.36574
Timestep Consumption Time: 16.05005
PPO Batch Consumption Time: 2.35862
Total Iteration Time: 20.41579

Cumulative Model Updates: 16438
Cumulative Timesteps: 137951058

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1420.26723
Policy Entropy: 0.18519
Value Function Loss: 0.49654

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.17321
Policy Update Magnitude: 0.05149
Value Function Update Magnitude: 0.07495

Collected Steps per Second: 10934.52346
Overall Steps per Second: 2437.83168

Timestep Collection Time: 4.57395
Timestep Consumption Time: 15.94182
PPO Batch Consumption Time: 2.34500
Total Iteration Time: 20.51577

Cumulative Model Updates: 16444
Cumulative Timesteps: 138001072

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 960.08784
Policy Entropy: 0.17927
Value Function Loss: 0.51117

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.16662
Policy Update Magnitude: 0.04795
Value Function Update Magnitude: 0.07709

Collected Steps per Second: 10826.37403
Overall Steps per Second: 2403.83697

Timestep Collection Time: 4.61946
Timestep Consumption Time: 16.18561
PPO Batch Consumption Time: 2.42867
Total Iteration Time: 20.80507

Cumulative Model Updates: 16450
Cumulative Timesteps: 138051084

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 888.89781
Policy Entropy: 0.17277
Value Function Loss: 0.52877

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.16660
Policy Update Magnitude: 0.04827
Value Function Update Magnitude: 0.07814

Collected Steps per Second: 11020.55663
Overall Steps per Second: 2369.30992

Timestep Collection Time: 4.54296
Timestep Consumption Time: 16.58808
PPO Batch Consumption Time: 2.44423
Total Iteration Time: 21.13105

Cumulative Model Updates: 16456
Cumulative Timesteps: 138101150

Timesteps Collected: 50066
--------END ITERATION REPORT--------


Saving checkpoint 138101150...
Checkpoint 138101150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 998.13551
Policy Entropy: 0.16649
Value Function Loss: 0.52762

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.16728
Policy Update Magnitude: 0.05545
Value Function Update Magnitude: 0.08468

Collected Steps per Second: 11097.39276
Overall Steps per Second: 2373.81145

Timestep Collection Time: 4.50935
Timestep Consumption Time: 16.57152
PPO Batch Consumption Time: 2.45335
Total Iteration Time: 21.08087

Cumulative Model Updates: 16462
Cumulative Timesteps: 138151192

Timesteps Collected: 50042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607.32190
Policy Entropy: 0.15815
Value Function Loss: 0.53363

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.17935
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.07402

Collected Steps per Second: 11851.20601
Overall Steps per Second: 2489.37957

Timestep Collection Time: 4.22101
Timestep Consumption Time: 15.87396
PPO Batch Consumption Time: 2.33418
Total Iteration Time: 20.09497

Cumulative Model Updates: 16468
Cumulative Timesteps: 138201216

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 881.95631
Policy Entropy: 0.14912
Value Function Loss: 0.53571

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.21310
Policy Update Magnitude: 0.05741
Value Function Update Magnitude: 0.07348

Collected Steps per Second: 10899.21199
Overall Steps per Second: 2390.04953

Timestep Collection Time: 4.59152
Timestep Consumption Time: 16.34695
PPO Batch Consumption Time: 2.43456
Total Iteration Time: 20.93848

Cumulative Model Updates: 16474
Cumulative Timesteps: 138251260

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1447.57837
Policy Entropy: 0.13968
Value Function Loss: 0.52139

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.20737
Policy Update Magnitude: 0.05844
Value Function Update Magnitude: 0.06843

Collected Steps per Second: 10837.29476
Overall Steps per Second: 2452.93046

Timestep Collection Time: 4.61739
Timestep Consumption Time: 15.78270
PPO Batch Consumption Time: 2.35491
Total Iteration Time: 20.40009

Cumulative Model Updates: 16480
Cumulative Timesteps: 138301300

Timesteps Collected: 50040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1119.66916
Policy Entropy: 0.13030
Value Function Loss: 0.50355

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.22214
Policy Update Magnitude: 0.05500
Value Function Update Magnitude: 0.06721

Collected Steps per Second: 11077.08897
Overall Steps per Second: 2441.25082

Timestep Collection Time: 4.51924
Timestep Consumption Time: 15.98664
PPO Batch Consumption Time: 2.34776
Total Iteration Time: 20.50588

Cumulative Model Updates: 16486
Cumulative Timesteps: 138351360

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1508.01436
Policy Entropy: 0.11755
Value Function Loss: 0.50562

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.24752
Policy Update Magnitude: 0.05731
Value Function Update Magnitude: 0.06747

Collected Steps per Second: 10878.03757
Overall Steps per Second: 2399.49894

Timestep Collection Time: 4.60396
Timestep Consumption Time: 16.26790
PPO Batch Consumption Time: 2.43507
Total Iteration Time: 20.87186

Cumulative Model Updates: 16492
Cumulative Timesteps: 138401442

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1576.69624
Policy Entropy: 0.10895
Value Function Loss: 0.53242

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.24182
Policy Update Magnitude: 0.05103
Value Function Update Magnitude: 0.07204

Collected Steps per Second: 11141.27755
Overall Steps per Second: 2445.64199

Timestep Collection Time: 4.48979
Timestep Consumption Time: 15.96373
PPO Batch Consumption Time: 2.34929
Total Iteration Time: 20.45353

Cumulative Model Updates: 16498
Cumulative Timesteps: 138451464

Timesteps Collected: 50022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840.97101
Policy Entropy: 0.10134
Value Function Loss: 0.55536

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.24255
Policy Update Magnitude: 0.04589
Value Function Update Magnitude: 0.06947

Collected Steps per Second: 11481.37942
Overall Steps per Second: 2437.13736

Timestep Collection Time: 4.36202
Timestep Consumption Time: 16.18750
PPO Batch Consumption Time: 2.39170
Total Iteration Time: 20.54952

Cumulative Model Updates: 16504
Cumulative Timesteps: 138501546

Timesteps Collected: 50082
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1121.00309
Policy Entropy: 0.09301
Value Function Loss: 0.57096

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.22189
Policy Update Magnitude: 0.04628
Value Function Update Magnitude: 0.07929

Collected Steps per Second: 11949.76636
Overall Steps per Second: 2436.57175

Timestep Collection Time: 4.19155
Timestep Consumption Time: 16.36521
PPO Batch Consumption Time: 2.41243
Total Iteration Time: 20.55675

Cumulative Model Updates: 16510
Cumulative Timesteps: 138551634

Timesteps Collected: 50088
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1101.26678
Policy Entropy: 0.08365
Value Function Loss: 0.57761

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.23338
Policy Update Magnitude: 0.04460
Value Function Update Magnitude: 0.08466

Collected Steps per Second: 11172.03792
Overall Steps per Second: 2405.86644

Timestep Collection Time: 4.47671
Timestep Consumption Time: 16.31164
PPO Batch Consumption Time: 2.40781
Total Iteration Time: 20.78835

Cumulative Model Updates: 16516
Cumulative Timesteps: 138601648

Timesteps Collected: 50014
--------END ITERATION REPORT--------


Saving checkpoint 138601648...
Checkpoint 138601648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1494.48621
Policy Entropy: 0.07745
Value Function Loss: 0.59146

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.22744
Policy Update Magnitude: 0.04819
Value Function Update Magnitude: 0.09514

Collected Steps per Second: 10981.39231
Overall Steps per Second: 2401.55284

Timestep Collection Time: 4.55498
Timestep Consumption Time: 16.27321
PPO Batch Consumption Time: 2.43357
Total Iteration Time: 20.82819

Cumulative Model Updates: 16522
Cumulative Timesteps: 138651668

Timesteps Collected: 50020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1065.33890
Policy Entropy: 0.06733
Value Function Loss: 0.60423

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.19246
Policy Update Magnitude: 0.05823
Value Function Update Magnitude: 0.10134

Collected Steps per Second: 11283.14347
Overall Steps per Second: 2397.19782

Timestep Collection Time: 4.43830
Timestep Consumption Time: 16.45192
PPO Batch Consumption Time: 2.42516
Total Iteration Time: 20.89022

Cumulative Model Updates: 16528
Cumulative Timesteps: 138701746

Timesteps Collected: 50078
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1445.96747
Policy Entropy: 0.05964
Value Function Loss: 0.60841

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.21548
Policy Update Magnitude: 0.06213
Value Function Update Magnitude: 0.10146

Collected Steps per Second: 11183.85494
Overall Steps per Second: 2389.01282

Timestep Collection Time: 4.47699
Timestep Consumption Time: 16.48146
PPO Batch Consumption Time: 2.43148
Total Iteration Time: 20.95845

Cumulative Model Updates: 16534
Cumulative Timesteps: 138751816

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1980.51202
Policy Entropy: 0.05303
Value Function Loss: 0.63830

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.21060
Policy Update Magnitude: 0.05432
Value Function Update Magnitude: 0.10221

Collected Steps per Second: 11696.23029
Overall Steps per Second: 2397.52166

Timestep Collection Time: 4.27557
Timestep Consumption Time: 16.58264
PPO Batch Consumption Time: 2.45047
Total Iteration Time: 20.85821

Cumulative Model Updates: 16540
Cumulative Timesteps: 138801824

Timesteps Collected: 50008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 887.16493
Policy Entropy: 0.04704
Value Function Loss: 0.64601

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.16859
Policy Update Magnitude: 0.05564
Value Function Update Magnitude: 0.09967

Collected Steps per Second: 11104.65795
Overall Steps per Second: 2407.29561

Timestep Collection Time: 4.50712
Timestep Consumption Time: 16.28385
PPO Batch Consumption Time: 2.40479
Total Iteration Time: 20.79097

Cumulative Model Updates: 16546
Cumulative Timesteps: 138851874

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776.55394
Policy Entropy: 0.03903
Value Function Loss: 0.65712

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.19593
Policy Update Magnitude: 0.05273
Value Function Update Magnitude: 0.08944

Collected Steps per Second: 11842.87501
Overall Steps per Second: 2405.77468

Timestep Collection Time: 4.22296
Timestep Consumption Time: 16.56535
PPO Batch Consumption Time: 2.42900
Total Iteration Time: 20.78831

Cumulative Model Updates: 16552
Cumulative Timesteps: 138901886

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1531.40051
Policy Entropy: 0.03185
Value Function Loss: 0.66061

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.18639
Policy Update Magnitude: 0.05237
Value Function Update Magnitude: 0.09150

Collected Steps per Second: 11093.84080
Overall Steps per Second: 2399.03975

Timestep Collection Time: 4.51241
Timestep Consumption Time: 16.35427
PPO Batch Consumption Time: 2.41262
Total Iteration Time: 20.86668

Cumulative Model Updates: 16558
Cumulative Timesteps: 138951946

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1152.45998
Policy Entropy: 0.02572
Value Function Loss: 0.66108

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.19348
Policy Update Magnitude: 0.05302
Value Function Update Magnitude: 0.09090

Collected Steps per Second: 10971.73836
Overall Steps per Second: 2467.38551

Timestep Collection Time: 4.56445
Timestep Consumption Time: 15.73233
PPO Batch Consumption Time: 2.34750
Total Iteration Time: 20.29679

Cumulative Model Updates: 16564
Cumulative Timesteps: 139002026

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 942.79672
Policy Entropy: 0.01928
Value Function Loss: 0.67716

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.17549
Policy Update Magnitude: 0.05575
Value Function Update Magnitude: 0.10973

Collected Steps per Second: 11199.62387
Overall Steps per Second: 2410.33469

Timestep Collection Time: 4.46854
Timestep Consumption Time: 16.29455
PPO Batch Consumption Time: 2.39820
Total Iteration Time: 20.76309

Cumulative Model Updates: 16570
Cumulative Timesteps: 139052072

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1407.91905
Policy Entropy: 0.01286
Value Function Loss: 0.65534

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.17822
Policy Update Magnitude: 0.07032
Value Function Update Magnitude: 0.09492

Collected Steps per Second: 11116.56496
Overall Steps per Second: 2456.89610

Timestep Collection Time: 4.50013
Timestep Consumption Time: 15.86133
PPO Batch Consumption Time: 2.37437
Total Iteration Time: 20.36146

Cumulative Model Updates: 16576
Cumulative Timesteps: 139102098

Timesteps Collected: 50026
--------END ITERATION REPORT--------


Saving checkpoint 139102098...
Checkpoint 139102098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1156.55499
Policy Entropy: 0.00356
Value Function Loss: 0.65350

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.18073
Policy Update Magnitude: 0.07151
Value Function Update Magnitude: 0.09050

Collected Steps per Second: 11068.27225
Overall Steps per Second: 2429.94539

Timestep Collection Time: 4.51868
Timestep Consumption Time: 16.06367
PPO Batch Consumption Time: 2.34906
Total Iteration Time: 20.58236

Cumulative Model Updates: 16582
Cumulative Timesteps: 139152112

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1724.27804
Policy Entropy: -0.00105
Value Function Loss: 0.61544

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.19820
Policy Update Magnitude: 0.06103
Value Function Update Magnitude: 0.09565

Collected Steps per Second: 10860.27731
Overall Steps per Second: 2423.70344

Timestep Collection Time: 4.60522
Timestep Consumption Time: 16.03014
PPO Batch Consumption Time: 2.36401
Total Iteration Time: 20.63536

Cumulative Model Updates: 16588
Cumulative Timesteps: 139202126

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 938.58918
Policy Entropy: -0.01036
Value Function Loss: 0.61993

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.18668
Policy Update Magnitude: 0.05372
Value Function Update Magnitude: 0.08994

Collected Steps per Second: 11609.50771
Overall Steps per Second: 2454.02875

Timestep Collection Time: 4.30733
Timestep Consumption Time: 16.06977
PPO Batch Consumption Time: 2.36091
Total Iteration Time: 20.37710

Cumulative Model Updates: 16594
Cumulative Timesteps: 139252132

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1058.34551
Policy Entropy: -0.01920
Value Function Loss: 0.62486

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.21215
Policy Update Magnitude: 0.05034
Value Function Update Magnitude: 0.08567

Collected Steps per Second: 11064.42096
Overall Steps per Second: 2378.11589

Timestep Collection Time: 4.52550
Timestep Consumption Time: 16.52983
PPO Batch Consumption Time: 2.44501
Total Iteration Time: 21.05532

Cumulative Model Updates: 16600
Cumulative Timesteps: 139302204

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1045.14773
Policy Entropy: -0.02609
Value Function Loss: 0.64449

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.18313
Policy Update Magnitude: 0.05235
Value Function Update Magnitude: 0.08126

Collected Steps per Second: 10768.24348
Overall Steps per Second: 2385.81090

Timestep Collection Time: 4.65071
Timestep Consumption Time: 16.34005
PPO Batch Consumption Time: 2.44583
Total Iteration Time: 20.99077

Cumulative Model Updates: 16606
Cumulative Timesteps: 139352284

Timesteps Collected: 50080
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769.09990
Policy Entropy: -0.03259
Value Function Loss: 0.64377

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.17009
Policy Update Magnitude: 0.05415
Value Function Update Magnitude: 0.08262

Collected Steps per Second: 10947.46294
Overall Steps per Second: 2410.85126

Timestep Collection Time: 4.56946
Timestep Consumption Time: 16.18006
PPO Batch Consumption Time: 2.38206
Total Iteration Time: 20.74952

Cumulative Model Updates: 16612
Cumulative Timesteps: 139402308

Timesteps Collected: 50024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 976.05977
Policy Entropy: -0.04073
Value Function Loss: 0.65807

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.18065
Policy Update Magnitude: 0.05303
Value Function Update Magnitude: 0.08010

Collected Steps per Second: 11005.89491
Overall Steps per Second: 2395.85385

Timestep Collection Time: 4.54865
Timestep Consumption Time: 16.34661
PPO Batch Consumption Time: 2.44758
Total Iteration Time: 20.89526

Cumulative Model Updates: 16618
Cumulative Timesteps: 139452370

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1436.17943
Policy Entropy: -0.04370
Value Function Loss: 0.65813

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.19474
Policy Update Magnitude: 0.06360
Value Function Update Magnitude: 0.08212

Collected Steps per Second: 11020.38608
Overall Steps per Second: 2424.91220

Timestep Collection Time: 4.54394
Timestep Consumption Time: 16.10670
PPO Batch Consumption Time: 2.36781
Total Iteration Time: 20.65064

Cumulative Model Updates: 16624
Cumulative Timesteps: 139502446

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2148.30927
Policy Entropy: -0.05266
Value Function Loss: 0.67405

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.26185
Policy Update Magnitude: 0.06275
Value Function Update Magnitude: 0.08379

Collected Steps per Second: 10950.66523
Overall Steps per Second: 2373.28861

Timestep Collection Time: 4.56904
Timestep Consumption Time: 16.51310
PPO Batch Consumption Time: 2.43768
Total Iteration Time: 21.08214

Cumulative Model Updates: 16630
Cumulative Timesteps: 139552480

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796.77554
Policy Entropy: -0.05941
Value Function Loss: 0.65160

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.22443
Policy Update Magnitude: 0.05956
Value Function Update Magnitude: 0.07980

Collected Steps per Second: 11675.77138
Overall Steps per Second: 2445.40322

Timestep Collection Time: 4.28614
Timestep Consumption Time: 16.17838
PPO Batch Consumption Time: 2.38528
Total Iteration Time: 20.46452

Cumulative Model Updates: 16636
Cumulative Timesteps: 139602524

Timesteps Collected: 50044
--------END ITERATION REPORT--------


Saving checkpoint 139602524...
Checkpoint 139602524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1621.90571
Policy Entropy: -0.07036
Value Function Loss: 0.65149

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.19093
Policy Update Magnitude: 0.06871
Value Function Update Magnitude: 0.07626

Collected Steps per Second: 11120.61019
Overall Steps per Second: 2387.21226

Timestep Collection Time: 4.49939
Timestep Consumption Time: 16.46062
PPO Batch Consumption Time: 2.43117
Total Iteration Time: 20.96001

Cumulative Model Updates: 16642
Cumulative Timesteps: 139652560

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1350.51994
Policy Entropy: -0.07354
Value Function Loss: 0.64642

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.17951
Policy Update Magnitude: 0.07121
Value Function Update Magnitude: 0.07529

Collected Steps per Second: 10988.21225
Overall Steps per Second: 2448.52833

Timestep Collection Time: 4.55197
Timestep Consumption Time: 15.87581
PPO Batch Consumption Time: 2.36860
Total Iteration Time: 20.42778

Cumulative Model Updates: 16648
Cumulative Timesteps: 139702578

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1572.89940
Policy Entropy: -0.08015
Value Function Loss: 0.64250

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.16638
Policy Update Magnitude: 0.06938
Value Function Update Magnitude: 0.07665

Collected Steps per Second: 10889.38480
Overall Steps per Second: 2398.60673

Timestep Collection Time: 4.59475
Timestep Consumption Time: 16.26486
PPO Batch Consumption Time: 2.39456
Total Iteration Time: 20.85961

Cumulative Model Updates: 16654
Cumulative Timesteps: 139752612

Timesteps Collected: 50034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1270.32475
Policy Entropy: -0.09199
Value Function Loss: 0.65810

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.20931
Policy Update Magnitude: 0.06528
Value Function Update Magnitude: 0.07633

Collected Steps per Second: 11004.04269
Overall Steps per Second: 2471.43135

Timestep Collection Time: 4.54488
Timestep Consumption Time: 15.69117
PPO Batch Consumption Time: 2.34657
Total Iteration Time: 20.23605

Cumulative Model Updates: 16660
Cumulative Timesteps: 139802624

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1885.59589
Policy Entropy: -0.09759
Value Function Loss: 0.65370

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.21151
Policy Update Magnitude: 0.08141
Value Function Update Magnitude: 0.08237

Collected Steps per Second: 11146.98828
Overall Steps per Second: 2393.91154

Timestep Collection Time: 4.49108
Timestep Consumption Time: 16.42114
PPO Batch Consumption Time: 2.42199
Total Iteration Time: 20.91222

Cumulative Model Updates: 16666
Cumulative Timesteps: 139852686

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2499.47781
Policy Entropy: -0.09998
Value Function Loss: 0.66077

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.17366
Policy Update Magnitude: 0.06953
Value Function Update Magnitude: 0.09021

Collected Steps per Second: 11106.77374
Overall Steps per Second: 2450.99511

Timestep Collection Time: 4.50626
Timestep Consumption Time: 15.91402
PPO Batch Consumption Time: 2.38224
Total Iteration Time: 20.42028

Cumulative Model Updates: 16672
Cumulative Timesteps: 139902736

Timesteps Collected: 50050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 919.38050
Policy Entropy: -0.10229
Value Function Loss: 0.65420

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.15118
Policy Update Magnitude: 0.06375
Value Function Update Magnitude: 0.08985

Collected Steps per Second: 12940.20877
Overall Steps per Second: 2465.15582

Timestep Collection Time: 3.86439
Timestep Consumption Time: 16.42074
PPO Batch Consumption Time: 2.42040
Total Iteration Time: 20.28513

Cumulative Model Updates: 16678
Cumulative Timesteps: 139952742

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1041.58457
Policy Entropy: -0.11091
Value Function Loss: 0.64962

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.07431
Value Function Update Magnitude: 0.08275

Collected Steps per Second: 12965.20255
Overall Steps per Second: 2496.22313

Timestep Collection Time: 3.86481
Timestep Consumption Time: 16.20872
PPO Batch Consumption Time: 2.39730
Total Iteration Time: 20.07353

Cumulative Model Updates: 16684
Cumulative Timesteps: 140002850

Timesteps Collected: 50108
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1235.73548
Policy Entropy: -0.12030
Value Function Loss: 0.65498

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.18063
Policy Update Magnitude: 0.09580
Value Function Update Magnitude: 0.08157

Collected Steps per Second: 14235.47341
Overall Steps per Second: 2609.92483

Timestep Collection Time: 3.51263
Timestep Consumption Time: 15.64654
PPO Batch Consumption Time: 2.30075
Total Iteration Time: 19.15917

Cumulative Model Updates: 16690
Cumulative Timesteps: 140052854

Timesteps Collected: 50004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 984.42797
Policy Entropy: -0.12179
Value Function Loss: 0.65541

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.18087
Policy Update Magnitude: 0.08093
Value Function Update Magnitude: 0.08054

Collected Steps per Second: 11474.15220
Overall Steps per Second: 2541.37450

Timestep Collection Time: 4.35936
Timestep Consumption Time: 15.32290
PPO Batch Consumption Time: 2.24354
Total Iteration Time: 19.68226

Cumulative Model Updates: 16696
Cumulative Timesteps: 140102874

Timesteps Collected: 50020
--------END ITERATION REPORT--------


Saving checkpoint 140102874...
Checkpoint 140102874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1113.49376
Policy Entropy: -0.13231
Value Function Loss: 0.65319

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.19896
Policy Update Magnitude: 0.06585
Value Function Update Magnitude: 0.07768

Collected Steps per Second: 10955.31066
Overall Steps per Second: 2472.34053

Timestep Collection Time: 4.56984
Timestep Consumption Time: 15.67980
PPO Batch Consumption Time: 2.33904
Total Iteration Time: 20.24964

Cumulative Model Updates: 16702
Cumulative Timesteps: 140152938

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1459.64776
Policy Entropy: -0.13963
Value Function Loss: 0.65107

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.18778
Policy Update Magnitude: 0.06404
Value Function Update Magnitude: 0.07612

Collected Steps per Second: 11144.47817
Overall Steps per Second: 2517.90978

Timestep Collection Time: 4.49083
Timestep Consumption Time: 15.38597
PPO Batch Consumption Time: 2.25065
Total Iteration Time: 19.87680

Cumulative Model Updates: 16708
Cumulative Timesteps: 140202986

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1274.35377
Policy Entropy: -0.14355
Value Function Loss: 0.65345

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.17768
Policy Update Magnitude: 0.06327
Value Function Update Magnitude: 0.07420

Collected Steps per Second: 11633.31195
Overall Steps per Second: 2411.95862

Timestep Collection Time: 4.29903
Timestep Consumption Time: 16.43598
PPO Batch Consumption Time: 2.42959
Total Iteration Time: 20.73502

Cumulative Model Updates: 16714
Cumulative Timesteps: 140252998

Timesteps Collected: 50012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1508.20081
Policy Entropy: -0.14965
Value Function Loss: 0.67976

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.16950
Policy Update Magnitude: 0.06348
Value Function Update Magnitude: 0.07626

Collected Steps per Second: 11591.67505
Overall Steps per Second: 2489.86500

Timestep Collection Time: 4.32000
Timestep Consumption Time: 15.79194
PPO Batch Consumption Time: 2.31020
Total Iteration Time: 20.11193

Cumulative Model Updates: 16720
Cumulative Timesteps: 140303074

Timesteps Collected: 50076
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1502.88922
Policy Entropy: -0.15640
Value Function Loss: 0.68187

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.18054
Policy Update Magnitude: 0.06138
Value Function Update Magnitude: 0.07491

Collected Steps per Second: 10873.89835
Overall Steps per Second: 2483.06946

Timestep Collection Time: 4.60424
Timestep Consumption Time: 15.55871
PPO Batch Consumption Time: 2.28864
Total Iteration Time: 20.16295

Cumulative Model Updates: 16726
Cumulative Timesteps: 140353140

Timesteps Collected: 50066
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1004.42756
Policy Entropy: -0.16369
Value Function Loss: 0.66382

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.15807
Policy Update Magnitude: 0.06196
Value Function Update Magnitude: 0.08247

Collected Steps per Second: 11590.45343
Overall Steps per Second: 2459.07075

Timestep Collection Time: 4.31769
Timestep Consumption Time: 16.03309
PPO Batch Consumption Time: 2.35719
Total Iteration Time: 20.35078

Cumulative Model Updates: 16732
Cumulative Timesteps: 140403184

Timesteps Collected: 50044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1392.00759
Policy Entropy: -0.17354
Value Function Loss: 0.65736

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.17926
Policy Update Magnitude: 0.06377
Value Function Update Magnitude: 0.08863

Collected Steps per Second: 10957.96804
Overall Steps per Second: 2416.53905

Timestep Collection Time: 4.57548
Timestep Consumption Time: 16.17237
PPO Batch Consumption Time: 2.38186
Total Iteration Time: 20.74785

Cumulative Model Updates: 16738
Cumulative Timesteps: 140453322

Timesteps Collected: 50138
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3272.03740
Policy Entropy: -0.18237
Value Function Loss: 0.62535

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.19847
Policy Update Magnitude: 0.07502
Value Function Update Magnitude: 0.08298

Collected Steps per Second: 10819.84091
Overall Steps per Second: 2448.33235

Timestep Collection Time: 4.62761
Timestep Consumption Time: 15.82305
PPO Batch Consumption Time: 2.36486
Total Iteration Time: 20.45065

Cumulative Model Updates: 16744
Cumulative Timesteps: 140503392

Timesteps Collected: 50070
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 966.72100
Policy Entropy: -0.19231
Value Function Loss: 0.65600

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.19968
Policy Update Magnitude: 0.07037
Value Function Update Magnitude: 0.07706

Collected Steps per Second: 10964.73938
Overall Steps per Second: 2396.02933

Timestep Collection Time: 4.56956
Timestep Consumption Time: 16.34171
PPO Batch Consumption Time: 2.40247
Total Iteration Time: 20.91126

Cumulative Model Updates: 16750
Cumulative Timesteps: 140553496

Timesteps Collected: 50104
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1518.60915
Policy Entropy: -0.19750
Value Function Loss: 0.63853

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.17255
Policy Update Magnitude: 0.06926
Value Function Update Magnitude: 0.07586

Collected Steps per Second: 10824.58382
Overall Steps per Second: 2431.34271

Timestep Collection Time: 4.62263
Timestep Consumption Time: 15.95777
PPO Batch Consumption Time: 2.38817
Total Iteration Time: 20.58040

Cumulative Model Updates: 16756
Cumulative Timesteps: 140603534

Timesteps Collected: 50038
--------END ITERATION REPORT--------


Saving checkpoint 140603534...
Checkpoint 140603534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1449.31358
Policy Entropy: -0.20587
Value Function Loss: 0.65042

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.18252
Policy Update Magnitude: 0.06579
Value Function Update Magnitude: 0.07474

Collected Steps per Second: 10981.36408
Overall Steps per Second: 2391.71661

Timestep Collection Time: 4.55972
Timestep Consumption Time: 16.37587
PPO Batch Consumption Time: 2.40955
Total Iteration Time: 20.93559

Cumulative Model Updates: 16762
Cumulative Timesteps: 140653606

Timesteps Collected: 50072
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2227.12561
Policy Entropy: -0.20953
Value Function Loss: 0.66179

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.16304
Policy Update Magnitude: 0.06907
Value Function Update Magnitude: 0.07913

Collected Steps per Second: 10878.41950
Overall Steps per Second: 2394.53793

Timestep Collection Time: 4.59957
Timestep Consumption Time: 16.29632
PPO Batch Consumption Time: 2.44178
Total Iteration Time: 20.89589

Cumulative Model Updates: 16768
Cumulative Timesteps: 140703642

Timesteps Collected: 50036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2033.96828
Policy Entropy: -0.21915
Value Function Loss: 0.65770

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.17657
Policy Update Magnitude: 0.07819
Value Function Update Magnitude: 0.07868

Collected Steps per Second: 11133.55542
Overall Steps per Second: 2469.55659

Timestep Collection Time: 4.49524
Timestep Consumption Time: 15.77075
PPO Batch Consumption Time: 2.32085
Total Iteration Time: 20.26599

Cumulative Model Updates: 16774
Cumulative Timesteps: 140753690

Timesteps Collected: 50048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1778.66156
Policy Entropy: -0.22643
Value Function Loss: 0.65246

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.19194
Policy Update Magnitude: 0.07145
Value Function Update Magnitude: 0.08343

Collected Steps per Second: 10781.98275
Overall Steps per Second: 2452.22922

Timestep Collection Time: 4.64237
Timestep Consumption Time: 15.76926
PPO Batch Consumption Time: 2.31477
Total Iteration Time: 20.41163

Cumulative Model Updates: 16780
Cumulative Timesteps: 140803744

Timesteps Collected: 50054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1723.48911
Policy Entropy: -0.23220
Value Function Loss: 0.62657

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.17299
Policy Update Magnitude: 0.06329
Value Function Update Magnitude: 0.08383

Collected Steps per Second: 11364.17868
Overall Steps per Second: 2481.56602

Timestep Collection Time: 4.40261
Timestep Consumption Time: 15.75886
PPO Batch Consumption Time: 2.30817
Total Iteration Time: 20.16146

Cumulative Model Updates: 16786
Cumulative Timesteps: 140853776

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1371.64729
Policy Entropy: -0.23803
Value Function Loss: 0.61737

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.17776
Policy Update Magnitude: 0.05968
Value Function Update Magnitude: 0.07999

Collected Steps per Second: 11036.95685
Overall Steps per Second: 2449.94577

Timestep Collection Time: 4.53440
Timestep Consumption Time: 15.89299
PPO Batch Consumption Time: 2.33816
Total Iteration Time: 20.42739

Cumulative Model Updates: 16792
Cumulative Timesteps: 140903822

Timesteps Collected: 50046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1562.40740
Policy Entropy: -0.24204
Value Function Loss: 0.62583

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.18603
Policy Update Magnitude: 0.07131
Value Function Update Magnitude: 0.07441

Collected Steps per Second: 10808.42754
Overall Steps per Second: 2445.72060

Timestep Collection Time: 4.63157
Timestep Consumption Time: 15.83683
PPO Batch Consumption Time: 2.36893
Total Iteration Time: 20.46841

Cumulative Model Updates: 16798
Cumulative Timesteps: 140953882

Timesteps Collected: 50060
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1864.23740
Policy Entropy: -0.25063
Value Function Loss: 0.61610

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.19433
Policy Update Magnitude: 0.07194
Value Function Update Magnitude: 0.07883

Collected Steps per Second: 10978.24738
Overall Steps per Second: 2389.98326

Timestep Collection Time: 4.55537
Timestep Consumption Time: 16.36946
PPO Batch Consumption Time: 2.40410
Total Iteration Time: 20.92483

Cumulative Model Updates: 16804
Cumulative Timesteps: 141003892

Timesteps Collected: 50010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1085.16735
Policy Entropy: -0.26222
Value Function Loss: 0.61399

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.21046
Policy Update Magnitude: 0.08253
Value Function Update Magnitude: 0.08026

Collected Steps per Second: 10874.40010
Overall Steps per Second: 2494.89204

Timestep Collection Time: 4.60384
Timestep Consumption Time: 15.46276
PPO Batch Consumption Time: 2.29664
Total Iteration Time: 20.06660

Cumulative Model Updates: 16810
Cumulative Timesteps: 141053956

Timesteps Collected: 50064
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2026.79042
Policy Entropy: -0.26671
Value Function Loss: 0.60063

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.20158
Policy Update Magnitude: 0.08485
Value Function Update Magnitude: 0.07878

Collected Steps per Second: 11198.02019
Overall Steps per Second: 2480.82134

Timestep Collection Time: 4.47025
Timestep Consumption Time: 15.70774
PPO Batch Consumption Time: 2.30428
Total Iteration Time: 20.17799

Cumulative Model Updates: 16816
Cumulative Timesteps: 141104014

Timesteps Collected: 50058
--------END ITERATION REPORT--------


Saving checkpoint 141104014...
Checkpoint 141104014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2126.74603
Policy Entropy: -0.27295
Value Function Loss: 0.60103

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.17681
Policy Update Magnitude: 0.07869
Value Function Update Magnitude: 0.07501

Collected Steps per Second: 10758.62466
Overall Steps per Second: 2423.19500

Timestep Collection Time: 4.65022
Timestep Consumption Time: 15.99607
PPO Batch Consumption Time: 2.39910
Total Iteration Time: 20.64630

Cumulative Model Updates: 16822
Cumulative Timesteps: 141154044

Timesteps Collected: 50030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1190.45404
Policy Entropy: -0.27793
Value Function Loss: 0.59265

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.17093
Policy Update Magnitude: 0.08414
Value Function Update Magnitude: 0.07320

Collected Steps per Second: 11011.37451
Overall Steps per Second: 2406.04108

Timestep Collection Time: 4.54130
Timestep Consumption Time: 16.24221
PPO Batch Consumption Time: 2.39239
Total Iteration Time: 20.78352

Cumulative Model Updates: 16828
Cumulative Timesteps: 141204050

Timesteps Collected: 50006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 970.46324
Policy Entropy: -0.28218
Value Function Loss: 0.58702

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.17507
Policy Update Magnitude: 0.08042
Value Function Update Magnitude: 0.07233

Collected Steps per Second: 10969.09452
Overall Steps per Second: 2455.49574

Timestep Collection Time: 4.55954
Timestep Consumption Time: 15.80865
PPO Batch Consumption Time: 2.32611
Total Iteration Time: 20.36819

Cumulative Model Updates: 16834
Cumulative Timesteps: 141254064

Timesteps Collected: 50014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1499.09139
Policy Entropy: -0.28626
Value Function Loss: 0.59393

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.18500
Policy Update Magnitude: 0.07704
Value Function Update Magnitude: 0.08046

Collected Steps per Second: 11928.21973
Overall Steps per Second: 2434.81321

Timestep Collection Time: 4.19694
Timestep Consumption Time: 16.36398
PPO Batch Consumption Time: 2.42120
Total Iteration Time: 20.56092

Cumulative Model Updates: 16840
Cumulative Timesteps: 141304126

Timesteps Collected: 50062
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2633.22971
Policy Entropy: -0.29409
Value Function Loss: 0.61325

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.15251
Policy Update Magnitude: 0.06595
Value Function Update Magnitude: 0.08246

Collected Steps per Second: 12497.59489
Overall Steps per Second: 2509.48018

Timestep Collection Time: 4.00333
Timestep Consumption Time: 15.93387
PPO Batch Consumption Time: 2.35356
Total Iteration Time: 19.93720

Cumulative Model Updates: 16846
Cumulative Timesteps: 141354158

Timesteps Collected: 50032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1747.14435
Policy Entropy: -0.30018
Value Function Loss: 0.62673

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.15852
Policy Update Magnitude: 0.06695
Value Function Update Magnitude: 0.08106

Collected Steps per Second: 10904.58389
Overall Steps per Second: 2435.61506

Timestep Collection Time: 4.58688
Timestep Consumption Time: 15.94921
PPO Batch Consumption Time: 2.38208
Total Iteration Time: 20.53609

Cumulative Model Updates: 16852
Cumulative Timesteps: 141404176

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1995.16925
Policy Entropy: -0.30755
Value Function Loss: 0.63301

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.16918
Policy Update Magnitude: 0.06632
Value Function Update Magnitude: 0.07789

Collected Steps per Second: 10893.27268
Overall Steps per Second: 2407.41128

Timestep Collection Time: 4.59164
Timestep Consumption Time: 16.18503
PPO Batch Consumption Time: 2.37638
Total Iteration Time: 20.77667

Cumulative Model Updates: 16858
Cumulative Timesteps: 141454194

Timesteps Collected: 50018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2080.98412
Policy Entropy: -0.31295
Value Function Loss: 0.60383

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.17948
Policy Update Magnitude: 0.06279
Value Function Update Magnitude: 0.07592

Collected Steps per Second: 11039.25463
Overall Steps per Second: 2460.38079

Timestep Collection Time: 4.53455
Timestep Consumption Time: 15.81109
PPO Batch Consumption Time: 2.35741
Total Iteration Time: 20.34563

Cumulative Model Updates: 16864
Cumulative Timesteps: 141504252

Timesteps Collected: 50058
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1577.51513
Policy Entropy: -0.31554
Value Function Loss: 0.60609

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.17100
Policy Update Magnitude: 0.06041
Value Function Update Magnitude: 0.07291

Collected Steps per Second: 11122.32604
Overall Steps per Second: 2406.28237

Timestep Collection Time: 4.50391
Timestep Consumption Time: 16.31409
PPO Batch Consumption Time: 2.40382
Total Iteration Time: 20.81801

Cumulative Model Updates: 16870
Cumulative Timesteps: 141554346

Timesteps Collected: 50094
--------END ITERATION REPORT--------
