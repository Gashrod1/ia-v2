{"Cumulative Model Updates":16870,"Value Function Loss":0.6060886184374491,"Total Iteration Time":20.81800562189892,"Cumulative Timesteps":141604386,"z_vel":-1.674976254902764,"total_goals":0,"Timesteps Collected":50094,"episode_goals":0,"SB3 Clip Fraction":0.17100333174069723,"_wandb":{"runtime":63182},"Timestep Collection Time":4.503914005123079,"_timestamp":1.7630331804983618e+09,"Policy Update Magnitude":0.060405295342206955,"_step":5804,"Mean KL Divergence":0.012868617040415605,"Collected Steps per Second":11122.326035314938,"Overall Steps per Second":2406.2823744895627,"_runtime":63182,"Value Function Update Magnitude":0.07291017472743988,"PPO Batch Consumption Time":2.403815428415934,"episode_touches":0,"Policy Reward":1577.5151285945542,"x_vel":-27.250277399660952,"y_vel":8.056318086582376,"total_touches":0,"Policy Entropy":-0.3155420770247777,"Timestep Consumption Time":16.31409161677584}