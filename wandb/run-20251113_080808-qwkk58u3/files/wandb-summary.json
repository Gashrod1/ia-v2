{"Timesteps Collected":50000,"Policy Update Magnitude":0.04604998230934143,"SB3 Clip Fraction":0.13180666665236154,"total_goals":0,"Overall Steps per Second":1287.3865585546444,"PPO Batch Consumption Time":1.5703744093577068,"_step":4548,"Timestep Collection Time":28.255495799996424,"Value Function Update Magnitude":0.15199382603168488,"episode_goals":0,"Value Function Loss":0.5123077382644018,"x_vel":-8.89783178368494,"_wandb":{"runtime":49453},"total_touches":0,"Cumulative Model Updates":13346,"Collected Steps per Second":1769.5672499934094,"Timestep Consumption Time":10.582877699984238,"episode_touches":0,"Total Iteration Time":38.83837349998066,"y_vel":-20.9381099589717,"Cumulative Timesteps":111728558,"_timestamp":1.7630181985290213e+09,"Policy Reward":907.5923491813901,"Policy Entropy":-0.021607283192376297,"_runtime":49453,"z_vel":-9.25932471625382,"Mean KL Divergence":0.009816619722793499}